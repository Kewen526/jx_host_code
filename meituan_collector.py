#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¾å›¢ç‚¹è¯„æ•°æ®é‡‡é›†ç»Ÿä¸€å…¥å£ - å•æ–‡ä»¶ç‰ˆæœ¬

ç›´æ¥åœ¨PyCharmä¸­è¿è¡Œï¼Œä¿®æ”¹ä¸‹æ–¹çš„é…ç½®å‚æ•°å³å¯
åŒ…å«: 6ä¸ªæ•°æ®é‡‡é›†ä»»åŠ¡ + store_statsé—¨åº—ç»Ÿè®¡ä»»åŠ¡(ä½¿ç”¨Playwrightæµè§ˆå™¨)
"""

import json
import time
import random
import requests
import requests.exceptions
import pandas as pd
import math
import os
import sys
import subprocess
import signal
import logging
from typing import Dict, Any, Optional, List, Tuple
from pathlib import Path
from datetime import datetime, timedelta
from io import BytesIO
from contextlib import contextmanager

# Playwrightå¯¼å…¥ (ç”¨äºstore_statsä»»åŠ¡)
try:
    from playwright.sync_api import sync_playwright
    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False
    print("âš ï¸ æœªå®‰è£…playwrightï¼Œstore_statsä»»åŠ¡å°†ä¸å¯ç”¨")
    print("   å®‰è£…æ–¹æ³•: pip install playwright && playwright install chromium")

# æµè§ˆå™¨æ± æ¨¡å—å¯¼å…¥
try:
    from browser_pool import (
        initialize_browser_pool,
        start_keepalive_service,
        shutdown_all as shutdown_browser_pool,
        get_browser_pool,
        account_lock_manager,
        cookie_upload_queue,
        fetch_task_with_server_ip,
        get_public_ip,
        get_cached_ip,
        BrowserPoolManager,
        KeepaliveService,
        resource_monitor,  # èµ„æºç›‘æ§å™¨
    )
    BROWSER_POOL_AVAILABLE = True
except ImportError as e:
    BROWSER_POOL_AVAILABLE = False
    print(f"âš ï¸ æµè§ˆå™¨æ± æ¨¡å—æœªåŠ è½½: {e}")
    print("   å°†ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼è¿è¡Œ")


# ============================================================================
# â˜…â˜…â˜… åœ¨è¿™é‡Œä¿®æ”¹é…ç½®å‚æ•° â˜…â˜…â˜…
# ============================================================================
ACCOUNT_NAME = "13718175572a"       # è´¦æˆ·åç§° (å¿…å¡«)
START_DATE = "2025-12-01"           # å¼€å§‹æ—¥æœŸ (å¿…å¡«, æ ¼å¼: YYYY-MM-DD)
END_DATE = "2025-12-15"             # ç»“æŸæ—¥æœŸ (å¿…å¡«, æ ¼å¼: YYYY-MM-DD)
TARGET_DATE = ""                    # store_statsç›®æ ‡æ—¥æœŸ (ç•™ç©º=ä½¿ç”¨END_DATE)
TASK = "all"                        # ä»»åŠ¡åç§° (å¿…å¡«)
                                    # å¯é€‰å€¼:
                                    #   "all" - é¡µé¢é©±åŠ¨æ¨¡å¼ï¼Œå…ˆè·³è½¬é¡µé¢å†æ‰§è¡Œä»»åŠ¡
                                    #           é¡ºåº: æŠ¥è¡¨é¡µé¢ â†’ å®¢æµåˆ†æé¡µé¢ â†’ è¯„ä»·é¡µé¢
                                    #   "store_stats" - é—¨åº—ç»Ÿè®¡(å¼ºåˆ¶ä¸‹çº¿ã€å®¢æµã€æ’åç­‰)
                                    #   "kewen_daily_report" - å®¢æ–‡æ—¥æŠ¥
                                    #   "promotion_daily_report" - æ¨å¹¿æ—¥æŠ¥
                                    #   "review_detail_dianping" - ç‚¹è¯„è¯„ä»·æ˜ç»†
                                    #   "review_detail_meituan" - ç¾å›¢è¯„ä»·æ˜ç»†
                                    #   "review_summary_dianping" - ç‚¹è¯„è¯„ä»·æ±‡æ€»
                                    #   "review_summary_meituan" - ç¾å›¢è¯„ä»·æ±‡æ€»

# store_stats æµè§ˆå™¨é…ç½®
HEADLESS = True                     # æµè§ˆå™¨æ¨¡å¼: True=åå°è¿è¡Œ, False=æ˜¾ç¤ºçª—å£

# ============================================================================
# â˜…â˜…â˜… å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼é…ç½® â˜…â˜…â˜…
# ============================================================================
DEV_MODE = True                     # å¼€å‘æ¨¡å¼: True=24å°æ—¶è¿è¡Œ, False=ä»…åœ¨å·¥ä½œæ—¶é—´è¿è¡Œ
WORK_START_HOUR = 8                 # å·¥ä½œå¼€å§‹æ—¶é—´ (ä»…DEV_MODE=Falseæ—¶ç”Ÿæ•ˆ)
WORK_END_HOUR = 23                  # å·¥ä½œç»“æŸæ—¶é—´ (ä»…DEV_MODE=Falseæ—¶ç”Ÿæ•ˆ)
NO_TASK_WAIT_SECONDS = 300          # æ— ä»»åŠ¡æ—¶ç­‰å¾…ç§’æ•° (5åˆ†é’Ÿ)

# ============================================================================
# â˜…â˜…â˜… æµè§ˆå™¨æ± æ¨¡å¼é…ç½® â˜…â˜…â˜…
# ============================================================================
USE_BROWSER_POOL = True             # æ˜¯å¦ä½¿ç”¨æµè§ˆå™¨æ± æ¨¡å¼ (æ¨èå¼€å¯)
                                    # True: ä½¿ç”¨æµè§ˆå™¨æ±  + ä¿æ´»æœºåˆ¶
                                    # False: ä¼ ç»Ÿæ¨¡å¼ï¼Œæ¯æ¬¡ä»»åŠ¡æ–°å»ºæµè§ˆå™¨

# ============================================================================
# â˜…â˜…â˜… è·¯å¾„é…ç½® (æœåŠ¡å™¨éƒ¨ç½²æ—¶ä½¿ç”¨ç»å¯¹è·¯å¾„) â˜…â˜…â˜…
# ============================================================================
DATA_DIR = "/home/meituan/data"                     # æ•°æ®æ ¹ç›®å½•
STATE_DIR = "/home/meituan/data/state"              # CookieçŠ¶æ€æ–‡ä»¶ç›®å½•
DOWNLOAD_DIR = "/home/meituan/data/downloads"       # ä¸‹è½½æ–‡ä»¶ç›®å½•

# ============================================================================
# APIé…ç½® (ä¸€èˆ¬ä¸éœ€è¦ä¿®æ”¹)
# ============================================================================
PLATFORM_ACCOUNTS_API_URL = "http://8.146.210.145:3000/api/get_platform_accounts"
LOG_API_URL = "http://8.146.210.145:3000/api/log"
AUTH_STATUS_API_URL = "http://8.146.210.145:3000/api/post/platform_accounts"  # ç™»å½•çŠ¶æ€ä¸ŠæŠ¥API
TASK_STATUS_BATCH_API_URL = "http://8.146.210.145:3000/api/account_task/update_batch"  # ä»»åŠ¡çŠ¶æ€æ‰¹é‡ä¸ŠæŠ¥API
TASK_STATUS_SINGLE_API_URL = "http://8.146.210.145:3000/api/account_task/update_single"  # ä»»åŠ¡çŠ¶æ€å•ç‹¬ä¸ŠæŠ¥API
TASK_SCHEDULE_API_URL = "http://8.146.210.145:3000/api/post_task_schedule"  # ä»»åŠ¡è°ƒåº¦ç”ŸæˆAPI
GET_TASK_API_URL = "http://8.146.210.145:3000/api/get_task"  # è·å–ä»»åŠ¡API
TASK_CALLBACK_API_URL = "http://8.146.210.145:3000/api/task/callback"  # ä»»åŠ¡å®Œæˆå›è°ƒAPI
RESCHEDULE_FAILED_API_URL = "http://8.146.210.145:3000/api/task/reschedule-failed"  # å¤±è´¥ä»»åŠ¡é‡æ–°è°ƒåº¦API
TASK_RESET_API_URL = "http://8.146.210.145:3000/api/task/schedule/reset"  # ä»»åŠ¡é‡ç½®APIï¼ˆèµ„æºä¸è¶³æ—¶å½’è¿˜ä»»åŠ¡ï¼‰
GET_PLATFORM_ACCOUNT_API_URL = "http://8.146.210.145:3000/api/get_platform_account"  # è·å–å¹³å°è´¦æˆ·ä¿¡æ¯API
POST_STORES_REGIONS_API_URL = "http://8.146.210.145:3000/api/post/platform_accounts"  # é—¨åº—/å•†åœˆæ•°æ®å›ä¼ API
SAVE_DIR = DOWNLOAD_DIR  # ä½¿ç”¨ç»å¯¹è·¯å¾„

# ============================================================================
# æŠ¥è¡¨æ¨¡æ¿ç›¸å…³APIé…ç½®
# ============================================================================
TEMPLATE_LIST_API = "https://e.dianping.com/gateway/adviser/report/template/list"
TEMPLATE_SAVE_API = "https://e.dianping.com/gateway/adviser/report/template/save"
PLATFORM_ACCOUNTS_UPDATE_API = "http://8.146.210.145:3000/api/platform-accounts"
TEMPLATES_ID_UPDATE_API_URL = "https://kewenai.asia/api/up/templates_id"

# æŠ¥è¡¨ä¸­å¿ƒé¡µé¢URLï¼ˆç”¨äºè·å–/åˆ›å»ºæ¨¡æ¿æ—¶è·³è½¬ï¼‰
REPORT_CENTER_URL = "https://e.dianping.com/app/merchant-platform/0fb1bec0bade47d?iUrl=Ly9oNS5kaWFucGluZy5jb20vdmctcGMtYWR2aWNlL3JlcG9ydC1jZW50ZXIvaW5kZXguaHRtbA"

# åˆ›å»ºæŠ¥è¡¨æ¨¡æ¿æ—¶ä½¿ç”¨çš„å›ºå®šæŒ‡æ ‡åˆ—è¡¨
TEMPLATE_METRIC_LIST = ",".join([
    "basic_shop_dp_score",
    "derived_shop_mt_score",
    "basic_shop_operation_score",
    "basic_shop_operation_grade",
    "basic_acc_shop_cpc_charge",
    "basic_shop_mem_publish_amount",
    "basic_shop_commission_amount",
    "basic_shop_commission_base_amount",
    "basic_shop_view_uv",
    "basic_shop_view_cnt",
    "basic_shop_visit_uv",
    "basic_shop_visit_cnt",
    "derived_shop_click_rate",
    "basic_shop_buy_uv",
    "basic_shop_booking_uv_new",
    "basic_shop_intent_uv_new",
    "derived_shop_intent_rate_new",
    "basic_shop_daily_favorite_user_cnt",
    "basic_shop_favorite_user_cnt",
    "basic_shop_flow_view_avg_page_stay_time",
    "basic_acc_shop_cpc_view_cnt",
    "basic_acc_shop_cpc_click_cnt",
    "basic_shop_trade_csm_amt",
    "basic_shop_trade_csm_amt_no_shop_share",
    "basic_shop_trade_csm_cnt",
    "basic_shop_trade_csm_order_cnt",
    "basic_shop_trade_csm_uv",
    "basic_shop_trade_csm_new_user_cnt",
    "basic_shop_product_sale_cnt",
    "basic_shop_product_sale_amt",
    "basic_shop_ask_user_cnt",
    "basic_shop_im_booking_uv",
    "derived_shop_ask_booking_rate",
    "derived_shop_ask_avg_reply_duration",
    "derived_shop_ask_30sec_reply_rate",
    "derived_shop_ask_5min_reply_rate",
    "basic_shop_refund_order_amt",
    "basic_shop_refund_order_cnt",
    "basic_shop_refund_user_cnt",
    "basic_shop_csmdisp_complain_cnt",
    "basic_shop_cpst_order_cnt",
    "basic_shop_review_chosen_new_cnt",
    "basic_shop_review_good_new_cnt",
    "basic_shop_review_good_mid_cnt",
    "basic_shop_review_chosen_bad_new_cnt",
    "derived_shop_review_chosen_bad_reply_rate",
    "basic_shop_review_all_cnt",
    "basic_shop_review_all_bad_cnt",
    "basic_scan_pay_order_cnt",
    "basic_scan_pay_amt",
    "basic_scan_consume_amt",
    "basic_scan_user_cnt",
    "basic_scan_favorite_user_cnt",
    "basic_scan_comment_user_cnt",
])

# ============================================================================
# â˜…â˜…â˜… ç»Ÿä¸€è¶…æ—¶å‚æ•°é…ç½® â˜…â˜…â˜…
# ============================================================================
CONNECT_TIMEOUT = 10        # è¿æ¥å»ºç«‹è¶…æ—¶ï¼ˆç§’ï¼‰
API_TIMEOUT = 30            # æ™®é€šAPIè¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰
DOWNLOAD_TIMEOUT = 120      # æ–‡ä»¶ä¸‹è½½è¶…æ—¶ï¼ˆç§’ï¼‰
BROWSER_PAGE_TIMEOUT = 60000  # æµè§ˆå™¨é¡µé¢åŠ è½½è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
LOGIN_CHECK_TIMEOUT = 30000   # ç™»å½•æ£€æµ‹è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰

# æŒ‡æ•°é€€é¿é‡è¯•é…ç½®
MAX_RETRY_ATTEMPTS = 3      # æœ€å¤§é‡è¯•æ¬¡æ•°
INITIAL_RETRY_DELAY = 2     # åˆå§‹é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
MAX_RETRY_DELAY = 60        # æœ€å¤§é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
RETRY_BACKOFF_FACTOR = 2    # é€€é¿å› å­

# ============================================================================
# â˜…â˜…â˜… æ—¥å¿—é…ç½® â˜…â˜…â˜…
# ============================================================================
LOG_LEVEL = logging.INFO
LOG_FORMAT = '%(asctime)s [%(levelname)s] %(message)s'
LOG_DATE_FORMAT = '%Y-%m-%d %H:%M:%S'

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=LOG_LEVEL,
    format=LOG_FORMAT,
    datefmt=LOG_DATE_FORMAT,
    handlers=[
        logging.StreamHandler()  # è¾“å‡ºåˆ°æ§åˆ¶å°
    ]
)
logger = logging.getLogger(__name__)

# å„ä»»åŠ¡çš„ä¸Šä¼ API
UPLOAD_APIS = {
    "store_stats": "http://8.146.210.145:3000/api/store_stats",
    "kewen_daily_report": "http://8.146.210.145:3000/api/kewen_daily_report",
    "promotion_daily_report": "http://8.146.210.145:3000/api/promotion_daily_report",
    "review_detail_dianping": "http://8.146.210.145:3000/api/review_detail_dianping",
    "review_detail_meituan": "http://8.146.210.145:3000/api/review_detail_meituan",
    "review_summary_dianping": "http://8.146.210.145:3000/api/review_summary_dianping",
    "review_summary_meituan": "http://8.146.210.145:3000/api/review_summary_meituan",
}

# ============================================================================
# é¡µé¢é©±åŠ¨ä»»åŠ¡é…ç½® - å…ˆè·³è½¬é¡µé¢å†æ‰§è¡Œå¯¹åº”ä»»åŠ¡
# ============================================================================
PAGE_URLS = {
    # æŠ¥è¡¨é¡µé¢ - æ‰§è¡Œ kewen_daily_report, promotion_daily_report
    "report": "https://e.dianping.com/app/merchant-platform/0fb1bec0bade47d?iUrl=Ly9oNS5kaWFucGluZy5jb20vdmctcGMtYWR2aWNlL3JlcG9ydC1jZW50ZXIvaW5kZXguaHRtbA",
    # å®¢æµåˆ†æé¡µé¢ - æ‰§è¡Œ store_stats
    "flow_analysis": "https://e.dianping.com/app/merchant-platform/468ccfd01240492?iUrl=Ly9oNS5kaWFucGluZy5jb20vdmctcGMtYWR2aWNlL2FkdmljZS1mbG93LWFuYWx5c2lzL2luZGV4Lmh0bWw",
    # è¯„ä»·é¡µé¢ - æ‰§è¡Œ review_detail_dianping, review_detail_meituan, review_summary_dianping, review_summary_meituan
    "review": "https://e.dianping.com/app/merchant-platform/7dfe97aa7164460?iUrl=Ly9lLmRpYW5waW5nLmNvbS92Zy1wbGF0Zm9ybS1yZXZpZXdtYW5hZ2Uvc2hvcC1jb21tZW50LWRwL2luZGV4Lmh0bWw",
}

# é¡µé¢ä¸ä»»åŠ¡çš„æ˜ å°„å…³ç³»
PAGE_TASKS = {
    "report": ["kewen_daily_report", "promotion_daily_report"],
    "flow_analysis": ["store_stats"],
    "review": ["review_detail_dianping", "review_detail_meituan", "review_summary_dianping", "review_summary_meituan"],
}

# é¡µé¢æ‰§è¡Œé¡ºåºï¼ˆå®¢æµåˆ†æå…ˆæ‰§è¡Œä»¥æ›´æ–°ç­¾åï¼Œè¯„ä»·é¡µé¢æ”¾æœ€åï¼‰
PAGE_ORDER = ["flow_analysis", "report", "review"]

# ============================================================================
# â˜…â˜…â˜… ä»»åŠ¡ç‹¬ç«‹é¡µé¢URLé…ç½® â˜…â˜…â˜…
# ============================================================================
# é¦–é¡µï¼ˆCookieç™»å½•åè·³è½¬ï¼‰
HOME_PAGE_URL = "https://e.dianping.com/app/merchant-platform/"

# æ¯ä¸ªä»»åŠ¡å¯¹åº”çš„ç‹¬ç«‹é¡µé¢URL
TASK_PAGE_URLS = {
    "kewen_daily_report": "https://e.dianping.com/app/merchant-platform/0fb1bec0bade47d?iUrl=Ly9oNS5kaWFucGluZy5jb20vdmctcGMtYWR2aWNlL3JlcG9ydC1jZW50ZXIvaW5kZXguaHRtbA",
    "promotion_daily_report": "https://e.dianping.com/app/merchant-platform/e77c7f630ee64ca?iUrl=Ly9oNS5kaWFucGluZy5jb20vYXBwL21lcmNoYW50LW1hbmFnZS1hZHZpY2UtcGMtc3RhdGljL2RpYWdub3Npcy1ob21lLmh0bWw#menuId=1",
    "store_stats": "https://e.dianping.com/app/merchant-platform/468ccfd01240492?iUrl=Ly9oNS5kaWFucGluZy5jb20vdmctcGMtYWR2aWNlL2FkdmljZS1mbG93LWFuYWx5c2lzL2luZGV4Lmh0bWw",
    "review_detail_dianping": "https://e.dianping.com/app/merchant-platform/7dfe97aa7164460?iUrl=Ly9lLmRpYW5waW5nLmNvbS92Zy1wbGF0Zm9ybS1yZXZpZXdtYW5hZ2Uvc2hvcC1jb21tZW50LWRwL2luZGV4Lmh0bWw",
    "review_detail_meituan": "https://e.dianping.com/app/merchant-platform/27e9b6df520b47f?iUrl=Ly9lLmRpYW5waW5nLmNvbS92Zy1wbGF0Zm9ybS1yZXZpZXdtYW5hZ2Uvc2hvcC1jb21tZW50LW10L2luZGV4Lmh0bWw",
    # ä»¥ä¸‹ä¸¤ä¸ªä»»åŠ¡å·²ç¦ç”¨ï¼Œæ— éœ€è·³è½¬é¡µé¢
    "review_summary_dianping": None,
    "review_summary_meituan": None,
}

# store_stats å†…éƒ¨æ•°æ®é‡‡é›†é¡µé¢URL
STORE_STATS_PAGE_URLS = {
    "flow_analysis": "https://e.dianping.com/app/merchant-platform/468ccfd01240492?iUrl=Ly9oNS5kaWFucGluZy5jb20vdmctcGMtYWR2aWNlL2FkdmljZS1mbG93LWFuYWx5c2lzL2luZGV4Lmh0bWw",
    "rival_analysis": "https://e.dianping.com/app/merchant-platform/fe6031ae4f544c4?iUrl=Ly9lLmRpYW5waW5nLmNvbS9hcHAvbWVyY2hhbnQtd29ya2JlbmNoL2luZGV4Lmh0bWwjLw",
    "trade_analysis": "https://e.dianping.com/app/merchant-platform/8b352a79fb3e44e?iUrl=Ly9oNS5kaWFucGluZy5jb20vYXBwL21lcmNoYW50LW1hbmFnZS1hZHZpY2UtcGMtc3RhdGljL2FkdmljZS10cmFkZS1hbmFseXNpcy5odG1s",
    "notice_center": "https://e.dianping.com/app/vg-pc-platform-merchant-selfhelp/newNoticeCenter.html",
}

# ä»»åŠ¡é¡µé¢åç§°æ˜ å°„ï¼ˆç”¨äºæ—¥å¿—æ˜¾ç¤ºï¼‰
TASK_PAGE_NAMES = {
    "kewen_daily_report": "æŠ¥è¡¨ä¸­å¿ƒ",
    "promotion_daily_report": "æ¨å¹¿ä¸­å¿ƒ",
    "store_stats": "å®¢æµåˆ†æ",
    "review_detail_dianping": "ç‚¹è¯„è¯„ä»·",
    "review_detail_meituan": "ç¾å›¢è¯„ä»·",
    "review_summary_dianping": "ç‚¹è¯„è¯„ä»·æ±‡æ€»(å·²ç¦ç”¨)",
    "review_summary_meituan": "ç¾å›¢è¯„ä»·æ±‡æ€»(å·²ç¦ç”¨)",
}

# store_stats å†…éƒ¨é¡µé¢åç§°
STORE_STATS_PAGE_NAMES = {
    "flow_analysis": "å®¢æµåˆ†æ",
    "rival_analysis": "åŒè¡Œåˆ†æ",
    "trade_analysis": "äº¤æ˜“åˆ†æ",
    "notice_center": "æ¶ˆæ¯ä¸­å¿ƒ",
}

# ============================================================================
# â˜…â˜…â˜… ä»»åŠ¡ç¦ç”¨å¼€å…³ â˜…â˜…â˜…
# ============================================================================
TASK_DISABLED_FLAGS = {
    "kewen_daily_report": False,
    "promotion_daily_report": False,
    "store_stats": False,
    "review_detail_dianping": False,
    "review_detail_meituan": False,
    "review_summary_dianping": True,   # âš ï¸ å·²ç¦ç”¨
    "review_summary_meituan": True,    # âš ï¸ å·²ç¦ç”¨
}

# ä»»åŠ¡æ‰§è¡Œé¡ºåºï¼ˆallæ¨¡å¼ä¸‹çš„æ‰§è¡Œé¡ºåºï¼‰
TASK_EXECUTION_ORDER = [
    "store_stats",
    "kewen_daily_report",
    "promotion_daily_report",
    "review_detail_dianping",
    "review_detail_meituan",
    "review_summary_dianping",
    "review_summary_meituan",
]

# ============================================================================
# å…±äº«ç­¾åå­˜å‚¨ (store_statsæ‰§è¡Œåæ›´æ–°ï¼Œä¾›å…¶ä»–ä»»åŠ¡ä½¿ç”¨)
# ============================================================================
SHARED_SIGNATURE = {
    'mtgsig': None,          # ç­¾åå­—ç¬¦ä¸²
    'cookies': None,         # æ›´æ–°åçš„cookies
    'updated_at': None,      # æ›´æ–°æ—¶é—´
    'shop_list': None,       # é—¨åº—åˆ—è¡¨
    'compare_regions': None, # é—¨åº—å•†åœˆä¿¡æ¯ï¼ˆç”¨äºåŒè¡Œæ’åï¼‰
    'brands_json': None,     # å›¢è´­IDæ˜ å°„ï¼ˆç”¨äºå¹¿å‘Šå•ï¼‰
}


# ============================================================================
# å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼: ä¿¡å·å¤„ç†å’Œæ—¶é—´çª—å£æ§åˆ¶
# ============================================================================
# å…¨å±€è¿è¡Œæ ‡å¿— (ç”¨äºä¼˜é›…é€€å‡º)
_daemon_running = True


def _signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å‡½æ•°ï¼Œç”¨äºä¼˜é›…é€€å‡º"""
    global _daemon_running
    _daemon_running = False
    sig_name = signal.Signals(signum).name if hasattr(signal, 'Signals') else str(signum)
    print(f"\n{'=' * 60}")
    print(f"âš ï¸ æ”¶åˆ°é€€å‡ºä¿¡å· ({sig_name})ï¼Œç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆåé€€å‡º...")
    print(f"{'=' * 60}")


def _setup_signal_handlers():
    """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
    signal.signal(signal.SIGINT, _signal_handler)   # Ctrl+C
    signal.signal(signal.SIGTERM, _signal_handler)  # killå‘½ä»¤
    print("âœ… å·²è®¾ç½®ä¿¡å·å¤„ç†å™¨ (æ”¯æŒCtrl+Cä¼˜é›…é€€å‡º)")


def is_in_work_window() -> bool:
    """æ£€æŸ¥å½“å‰æ˜¯å¦åœ¨å·¥ä½œæ—¶é—´çª—å£å†…

    DEV_MODE=True æ—¶å§‹ç»ˆè¿”å›True (24å°æ—¶è¿è¡Œ)
    DEV_MODE=False æ—¶æ£€æŸ¥æ˜¯å¦åœ¨ WORK_START_HOUR è‡³ WORK_END_HOUR ä¹‹é—´
    """
    if DEV_MODE:
        return True
    current_hour = datetime.now().hour
    return WORK_START_HOUR <= current_hour < WORK_END_HOUR


def seconds_until_work_start() -> int:
    """è®¡ç®—è·ç¦»ä¸‹ä¸€ä¸ªå·¥ä½œæ—¶é—´å¼€å§‹çš„ç§’æ•°"""
    now = datetime.now()
    if now.hour >= WORK_END_HOUR:
        # ä»Šå¤©å·²è¿‡å·¥ä½œç»“æŸæ—¶é—´ï¼Œç­‰åˆ°æ˜å¤©å¼€å§‹æ—¶é—´
        next_start = now.replace(hour=WORK_START_HOUR, minute=0, second=0, microsecond=0) + timedelta(days=1)
    elif now.hour < WORK_START_HOUR:
        # è¿˜æ²¡åˆ°ä»Šå¤©çš„å¼€å§‹æ—¶é—´
        next_start = now.replace(hour=WORK_START_HOUR, minute=0, second=0, microsecond=0)
    else:
        # å·²åœ¨å·¥ä½œæ—¶é—´å†…
        return 0
    return int((next_start - now).total_seconds())


def ensure_directories():
    """ç¡®ä¿æ‰€æœ‰å¿…è¦çš„ç›®å½•å­˜åœ¨"""
    directories = [DATA_DIR, STATE_DIR, DOWNLOAD_DIR]
    for dir_path in directories:
        try:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
            print(f"âœ… ç›®å½•å·²å°±ç»ª: {dir_path}")
        except Exception as e:
            print(f"âŒ åˆ›å»ºç›®å½•å¤±è´¥ {dir_path}: {e}")
            raise


def interruptible_sleep(seconds: int, check_interval: int = 10) -> bool:
    """å¯ä¸­æ–­çš„ç¡çœ å‡½æ•°

    Args:
        seconds: æ€»ç¡çœ ç§’æ•°
        check_interval: æ£€æŸ¥é—´éš”ç§’æ•°

    Returns:
        bool: True=æ­£å¸¸å®Œæˆ, False=è¢«ä¸­æ–­
    """
    global _daemon_running
    elapsed = 0
    while elapsed < seconds and _daemon_running:
        sleep_time = min(check_interval, seconds - elapsed)
        time.sleep(sleep_time)
        elapsed += sleep_time
    return _daemon_running


# ============================================================================
# æ—¥å¿—ä¸ŠæŠ¥åŠŸèƒ½
# ============================================================================
def log_task_result(
    account_id: str,
    shop_id: int,
    table_name: str,
    data_date_start: str,
    data_date_end: str,
    upload_status: int,
    record_count: int = 0,
    error_message: str = "æ— "
) -> bool:
    """ä¸ŠæŠ¥ä»»åŠ¡æ‰§è¡Œæ—¥å¿—åˆ°API"""
    headers = {'Content-Type': 'application/json'}
    json_param = {
        "account_id": account_id,
        "shop_id": shop_id,
        "table_name": table_name,
        "data_date_start": data_date_start,
        "data_date_end": data_date_end,
        "upload_status": upload_status,
        "record_count": record_count,
        "error_message": error_message
    }
    proxies = {'http': None, 'https': None}

    print(f"\n{'â”€' * 50}")
    print(f"ğŸ“ æ—¥å¿—ä¸ŠæŠ¥è¯·æ±‚:")
    print(f"   URL: {LOG_API_URL}")
    print(f"   è¯·æ±‚å‚æ•°: {json.dumps(json_param, ensure_ascii=False, indent=6)}")

    try:
        response = requests.post(LOG_API_URL, headers=headers, data=json.dumps(json_param), proxies=proxies, timeout=30)
        print(f"   HTTPçŠ¶æ€ç : {response.status_code}")
        print(f"   å“åº”å†…å®¹: {response.text[:500] if response.text else '(ç©º)'}")
        if response.status_code == 200:
            print(f"   âœ… æ—¥å¿—ä¸ŠæŠ¥æˆåŠŸ")
            return True
        else:
            print(f"   âŒ æ—¥å¿—ä¸ŠæŠ¥å¤±è´¥")
            return False
    except Exception as e:
        print(f"   âŒ æ—¥å¿—ä¸ŠæŠ¥å¼‚å¸¸: {e}")
        return False


def log_success(account_id: str, shop_id: int, table_name: str, data_date_start: str, data_date_end: str, record_count: int) -> bool:
    return log_task_result(account_id, shop_id, table_name, data_date_start, data_date_end, 2, record_count, "æ— ")


def log_failure(account_id: str, shop_id: int, table_name: str, data_date_start: str, data_date_end: str, error_message: str) -> bool:
    return log_task_result(account_id, shop_id, table_name, data_date_start, data_date_end, 1, 0, error_message)


# ============================================================================
# é€šç”¨å·¥å…·å‡½æ•°
# ============================================================================
def disable_proxy():
    """ç¦ç”¨ç³»ç»Ÿä»£ç†"""
    for key in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 'ALL_PROXY', 'all_proxy']:
        os.environ.pop(key, None)
    os.environ['NO_PROXY'] = '*'
    os.environ['no_proxy'] = '*'
    print("âœ… å·²ç¦ç”¨ç³»ç»Ÿä»£ç†")


def get_session() -> requests.Session:
    """è·å–ç¦ç”¨ä»£ç†çš„session"""
    session = requests.Session()
    session.trust_env = False
    session.proxies = {'http': None, 'https': None}
    return session


@contextmanager
def managed_session():
    """Sessionä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç¡®ä¿Sessionæ­£ç¡®å…³é—­"""
    session = get_session()
    try:
        yield session
    finally:
        session.close()


def safe_json_parse(response: requests.Response, default: Any = None) -> Tuple[Any, Optional[str]]:
    """å®‰å…¨è§£æJSONå“åº”

    Args:
        response: requestså“åº”å¯¹è±¡
        default: è§£æå¤±è´¥æ—¶çš„é»˜è®¤è¿”å›å€¼

    Returns:
        (è§£æç»“æœ, é”™è¯¯ä¿¡æ¯) - æˆåŠŸæ—¶é”™è¯¯ä¿¡æ¯ä¸ºNone
    """
    try:
        return response.json(), None
    except json.JSONDecodeError as e:
        error_msg = f"JSONè§£æå¤±è´¥: {e}. å“åº”å†…å®¹: {response.text[:200] if response.text else '(ç©º)'}"
        logger.error(error_msg)
        return default, error_msg
    except Exception as e:
        error_msg = f"è§£æå“åº”æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"
        logger.error(error_msg)
        return default, error_msg


def calculate_retry_delay(attempt: int, initial_delay: float = INITIAL_RETRY_DELAY,
                          max_delay: float = MAX_RETRY_DELAY,
                          backoff_factor: float = RETRY_BACKOFF_FACTOR) -> float:
    """è®¡ç®—æŒ‡æ•°é€€é¿å»¶è¿Ÿæ—¶é—´ï¼ˆå¸¦æŠ–åŠ¨ï¼‰

    Args:
        attempt: å½“å‰é‡è¯•æ¬¡æ•°ï¼ˆä»1å¼€å§‹ï¼‰
        initial_delay: åˆå§‹å»¶è¿Ÿç§’æ•°
        max_delay: æœ€å¤§å»¶è¿Ÿç§’æ•°
        backoff_factor: é€€é¿å› å­

    Returns:
        å»¶è¿Ÿç§’æ•°ï¼ˆåŒ…å«éšæœºæŠ–åŠ¨ï¼‰
    """
    delay = initial_delay * (backoff_factor ** (attempt - 1))
    delay = min(delay, max_delay)
    # æ·»åŠ  Â±25% çš„éšæœºæŠ–åŠ¨
    jitter = delay * 0.25 * (2 * random.random() - 1)
    return delay + jitter


def is_retryable_error(error: Exception) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºå¯é‡è¯•çš„é”™è¯¯

    Args:
        error: å¼‚å¸¸å¯¹è±¡

    Returns:
        Trueè¡¨ç¤ºå¯ä»¥é‡è¯•ï¼ŒFalseè¡¨ç¤ºä¸åº”é‡è¯•
    """
    # è¿æ¥è¶…æ—¶ - å¯é‡è¯•
    if isinstance(error, requests.exceptions.ConnectTimeout):
        return True
    # è¯»å–è¶…æ—¶ - å¯é‡è¯•
    if isinstance(error, requests.exceptions.ReadTimeout):
        return True
    # è¿æ¥é”™è¯¯ï¼ˆä¸åŒ…å«DNSå¤±è´¥ï¼‰- å¯é‡è¯•
    if isinstance(error, requests.exceptions.ConnectionError):
        error_str = str(error).lower()
        # DNSè§£æå¤±è´¥ä¸é‡è¯•
        if 'name or service not known' in error_str or 'getaddrinfo failed' in error_str:
            return False
        return True
    # æœåŠ¡å™¨é”™è¯¯ï¼ˆ5xxï¼‰- é€šè¿‡HTTPçŠ¶æ€ç åˆ¤æ–­ï¼Œè¿™é‡Œä¸å¤„ç†
    return False


def is_retryable_status_code(status_code: int) -> bool:
    """åˆ¤æ–­HTTPçŠ¶æ€ç æ˜¯å¦å¯é‡è¯•

    Args:
        status_code: HTTPçŠ¶æ€ç 

    Returns:
        Trueè¡¨ç¤ºå¯ä»¥é‡è¯•
    """
    # 5xx æœåŠ¡å™¨é”™è¯¯å¯é‡è¯•
    if 500 <= status_code < 600:
        return True
    # 429 Too Many Requests å¯é‡è¯•
    if status_code == 429:
        return True
    return False


def retry_request(request_func, max_attempts: int = MAX_RETRY_ATTEMPTS,
                  description: str = "è¯·æ±‚") -> requests.Response:
    """å¸¦æŒ‡æ•°é€€é¿çš„è¯·æ±‚é‡è¯•åŒ…è£…å™¨

    Args:
        request_func: æ‰§è¡Œè¯·æ±‚çš„å‡½æ•°ï¼Œæ— å‚æ•°
        max_attempts: æœ€å¤§å°è¯•æ¬¡æ•°
        description: è¯·æ±‚æè¿°ï¼Œç”¨äºæ—¥å¿—

    Returns:
        å“åº”å¯¹è±¡

    Raises:
        æœ€åä¸€æ¬¡å¤±è´¥çš„å¼‚å¸¸
    """
    last_error = None

    for attempt in range(1, max_attempts + 1):
        try:
            response = request_func()

            # æ£€æŸ¥HTTPçŠ¶æ€ç æ˜¯å¦éœ€è¦é‡è¯•
            if is_retryable_status_code(response.status_code):
                if attempt < max_attempts:
                    delay = calculate_retry_delay(attempt)
                    logger.warning(f"{description} è¿”å› {response.status_code}ï¼Œç¬¬ {attempt}/{max_attempts} æ¬¡å°è¯•ï¼Œ"
                                   f"{delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    continue

            return response

        except Exception as e:
            last_error = e

            # åˆ¤æ–­æ˜¯å¦å¯é‡è¯•
            if not is_retryable_error(e):
                logger.error(f"{description} å‘ç”Ÿä¸å¯é‡è¯•é”™è¯¯: {e}")
                raise

            if attempt < max_attempts:
                delay = calculate_retry_delay(attempt)
                logger.warning(f"{description} å¤±è´¥: {e}ï¼Œç¬¬ {attempt}/{max_attempts} æ¬¡å°è¯•ï¼Œ"
                               f"{delay:.1f} ç§’åé‡è¯•...")
                time.sleep(delay)
            else:
                logger.error(f"{description} é‡è¯• {max_attempts} æ¬¡å‡å¤±è´¥: {e}")
                raise

    raise last_error


def clean_download_directory(directory: str = DOWNLOAD_DIR, max_age_days: int = 7) -> int:
    """æ¸…ç†ä¸‹è½½ç›®å½•ä¸­çš„æ—§æ–‡ä»¶

    Args:
        directory: ä¸‹è½½ç›®å½•è·¯å¾„
        max_age_days: ä¿ç•™æ–‡ä»¶çš„æœ€å¤§å¤©æ•°

    Returns:
        åˆ é™¤çš„æ–‡ä»¶æ•°é‡
    """
    deleted_count = 0
    try:
        dir_path = Path(directory)
        if not dir_path.exists():
            return 0

        cutoff_time = time.time() - (max_age_days * 24 * 60 * 60)

        for file_path in dir_path.glob('*'):
            if file_path.is_file():
                try:
                    if file_path.stat().st_mtime < cutoff_time:
                        file_path.unlink()
                        deleted_count += 1
                        logger.info(f"å·²åˆ é™¤è¿‡æœŸæ–‡ä»¶: {file_path.name}")
                except Exception as e:
                    logger.warning(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

        if deleted_count > 0:
            logger.info(f"æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {deleted_count} ä¸ªè¿‡æœŸæ–‡ä»¶")
    except Exception as e:
        logger.error(f"æ¸…ç†ä¸‹è½½ç›®å½•å¤±è´¥: {e}")

    return deleted_count


def delete_file_safely(file_path: str) -> bool:
    """å®‰å…¨åˆ é™¤æ–‡ä»¶

    Args:
        file_path: æ–‡ä»¶è·¯å¾„

    Returns:
        æ˜¯å¦åˆ é™¤æˆåŠŸ
    """
    try:
        path = Path(file_path)
        if path.exists():
            path.unlink()
            logger.debug(f"å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {file_path}")
            return True
    except Exception as e:
        logger.warning(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    return False


def validate_excel_file(file_path: str) -> Tuple[bool, Optional[str]]:
    """éªŒè¯Excelæ–‡ä»¶å®Œæ•´æ€§

    Args:
        file_path: Excelæ–‡ä»¶è·¯å¾„

    Returns:
        (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
    """
    try:
        path = Path(file_path)

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not path.exists():
            return False, "æ–‡ä»¶ä¸å­˜åœ¨"

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = path.stat().st_size
        if file_size == 0:
            return False, "æ–‡ä»¶å¤§å°ä¸º0"

        if file_size < 100:  # Excelæ–‡ä»¶è‡³å°‘åº”è¯¥æœ‰å‡ ç™¾å­—èŠ‚
            return False, f"æ–‡ä»¶å¤§å°å¼‚å¸¸: {file_size} bytes"

        # å°è¯•ç”¨pandasæ‰“å¼€éªŒè¯æ ¼å¼
        try:
            df = pd.read_excel(file_path, nrows=1)
            return True, None
        except Exception as e:
            return False, f"Excelæ ¼å¼æ— æ•ˆ: {e}"

    except Exception as e:
        return False, f"éªŒè¯æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}"


def report_auth_invalid(account_name: str) -> bool:
    """ä¸ŠæŠ¥è´¦æˆ·ç™»å½•å¤±æ•ˆçŠ¶æ€åˆ°API

    å½“çŠ¶æ€æ–‡ä»¶ç™»å½•å¤±è´¥ä¸”APIè¿”å›çš„cookieç™»å½•ä¹Ÿå¤±è´¥åè°ƒç”¨æ­¤å‡½æ•°
    """
    print(f"\n{'â”€' * 50}")
    print(f"ğŸ”” ä¸ŠæŠ¥è´¦æˆ·ç™»å½•å¤±æ•ˆçŠ¶æ€...")

    headers = {'Content-Type': 'application/json'}
    json_param = {
        "account": account_name,
        "auth_status": "invalid"
    }
    proxies = {'http': None, 'https': None}

    try:
        response = requests.post(
            AUTH_STATUS_API_URL,
            headers=headers,
            data=json.dumps(json_param),
            proxies=proxies,
            timeout=30
        )
        print(f"   URL: {AUTH_STATUS_API_URL}")
        print(f"   è¯·æ±‚å‚æ•°: {json.dumps(json_param, ensure_ascii=False)}")
        print(f"   HTTPçŠ¶æ€ç : {response.status_code}")
        print(f"   å“åº”å†…å®¹: {response.text[:500] if response.text else '(ç©º)'}")

        if response.status_code == 200:
            print(f"   âœ… è´¦æˆ·å¤±æ•ˆçŠ¶æ€ä¸ŠæŠ¥æˆåŠŸ")
            return True
        else:
            print(f"   âŒ è´¦æˆ·å¤±æ•ˆçŠ¶æ€ä¸ŠæŠ¥å¤±è´¥")
            return False
    except Exception as e:
        print(f"   âŒ è´¦æˆ·å¤±æ•ˆçŠ¶æ€ä¸ŠæŠ¥å¼‚å¸¸: {e}")
        return False


def is_auth_invalid_error(code: int = None, message: str = None) -> bool:
    """æ£€æµ‹APIå“åº”æ˜¯å¦ä¸ºç™»å½•å¤±æ•ˆé”™è¯¯

    åˆ¤æ–­æ¡ä»¶:
    - code == 401
    - code == 606
    - message åŒ…å« "æœªç™»å½•"
    - message åŒ…å« "ç™»å½•çŠ¶æ€å¤±æ•ˆ"
    - message åŒ…å« "è¯·é‡æ–°ç™»å½•"

    Args:
        code: APIè¿”å›çš„çŠ¶æ€ç 
        message: APIè¿”å›çš„æ¶ˆæ¯å†…å®¹

    Returns:
        bool: Trueè¡¨ç¤ºç™»å½•å·²å¤±æ•ˆï¼Œéœ€è¦ä¸ŠæŠ¥
    """
    # æ£€æŸ¥çŠ¶æ€ç 
    if code in [401, 606]:
        return True

    # æ£€æŸ¥æ¶ˆæ¯å†…å®¹
    if message:
        message_str = str(message)
        auth_invalid_keywords = ["æœªç™»å½•", "ç™»å½•çŠ¶æ€å¤±æ•ˆ", "è¯·é‡æ–°ç™»å½•"]
        for keyword in auth_invalid_keywords:
            if keyword in message_str:
                return True

    return False


def handle_auth_invalid(account_name: str, start_date: str, end_date: str,
                        task_name: str, error_message: str) -> None:
    """ç»Ÿä¸€å¤„ç†ç™»å½•å¤±æ•ˆé”™è¯¯

    å¤„ç†æµç¨‹:
    1. è°ƒç”¨ report_auth_invalid() â†’ /api/post/platform_accounts
    2. è°ƒç”¨ log_failure() â†’ /api/log
    3. è°ƒç”¨ upload_task_status_batch() â†’ /api/account_task/update_batch

    Args:
        account_name: è´¦æˆ·åç§°
        start_date: æ•°æ®å¼€å§‹æ—¥æœŸ
        end_date: æ•°æ®ç»“æŸæ—¥æœŸ
        task_name: å½“å‰ä»»åŠ¡åç§°
        error_message: é”™è¯¯ä¿¡æ¯
    """
    print(f"\n{'=' * 60}")
    print(f"ğŸš¨ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆï¼Œå¼€å§‹ä¸ŠæŠ¥åˆ°ä¸‰ä¸ªæ¥å£...")
    print(f"   è´¦æˆ·: {account_name}")
    print(f"   ä»»åŠ¡: {task_name}")
    print(f"   é”™è¯¯: {error_message}")
    print(f"{'=' * 60}")

    # 1. ä¸ŠæŠ¥è´¦æˆ·å¤±æ•ˆçŠ¶æ€åˆ° /api/post/platform_accounts
    report_auth_invalid(account_name)

    # 2. ä¸ŠæŠ¥æ—¥å¿—åˆ° /api/log
    log_failure(account_name, 0, task_name, start_date, end_date, f"ç™»å½•å¤±æ•ˆ: {error_message}")

    # 3. ä¸ŠæŠ¥ä»»åŠ¡çŠ¶æ€åˆ° /api/account_task/update_batch
    # å°†å½“å‰ä»»åŠ¡æ ‡è®°ä¸ºå¤±è´¥ï¼Œå…¶ä»–ä»»åŠ¡æ ‡è®°ä¸ºæœªæ‰§è¡Œ
    task_result = {
        'task_name': task_name,
        'success': False,
        'record_count': 0,
        'error_message': f"ç™»å½•å¤±æ•ˆ: {error_message}"
    }
    upload_task_status_batch(account_name, start_date, end_date, [task_result])

    print(f"\nâœ… ç™»å½•å¤±æ•ˆä¸ŠæŠ¥å®Œæˆ")


class AuthInvalidError(Exception):
    """ç™»å½•å¤±æ•ˆå¼‚å¸¸

    å½“æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆæ—¶æŠ›å‡ºæ­¤å¼‚å¸¸ï¼Œç”¨äºç«‹å³åœæ­¢é‡è¯•å¹¶ç»ˆæ­¢ä»»åŠ¡
    """
    pass


def upload_task_status_batch(account_id: str, start_date: str, end_date: str, results: List[Dict[str, Any]]) -> bool:
    """æ‰¹é‡ä¸ŠæŠ¥æ‰€æœ‰ä»»åŠ¡çŠ¶æ€åˆ°API

    Args:
        account_id: è´¦æˆ·ID
        start_date: æ•°æ®å¼€å§‹æ—¥æœŸ
        end_date: æ•°æ®ç»“æŸæ—¥æœŸ
        results: ä»»åŠ¡æ‰§è¡Œç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« task_name, success, record_count, error_message

    Returns:
        bool: ä¸ŠæŠ¥æ˜¯å¦æˆåŠŸ
    """
    print(f"\n{'â”€' * 50}")
    print(f"ğŸ“¤ æ‰¹é‡ä¸ŠæŠ¥ä»»åŠ¡çŠ¶æ€...")

    # å…¨éƒ¨7ä¸ªä»»åŠ¡çš„åç§°åˆ—è¡¨
    ALL_TASK_NAMES = [
        "store_stats",
        "kewen_daily_report",
        "promotion_daily_report",
        "review_detail_dianping",
        "review_detail_meituan",
        "review_summary_dianping",
        "review_summary_meituan",
    ]

    # æ„å»ºAPIè¯·æ±‚å‚æ•°
    json_param = {
        "account_id": account_id,
        "data_start_date": start_date,
        "data_end_date": end_date,
    }

    # å…ˆç”¨é»˜è®¤å€¼åˆå§‹åŒ–æ‰€æœ‰7ä¸ªä»»åŠ¡çš„çŠ¶æ€ (0=æœªæ‰§è¡Œ)
    for task_name in ALL_TASK_NAMES:
        json_param[f"{task_name}_status"] = 0  # æœªæ‰§è¡Œ
        json_param[f"{task_name}_records"] = 0
        json_param[f"{task_name}_error"] = None

    # ç”¨å®é™…æ‰§è¡Œç»“æœè¦†ç›–
    for result in results:
        task_name = result.get('task_name')
        if task_name not in ALL_TASK_NAMES:
            print(f"   âš ï¸ æœªçŸ¥ä»»åŠ¡åç§°: {task_name}ï¼Œè·³è¿‡")
            continue

        success = result.get('success', False)
        record_count = result.get('record_count', 0)
        error_message = result.get('error_message', 'æ— ')

        # çŠ¶æ€ç : success=True -> 2, success=False -> 3
        status = 2 if success else 3
        # é”™è¯¯ä¿¡æ¯: success=True -> None, success=False -> å®é™…é”™è¯¯ä¿¡æ¯
        error = None if success else error_message

        json_param[f"{task_name}_status"] = status
        json_param[f"{task_name}_records"] = record_count
        json_param[f"{task_name}_error"] = error

    headers = {'Content-Type': 'application/json'}
    proxies = {'http': None, 'https': None}

    print(f"   URL: {TASK_STATUS_BATCH_API_URL}")
    print(f"   è¯·æ±‚å‚æ•°: {json.dumps(json_param, ensure_ascii=False, indent=6)}")

    try:
        response = requests.post(
            TASK_STATUS_BATCH_API_URL,
            headers=headers,
            data=json.dumps(json_param),
            proxies=proxies,
            timeout=30
        )
        print(f"   HTTPçŠ¶æ€ç : {response.status_code}")
        print(f"   å“åº”å†…å®¹: {response.text[:500] if response.text else '(ç©º)'}")

        if response.status_code == 200:
            print(f"   âœ… æ‰¹é‡ä»»åŠ¡çŠ¶æ€ä¸ŠæŠ¥æˆåŠŸ")
            return True
        else:
            print(f"   âŒ æ‰¹é‡ä»»åŠ¡çŠ¶æ€ä¸ŠæŠ¥å¤±è´¥")
            return False
    except Exception as e:
        print(f"   âŒ æ‰¹é‡ä»»åŠ¡çŠ¶æ€ä¸ŠæŠ¥å¼‚å¸¸: {e}")
        return False


def upload_task_status_single(account_id: str, start_date: str, end_date: str, result: Dict[str, Any]) -> bool:
    """å•ç‹¬ä¸ŠæŠ¥å•ä¸ªä»»åŠ¡çŠ¶æ€åˆ°API

    Args:
        account_id: è´¦æˆ·ID
        start_date: æ•°æ®å¼€å§‹æ—¥æœŸ
        end_date: æ•°æ®ç»“æŸæ—¥æœŸ
        result: å•ä¸ªä»»åŠ¡æ‰§è¡Œç»“æœï¼ŒåŒ…å« task_name, success, record_count, error_message

    Returns:
        bool: ä¸ŠæŠ¥æ˜¯å¦æˆåŠŸ
    """
    print(f"\n{'â”€' * 50}")
    print(f"ğŸ“¤ å•ç‹¬ä¸ŠæŠ¥ä»»åŠ¡çŠ¶æ€...")

    task_name = result.get('task_name')
    success = result.get('success', False)
    record_count = result.get('record_count', 0)
    error_message = result.get('error_message', 'æ— ')

    # çŠ¶æ€ç : success=True -> 2, success=False -> 3
    status = 2 if success else 3
    # é”™è¯¯ä¿¡æ¯: success=True -> None, success=False -> å®é™…é”™è¯¯ä¿¡æ¯
    error = None if success else error_message

    json_param = {
        "account_id": account_id,
        "data_start_date": start_date,
        "data_end_date": end_date,
        "task_name": task_name,
        "status": status,
        "record_count": record_count,
        "error_message": error
    }

    headers = {'Content-Type': 'application/json'}
    proxies = {'http': None, 'https': None}

    print(f"   URL: {TASK_STATUS_SINGLE_API_URL}")
    print(f"   è¯·æ±‚å‚æ•°: {json.dumps(json_param, ensure_ascii=False, indent=6)}")

    try:
        response = requests.post(
            TASK_STATUS_SINGLE_API_URL,
            headers=headers,
            data=json.dumps(json_param),
            proxies=proxies,
            timeout=30
        )
        print(f"   HTTPçŠ¶æ€ç : {response.status_code}")
        print(f"   å“åº”å†…å®¹: {response.text[:500] if response.text else '(ç©º)'}")

        if response.status_code == 200:
            print(f"   âœ… å•ä¸ªä»»åŠ¡çŠ¶æ€ä¸ŠæŠ¥æˆåŠŸ")
            return True
        else:
            print(f"   âŒ å•ä¸ªä»»åŠ¡çŠ¶æ€ä¸ŠæŠ¥å¤±è´¥")
            return False
    except Exception as e:
        print(f"   âŒ å•ä¸ªä»»åŠ¡çŠ¶æ€ä¸ŠæŠ¥å¼‚å¸¸: {e}")
        return False


def random_delay(min_seconds: float = 2, max_seconds: float = 5):
    """éšæœºç­‰å¾…æŒ‡å®šèŒƒå›´çš„æ—¶é—´ï¼ˆåçˆ¬è™«æªæ–½ï¼‰

    Args:
        min_seconds: æœ€å°ç­‰å¾…ç§’æ•°ï¼Œé»˜è®¤2ç§’
        max_seconds: æœ€å¤§ç­‰å¾…ç§’æ•°ï¼Œé»˜è®¤5ç§’
    """
    delay = random.uniform(min_seconds, max_seconds)
    print(f"â³ åçˆ¬è™«ç­‰å¾… {delay:.1f} ç§’...")
    time.sleep(delay)


# ============================================================================
# â˜…â˜…â˜… é—¨åº—æƒé™å¤„ç†å‡½æ•° â˜…â˜…â˜…
# ============================================================================
def handle_shop_permission_issue(page) -> bool:
    """å¤„ç†é—¨åº—æƒé™é—®é¢˜ï¼Œåˆ‡æ¢åˆ°å…¨éƒ¨é—¨åº—

    å½“é¡µé¢å‡ºç°"è¯¥é—¨åº—æ— æ­¤åŠŸèƒ½æ“ä½œæƒé™"æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å…¨éƒ¨é—¨åº—

    Args:
        page: Playwright page å¯¹è±¡

    Returns:
        æ˜¯å¦æ£€æµ‹åˆ°å¹¶å¤„ç†äº†æƒé™é—®é¢˜
    """
    try:
        # æ£€æµ‹æ˜¯å¦å‡ºç°"æ— æƒé™"æç¤ºï¼ˆç­‰å¾…2ç§’ï¼‰
        permission_text = page.locator("text=è¯¥é—¨åº—æ— æ­¤åŠŸèƒ½æ“ä½œæƒé™")
        if permission_text.is_visible(timeout=2000):
            logger.warning("æ£€æµ‹åˆ°é—¨åº—æƒé™é—®é¢˜ï¼Œå°è¯•åˆ‡æ¢åˆ°å…¨éƒ¨é—¨åº—...")

            try:
                # ç‚¹å‡»é—¨åº—é€‰æ‹©å™¨å±•å¼€ï¼ˆé€šè¿‡IDå®šä½ï¼‰
                shop_selector = page.locator("#shopName")
                if shop_selector.is_visible(timeout=2000):
                    shop_selector.click()
                    time.sleep(1.5)
                    logger.info("å·²ç‚¹å‡»é—¨åº—é€‰æ‹©å™¨")

                    # ç‚¹å‡»"å…¨éƒ¨é—¨åº—"é€‰é¡¹
                    all_shops = page.locator("text=å…¨éƒ¨é—¨åº—")
                    if all_shops.is_visible(timeout=2000):
                        all_shops.click()
                        time.sleep(2)
                        logger.info("å·²åˆ‡æ¢åˆ°å…¨éƒ¨é—¨åº—")
                        return True
                    else:
                        logger.warning("æœªæ‰¾åˆ°'å…¨éƒ¨é—¨åº—'é€‰é¡¹")
                else:
                    logger.warning("æœªæ‰¾åˆ°é—¨åº—é€‰æ‹©å™¨")
            except Exception as e:
                logger.warning(f"é—¨åº—åˆ‡æ¢æ“ä½œå¤±è´¥: {e}")

            # å³ä½¿åˆ‡æ¢å¤±è´¥ä¹Ÿè¿”å›Trueï¼Œè¡¨ç¤ºæ£€æµ‹åˆ°äº†æƒé™é—®é¢˜
            return True

    except Exception as e:
        # æ²¡æœ‰æ£€æµ‹åˆ°æƒé™é—®é¢˜ï¼Œè¿™æ˜¯æ­£å¸¸æƒ…å†µ
        pass

    return False


# ============================================================================
# â˜…â˜…â˜… é€šç”¨é¡µé¢è·³è½¬å‡½æ•° â˜…â˜…â˜…
# ============================================================================
def navigate_to_url(page, url: str, page_name: str, max_retries: int = 3) -> bool:
    """è·³è½¬åˆ°æŒ‡å®šURL

    Args:
        page: Playwright page å¯¹è±¡
        url: ç›®æ ‡URL
        page_name: é¡µé¢åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

    Returns:
        æ˜¯å¦è·³è½¬æˆåŠŸ
    """
    logger.info(f"æ­£åœ¨è·³è½¬åˆ° [{page_name}]...")
    logger.debug(f"URL: {url[:80]}...")

    for attempt in range(1, max_retries + 1):
        try:
            page.goto(url, wait_until='load', timeout=BROWSER_PAGE_TIMEOUT)

            # é¢å¤–ç­‰å¾…é¡µé¢ç¨³å®š
            wait_time = random.uniform(3, 5)
            logger.debug(f"ç­‰å¾…é¡µé¢ç¨³å®š {wait_time:.1f} ç§’...")
            time.sleep(wait_time)

            # å¤„ç†é—¨åº—æƒé™é—®é¢˜
            handle_shop_permission_issue(page)

            logger.info(f"å·²è·³è½¬åˆ° [{page_name}]")
            return True

        except Exception as e:
            error_str = str(e).lower()
            is_timeout = 'timeout' in error_str

            if is_timeout and attempt < max_retries:
                delay = calculate_retry_delay(attempt)
                logger.warning(f"ç¬¬ {attempt}/{max_retries} æ¬¡è·³è½¬è¶…æ—¶ï¼Œ{delay:.1f} ç§’åé‡è¯•...")
                time.sleep(delay)
            else:
                logger.error(f"è·³è½¬å¤±è´¥: {e}")
                return False

    return False


def load_cookies_from_api(account_name: str) -> Dict[str, Any]:
    """ä»APIåŠ è½½cookieså’Œç›¸å…³ä¿¡æ¯

    ä½¿ç”¨ /api/get_platform_account è·å–è´¦æˆ·ä¿¡æ¯
    """
    print(f"ğŸ” æ­£åœ¨ä»APIè·å–è´¦æˆ· [{account_name}] çš„cookie...")

    session = get_session()
    try:
        response = session.post(
            GET_PLATFORM_ACCOUNT_API_URL,
            headers={'Content-Type': 'application/json'},
            json={"account": account_name},
            timeout=API_TIMEOUT,
            proxies={'http': None, 'https': None}
        )
        response.raise_for_status()

        # å®‰å…¨è§£æJSON
        result, json_error = safe_json_parse(response, {})
        if json_error:
            raise Exception(f"APIå“åº”è§£æå¤±è´¥: {json_error}")

        if not result.get('success'):
            raise Exception(f"APIè¿”å›å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")

        record = result.get('data', {})
        if not record:
            raise Exception(f"æœªæ‰¾åˆ°è´¦æˆ· [{account_name}] çš„cookieæ•°æ®")

        # è§£æcookiesï¼ˆå­—æ®µå: cookieï¼‰
        cookie_data = record.get('cookie')
        if isinstance(cookie_data, str):
            cookies = json.loads(cookie_data)
        else:
            cookies = cookie_data or {}

        # è§£æmtgsig
        mtgsig_data = record.get('mtgsig')
        if isinstance(mtgsig_data, str):
            mtgsig = mtgsig_data
        elif isinstance(mtgsig_data, dict):
            mtgsig = json.dumps(mtgsig_data)
        else:
            mtgsig = None

        # è§£æshop_infoï¼ˆå­—æ®µå: stores_jsonï¼‰
        # ä½¿ç”¨ or [] ç¡®ä¿ null/None ä¹Ÿèƒ½æ­£ç¡®è½¬ä¸ºç©ºåˆ—è¡¨ï¼ˆdict.geté»˜è®¤å€¼ä»…åœ¨keyä¸å­˜åœ¨æ—¶ç”Ÿæ•ˆï¼‰
        shop_info = record.get('stores_json') or []

        # è·å–templates_id
        templates_id = record.get('templates_id')

        # è·å–é—¨åº—å•†åœˆä¿¡æ¯ï¼ˆç”¨äºåŒè¡Œæ’åæ•°æ®ï¼‰
        compare_regions = record.get('compareRegions_json', {})

        # è·å–å›¢è´­IDæ˜ å°„ï¼ˆç”¨äºå¹¿å‘Šå•æ•°æ®ï¼‰
        brands_json = record.get('brands_json', [])

        print(f"âœ… æˆåŠŸåŠ è½½ {len(cookies)} ä¸ªcookies")
        if compare_regions:
            print(f"âœ… æˆåŠŸåŠ è½½ {len(compare_regions)} ä¸ªé—¨åº—å•†åœˆä¿¡æ¯")
        if brands_json:
            print(f"âœ… æˆåŠŸåŠ è½½ {len(brands_json)} ä¸ªå›¢è´­IDæ˜ å°„")

        return {
            'cookies': cookies,
            'mtgsig': mtgsig,
            'shop_info': shop_info,
            'templates_id': templates_id,
            'compare_regions': compare_regions,
            'brands_json': brands_json
        }
    finally:
        session.close()


def get_shop_ids(shop_info) -> List[int]:
    """ä»shop_infoæå–é—¨åº—IDåˆ—è¡¨

    æ”¯æŒä¸¤ç§å­—æ®µåæ ¼å¼ï¼š
    - shop_id: stores_jsonæ ¼å¼ï¼ˆæ¥è‡ªget_platform_accountï¼‰
    - shopId: æ—§æ ¼å¼ï¼ˆå…¼å®¹ï¼‰
    """
    shop_ids = []
    if shop_info:
        if isinstance(shop_info, list):
            for shop in shop_info:
                if isinstance(shop, dict):
                    # ä¼˜å…ˆä½¿ç”¨shop_idï¼Œå…¼å®¹shopId
                    shop_id = shop.get('shop_id') or shop.get('shopId')
                    if shop_id:
                        shop_ids.append(int(shop_id))
        elif isinstance(shop_info, dict):
            shop_id = shop_info.get('shop_id') or shop_info.get('shopId')
            if shop_id:
                shop_ids.append(int(shop_id))
    return shop_ids if shop_ids else [0]


def get_platform_account(account: str) -> Dict[str, Any]:
    """è·å–å¹³å°è´¦æˆ·ä¿¡æ¯

    è°ƒç”¨ /api/get_platform_account è·å–è´¦æˆ·çš„å®Œæ•´ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
    - cookie: ç™»å½•å‡­è¯
    - mtgsig: ç­¾åä¿¡æ¯
    - templates_id: æŠ¥è¡¨æ¨¡æ¿ID
    - stores_json: é—¨åº—ä¿¡æ¯
    - auth_status: ç™»å½•çŠ¶æ€
    ç­‰

    Args:
        account: è´¦æˆ·åç§°ï¼ˆæ‰‹æœºå·ï¼‰

    Returns:
        dict: åŒ…å«è´¦æˆ·å®Œæ•´ä¿¡æ¯çš„å­—å…¸
            - success: æ˜¯å¦æˆåŠŸ
            - data: è´¦æˆ·æ•°æ®ï¼ˆæˆåŠŸæ—¶ï¼‰
            - error_message: é”™è¯¯ä¿¡æ¯ï¼ˆå¤±è´¥æ—¶ï¼‰
    """
    print(f"\n{'â”€' * 50}")
    print(f"ğŸ” è·å–å¹³å°è´¦æˆ·ä¿¡æ¯: {account}")

    headers = {'Content-Type': 'application/json'}
    json_param = {"account": account}
    proxies = {'http': None, 'https': None}

    print(f"   URL: {GET_PLATFORM_ACCOUNT_API_URL}")
    print(f"   è¯·æ±‚å‚æ•°: {json.dumps(json_param, ensure_ascii=False)}")

    try:
        response = requests.post(
            GET_PLATFORM_ACCOUNT_API_URL,
            headers=headers,
            data=json.dumps(json_param),
            proxies=proxies,
            timeout=30
        )
        print(f"   HTTPçŠ¶æ€ç : {response.status_code}")

        if response.status_code == 200:
            result = response.json()
            if result.get('success'):
                data = result.get('data', {})
                templates_id = data.get('templates_id')
                auth_status = data.get('auth_status')
                stores_json = data.get('stores_json', [])

                print(f"   âœ… è·å–æˆåŠŸ")
                print(f"   templates_id: {templates_id}")
                print(f"   auth_status: {auth_status}")
                print(f"   é—¨åº—æ•°é‡: {len(stores_json) if stores_json else 0}")

                return {
                    'success': True,
                    'data': data,
                    'templates_id': templates_id,
                    'auth_status': auth_status,
                    'cookie': data.get('cookie'),
                    'mtgsig': data.get('mtgsig'),
                    'stores_json': stores_json
                }
            else:
                error_msg = result.get('message', 'è·å–è´¦æˆ·ä¿¡æ¯å¤±è´¥')
                print(f"   âŒ APIè¿”å›å¤±è´¥: {error_msg}")
                return {
                    'success': False,
                    'error_message': error_msg
                }
        else:
            error_msg = f"HTTPçŠ¶æ€ç : {response.status_code}"
            print(f"   âŒ è¯·æ±‚å¤±è´¥: {error_msg}")
            return {
                'success': False,
                'error_message': error_msg
            }
    except Exception as e:
        error_msg = f"è¯·æ±‚å¼‚å¸¸: {str(e)}"
        print(f"   âŒ {error_msg}")
        return {
            'success': False,
            'error_message': error_msg
        }


def generate_mtgsig(cookies: dict, mtgsig_from_api: str = None) -> str:
    """ç”Ÿæˆmtgsigç­¾åå‚æ•°

    ä¼˜å…ˆçº§: APIç­¾å > æœ¬åœ°ç”Ÿæˆï¼ˆæ¯æ¬¡ç”Ÿæˆæ–°æ—¶é—´æˆ³ï¼‰
    æ³¨æ„: ä¸å†ä½¿ç”¨å…±äº«ç­¾åï¼Œé¿å…ç­¾åè¿‡æœŸå¯¼è‡´ä»»åŠ¡å¤±è´¥
    """
    # 1. ä¼˜å…ˆä½¿ç”¨APIè¿”å›çš„ç­¾å
    if mtgsig_from_api:
        return mtgsig_from_api

    # 2. æœ¬åœ°ç”Ÿæˆæ–°ç­¾åï¼ˆæ¯æ¬¡ç”Ÿæˆæ–°æ—¶é—´æˆ³ï¼Œç¡®ä¿ç­¾åæœ‰æ•ˆï¼‰
    timestamp = int(time.time() * 1000)
    webdfpid = cookies.get('WEBDFPID', '')
    a3 = webdfpid.split('-')[0] if webdfpid and '-' in webdfpid else '5y24v3837yu856y40w99918z268u6v77801vv1w288197958zzvzwy74'

    mtgsig = {
        "a1": "1.2",
        "a2": timestamp,
        "a3": a3,
        "a5": "jBpEMWibZqnOfn+vAsi8yo/kZpK57yUmniEBsbeugiBk2/5nSVi4jUHwsaXt01Ll43X26NE4uABqljWc7M9e8mkBxcu=",
        "a6": "hs1.6kqTyxwalpmvA3xfWt6C4GOVXV8jTW1AytrgLRPiQXPPO3n3UQFIKWTiDGaeXmDJtn4MQEi7f+BMdUtXeeSaMXW9hYSgOd2UuD/+Lac4sqD5ssj0nZesRyvVbOWEeBmBx",
        "a8": "e64733017f50d5892bacd63100c4099c",
        "a9": "4.1.1,7,205",
        "a10": "31",
        "x0": 4,
        "d1": "c9332725bc86a957c5b3185975b58e79"
    }
    return json.dumps(mtgsig)


# ============================================================================
# â˜…â˜…â˜… æŠ¥è¡¨æ¨¡æ¿IDè·å–/åˆ›å»ºåŠŸèƒ½ â˜…â˜…â˜…
# ============================================================================
def get_template_list(cookies: dict, mtgsig: str = None) -> Dict[str, Any]:
    """è·å–æŠ¥è¡¨æ¨¡æ¿åˆ—è¡¨

    Args:
        cookies: cookieå­—å…¸
        mtgsig: mtgsigç­¾åï¼ˆå¯é€‰ï¼‰

    Returns:
        åŒ…å«æ¨¡æ¿åˆ—è¡¨çš„å­—å…¸
    """
    print(f"\nğŸ“‹ æ­£åœ¨è·å–æŠ¥è¡¨æ¨¡æ¿åˆ—è¡¨...")
    print(f"   APIåœ°å€: {TEMPLATE_LIST_API}")

    session = get_session()

    params = {
        'source': '1',
        'device': 'pc',
        'offset': '0',
        'limit': '19',
        'keyword': '',
        'yodaReady': 'h5',
        'csecplatform': '4',
        'csecversion': '4.1.1',
        'mtgsig': generate_mtgsig(cookies, mtgsig)
    }

    headers = {
        'Accept': 'application/json, text/plain, */*',
        'Accept-Language': 'zh-CN,zh;q=0.9',
        'Content-Type': 'application/json',
        'Referer': 'https://e.dianping.com/',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }

    try:
        response = session.get(
            TEMPLATE_LIST_API,
            params=params,
            headers=headers,
            cookies=cookies,
            timeout=API_TIMEOUT,
            proxies={'http': None, 'https': None}
        )
        response.raise_for_status()
        result = response.json()

        print(f"   APIå“åº”çŠ¶æ€: {response.status_code}")
        print(f"   APIå“åº”ç : {result.get('code')}")

        return result

    except requests.exceptions.RequestException as e:
        print(f"   âŒ è·å–æ¨¡æ¿åˆ—è¡¨å¤±è´¥: {e}")
        return {'code': -1, 'error': str(e)}
    finally:
        session.close()


def find_template_id(cookies: dict, mtgsig: str = None, template_names: List[str] = None) -> Dict[str, Any]:
    """è·å–æŠ¥è¡¨æ¨¡æ¿ID

    ä¼˜å…ˆæŸ¥æ‰¾é¡ºåº:
    1. Kewen_data
    2. hdp-all

    Args:
        cookies: cookieå­—å…¸
        mtgsig: mtgsigç­¾åï¼ˆå¯é€‰ï¼‰
        template_names: è‡ªå®šä¹‰æ¨¡æ¿ååˆ—è¡¨ï¼ˆå¯é€‰ï¼‰

    Returns:
        åŒ…å«template_idå’Œtemplate_nameçš„å­—å…¸
    """
    # é»˜è®¤æŸ¥æ‰¾çš„æ¨¡æ¿åé¡ºåº
    default_names = ['Kewen_data', 'hdp-all']

    if template_names:
        search_names = template_names + default_names
    else:
        search_names = default_names

    print(f"\nğŸ” å¼€å§‹æŸ¥æ‰¾æŠ¥è¡¨æ¨¡æ¿...")
    print(f"   æŸ¥æ‰¾é¡ºåº: {' -> '.join(search_names)}")

    # è·å–æ¨¡æ¿åˆ—è¡¨
    result = get_template_list(cookies, mtgsig)

    if result.get('code') != 200:
        error_msg = f"APIè¿”å›é”™è¯¯ç : {result.get('code')}, æ¶ˆæ¯: {result.get('msg', 'æœªçŸ¥')}"
        print(f"   âŒ {error_msg}")
        return {
            'success': False,
            'template_id': None,
            'template_name': None,
            'all_templates': [],
            'error': error_msg
        }

    data = result.get('data', {})
    template_list = data.get('list', [])

    if not template_list:
        print("   âš ï¸ æœªè·å–åˆ°ä»»ä½•æŠ¥è¡¨æ¨¡æ¿")
        return {
            'success': False,
            'template_id': None,
            'template_name': None,
            'all_templates': [],
            'error': "æœªè·å–åˆ°ä»»ä½•æŠ¥è¡¨æ¨¡æ¿"
        }

    # æ‰“å°æ‰€æœ‰å¯ç”¨æ¨¡æ¿
    print(f"\nğŸ“Š å¯ç”¨çš„æŠ¥è¡¨æ¨¡æ¿åˆ—è¡¨ (å…± {len(template_list)} ä¸ª):")
    print("   " + "-" * 50)
    for idx, template in enumerate(template_list, 1):
        print(f"   {idx:2}. ID: {template.get('id'):15} | åç§°: {template.get('name')}")
    print("   " + "-" * 50)

    # æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾æ¨¡æ¿
    for search_name in search_names:
        for template in template_list:
            if template.get('name') == search_name:
                template_id = template.get('id')
                template_name = template.get('name')
                print(f"\nâœ… æ‰¾åˆ°ç›®æ ‡æ¨¡æ¿!")
                print(f"   æ¨¡æ¿åç§°: {template_name}")
                print(f"   æ¨¡æ¿ID: {template_id}")
                return {
                    'success': True,
                    'template_id': template_id,
                    'template_name': template_name,
                    'all_templates': template_list
                }

    # æœªæ‰¾åˆ°ç›®æ ‡æ¨¡æ¿
    print(f"\nâš ï¸ æœªæ‰¾åˆ°ç›®æ ‡æ¨¡æ¿: {search_names}")
    return {
        'success': False,
        'template_id': None,
        'template_name': None,
        'all_templates': template_list,
        'error': f"æœªæ‰¾åˆ°ä»¥ä¸‹æ¨¡æ¿: {', '.join(search_names)}"
    }


def create_report_template(cookies: dict, mtgsig: str, template_name: str = "Kewen_data") -> Dict[str, Any]:
    """åˆ›å»ºæŠ¥è¡¨æ¨¡æ¿

    Args:
        cookies: cookieå­—å…¸
        mtgsig: mtgsigç­¾å
        template_name: æ¨¡æ¿åç§°ï¼Œé»˜è®¤ä¸º "Kewen_data"

    Returns:
        åŒ…å«åˆ›å»ºç»“æœçš„å­—å…¸
    """
    print(f"\nğŸ“¤ æ­£åœ¨åˆ›å»ºæŠ¥è¡¨æ¨¡æ¿: {template_name}")
    print(f"   APIåœ°å€: {TEMPLATE_SAVE_API}")

    if not mtgsig:
        print("   âŒ åˆ›å»ºæ¨¡æ¿éœ€è¦mtgsigç­¾å")
        return {
            'success': False,
            'template_id': None,
            'template_name': template_name,
            'error': "åˆ›å»ºæ¨¡æ¿éœ€è¦mtgsigç­¾å"
        }

    session = get_session()

    headers = {
        'Accept': 'application/json, text/plain, */*',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Content-Type': 'application/x-www-form-urlencoded',
        'Origin': 'https://h5.dianping.com',
        'Referer': 'https://h5.dianping.com/',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36',
    }

    params = {
        'yodaReady': 'h5',
        'csecplatform': '4',
        'csecversion': '4.1.1',
        'mtgsig': mtgsig
    }

    post_data = {
        'source': '1',
        'device': 'pc',
        'name': template_name,
        'platform': '0',
        'relationObjectIds': '0',
        'compareTypes': '',
        'metricList': TEMPLATE_METRIC_LIST,
        'dateType': 'day',
        'dateSubType': '',
        'statsType': 'shop',
        'summaryType': 'shop'
    }

    try:
        response = session.post(
            TEMPLATE_SAVE_API,
            params=params,
            headers=headers,
            cookies=cookies,
            data=post_data,
            timeout=API_TIMEOUT,
            proxies={'http': None, 'https': None}
        )

        print(f"   HTTPçŠ¶æ€ç : {response.status_code}")
        resp_json = response.json()
        print(f"   å“åº”å†…å®¹: {json.dumps(resp_json, ensure_ascii=False)}")

        if resp_json.get('code') == 200:
            template_id = resp_json.get('data')
            print(f"\nâœ… æŠ¥è¡¨æ¨¡æ¿åˆ›å»ºæˆåŠŸ!")
            print(f"   æ¨¡æ¿ID: {template_id}")
            return {
                'success': True,
                'template_id': template_id,
                'template_name': template_name
            }
        else:
            error_msg = resp_json.get('msg', 'æœªçŸ¥é”™è¯¯')
            print(f"\nâŒ åˆ›å»ºå¤±è´¥: {error_msg}")
            return {
                'success': False,
                'template_id': None,
                'template_name': template_name,
                'error': error_msg
            }

    except requests.exceptions.RequestException as e:
        print(f"\nâŒ åˆ›å»ºæŠ¥è¡¨æ¨¡æ¿è¯·æ±‚å¤±è´¥: {e}")
        return {
            'success': False,
            'template_id': None,
            'template_name': template_name,
            'error': str(e)
        }
    finally:
        session.close()


def update_template_id_to_backend(account_name: str, templates_id: int) -> bool:
    """å°†templates_idå›å†™åˆ°åç«¯æ•°æ®åº“

    åŒæ—¶è°ƒç”¨ä¸¤ä¸ªAPIï¼š
    1. /api/platform-accounts - åŸæœ‰API
    2. /api/cookie_config - æ–°å¢API

    Args:
        account_name: è´¦æˆ·åç§°
        templates_id: æ¨¡æ¿ID

    Returns:
        æ˜¯å¦æ›´æ–°æˆåŠŸï¼ˆä¸¤ä¸ªAPIéƒ½æˆåŠŸæ‰è¿”å›Trueï¼‰
    """
    print(f"\nğŸ“¤ æ­£åœ¨å›å†™ templates_id åˆ°åç«¯...")
    print(f"   è´¦æˆ·: {account_name}")
    print(f"   templates_id: {templates_id}")

    session = get_session()
    success_count = 0

    try:
        # ========== è°ƒç”¨API 1: /api/platform-accounts ==========
        print(f"\n   [1/2] è°ƒç”¨ {PLATFORM_ACCOUNTS_UPDATE_API}")
        try:
            response1 = session.post(
                PLATFORM_ACCOUNTS_UPDATE_API,
                headers={'Content-Type': 'application/json'},
                json={"account": account_name, "templates_id": templates_id},
                timeout=API_TIMEOUT,
                proxies={'http': None, 'https': None}
            )

            print(f"      HTTPçŠ¶æ€ç : {response1.status_code}")
            result1 = response1.json()
            print(f"      å“åº”å†…å®¹: {json.dumps(result1, ensure_ascii=False)}")

            if result1.get('success'):
                affected_rows = result1.get('data', {}).get('affectedRows', 0)
                print(f"      âœ… æˆåŠŸ! å½±å“è¡Œæ•°: {affected_rows}")
                success_count += 1
            else:
                print(f"      âŒ å¤±è´¥: {result1.get('msg', 'æœªçŸ¥é”™è¯¯')}")
        except requests.exceptions.RequestException as e:
            print(f"      âŒ è¯·æ±‚å¤±è´¥: {e}")

        # ========== è°ƒç”¨API 2: /api/up/templates_id ==========
        print(f"\n   [2/2] è°ƒç”¨ {TEMPLATES_ID_UPDATE_API_URL}")
        try:
            response2 = session.post(
                TEMPLATES_ID_UPDATE_API_URL,
                headers={'Content-Type': 'application/json'},
                json={"name": account_name, "templates_id": templates_id},
                timeout=API_TIMEOUT,
                proxies={'http': None, 'https': None}
            )

            print(f"      HTTPçŠ¶æ€ç : {response2.status_code}")
            result2 = response2.json()
            print(f"      å“åº”å†…å®¹: {json.dumps(result2, ensure_ascii=False)}")

            if result2.get('success') or response2.status_code == 200:
                print(f"      âœ… æˆåŠŸ!")
                success_count += 1
            else:
                print(f"      âŒ å¤±è´¥: {result2.get('msg', 'æœªçŸ¥é”™è¯¯')}")
        except requests.exceptions.RequestException as e:
            print(f"      âŒ è¯·æ±‚å¤±è´¥: {e}")

        # æ±‡æ€»ç»“æœ
        if success_count == 2:
            print(f"\nâœ… å›å†™å®Œæˆ! 2ä¸ªAPIå‡æˆåŠŸ")
            return True
        elif success_count == 1:
            print(f"\nâš ï¸ å›å†™éƒ¨åˆ†æˆåŠŸ (1/2)")
            return True  # è‡³å°‘æœ‰ä¸€ä¸ªæˆåŠŸä¹Ÿè¿”å›True
        else:
            print(f"\nâŒ å›å†™å¤±è´¥! 2ä¸ªAPIå‡å¤±è´¥")
            return False

    except Exception as e:
        print(f"âŒ å›å†™è¿‡ç¨‹å¼‚å¸¸: {e}")
        return False
    finally:
        session.close()


def ensure_template_id(account_name: str, cookies: dict, mtgsig: str) -> Optional[int]:
    """ç¡®ä¿è·å–åˆ° templates_id

    é€»è¾‘:
    1. å…ˆå°è¯•ä»æ¨¡æ¿åˆ—è¡¨ä¸­æŸ¥æ‰¾ "Kewen_data" æˆ– "hdp-all"
    2. å¦‚æœæ‰¾ä¸åˆ°ï¼Œåˆ™åˆ›å»ºåä¸º "Kewen_data" çš„æ¨¡æ¿
    3. è·å–åˆ° templates_id åå›å†™åˆ°åç«¯

    Args:
        account_name: è´¦æˆ·åç§°
        cookies: cookieå­—å…¸
        mtgsig: mtgsigç­¾å

    Returns:
        templates_id (int) æˆ– None
    """
    print("\n" + "=" * 60)
    print("ğŸ”§ å¼€å§‹è·å–/åˆ›å»ºæŠ¥è¡¨æ¨¡æ¿ID")
    print("=" * 60)

    # æ­¥éª¤1: å°è¯•æŸ¥æ‰¾å·²æœ‰æ¨¡æ¿
    find_result = find_template_id(cookies, mtgsig)

    if find_result['success']:
        template_id = find_result['template_id']
        print(f"\nâœ… å·²æ‰¾åˆ°ç°æœ‰æ¨¡æ¿ï¼ŒID: {template_id}")

        # å›å†™åˆ°åç«¯
        update_template_id_to_backend(account_name, template_id)

        return template_id

    # æ­¥éª¤2: æœªæ‰¾åˆ°æ¨¡æ¿ï¼Œéœ€è¦åˆ›å»º
    print("\nâš ï¸ æœªæ‰¾åˆ°ç›®æ ‡æ¨¡æ¿ï¼Œå¼€å§‹åˆ›å»ºæ–°æ¨¡æ¿...")
    random_delay(1, 2)

    create_result = create_report_template(cookies, mtgsig, "Kewen_data")

    if create_result['success']:
        template_id = create_result['template_id']
        print(f"\nâœ… æ–°æ¨¡æ¿åˆ›å»ºæˆåŠŸï¼ŒID: {template_id}")

        # å›å†™åˆ°åç«¯
        update_template_id_to_backend(account_name, template_id)

        return template_id

    # åˆ›å»ºä¹Ÿå¤±è´¥äº†
    print("\nâŒ æ— æ³•è·å–æˆ–åˆ›å»ºæŠ¥è¡¨æ¨¡æ¿ID")
    return None


def ensure_template_id_with_browser(account_name: str, cookies: dict,
                                     mtgsig: str, headless: bool = True,
                                     browser_pool: 'BrowserPoolManager' = None) -> Optional[int]:
    """ä½¿ç”¨æµè§ˆå™¨è·å–/åˆ›å»ºæŠ¥è¡¨æ¨¡æ¿ID

    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. æµè§ˆå™¨æ± æ¨¡å¼ï¼šä¼ å…¥ browser_poolï¼Œå¤ç”¨æ± ä¸­çš„ Contextï¼ˆé¿å… Playwright å®ä¾‹å†²çªï¼‰
    2. å•ä»»åŠ¡æ¨¡å¼ï¼šä¸ä¼  browser_poolï¼Œåˆ›å»ºç‹¬ç«‹çš„ Playwright å®ä¾‹

    æµç¨‹ï¼š
    1. è·å–/åˆ›å»ºæµè§ˆå™¨é¡µé¢
    2. æ·»åŠ  cookiesï¼ˆå•ä»»åŠ¡æ¨¡å¼ï¼‰
    3. æ£€æŸ¥ç™»å½•çŠ¶æ€
    4. ç™»å½•æœ‰æ•ˆ â†’ è·³è½¬åˆ°æŠ¥è¡¨ä¸­å¿ƒé¡µé¢
    5. è°ƒç”¨ ensure_template_id() è·å–/åˆ›å»º
    6. å…³é—­æµè§ˆå™¨ï¼ˆå•ä»»åŠ¡æ¨¡å¼ï¼‰
    7. è¿”å› templates_id

    Args:
        account_name: è´¦æˆ·åç§°
        cookies: cookieå­—å…¸
        mtgsig: mtgsigç­¾å
        headless: æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼
        browser_pool: æµè§ˆå™¨æ± ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰

    Returns:
        templates_id (int) æˆ– None
    """
    if not PLAYWRIGHT_AVAILABLE:
        print("âŒ Playwrightæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨æµè§ˆå™¨æ¨¡å¼è·å–æ¨¡æ¿ID")
        return None

    print("\n" + "=" * 60)
    print("ğŸŒ å¯åŠ¨æµè§ˆå™¨è·å–/åˆ›å»ºæŠ¥è¡¨æ¨¡æ¿ID")
    print("=" * 60)

    # æµè§ˆå™¨æ± æ¨¡å¼
    if browser_pool:
        print("   ä½¿ç”¨æµè§ˆå™¨æ± æ¨¡å¼")
        try:
            # ä»æµè§ˆå™¨æ± è·å– Contextï¼ˆå¸¦è‡ªåŠ¨é‡è¿ï¼‰
            wrapper = browser_pool.get_context(account_name, cookies)
            if not wrapper:
                print("âŒ æ— æ³•ä»æµè§ˆå™¨æ± è·å– Context")
                log_failure(account_name, 0, "ensure_template_id", "", "",
                           "æ— æ³•ä»æµè§ˆå™¨æ± è·å– Context")
                return None

            # éªŒè¯ wrapper æœ‰æ•ˆæ€§
            if not wrapper.is_valid():
                print("âŒ è·å–çš„ Context æ— æ•ˆ")
                log_failure(account_name, 0, "ensure_template_id", "", "",
                           "è·å–çš„ Context æ— æ•ˆ")
                # ç§»é™¤æ— æ•ˆçš„ context
                browser_pool.remove_context(account_name)
                return None

            page = wrapper.page

            # ========== æ£€æŸ¥ç™»å½•çŠ¶æ€ ==========
            print(f"\nğŸ” æ£€æŸ¥ç™»å½•çŠ¶æ€...")
            login_check_url = "https://e.dianping.com/app/vg-pc-platform-merchant-selfhelp/newNoticeCenter.html"

            # ä½¿ç”¨å®‰å…¨çš„é¡µé¢è·³è½¬
            if not wrapper.safe_goto(login_check_url, wait_until='domcontentloaded',
                                      timeout=30000, max_retries=2):
                print(f"   âŒ ç™»å½•æ£€æµ‹é¡µé¢è·³è½¬å¤±è´¥")
                log_failure(account_name, 0, "ensure_template_id", "", "",
                           "ç™»å½•æ£€æµ‹é¡µé¢è·³è½¬å¤±è´¥ï¼Œæµè§ˆå™¨å¯èƒ½å·²å…³é—­")
                # ç§»é™¤å¤±æ•ˆçš„ context
                browser_pool.remove_context(account_name)
                return None

            time.sleep(2)

            # æ£€æŸ¥é¡µé¢æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
            try:
                current_url = page.url
            except Exception as e:
                print(f"   âŒ è·å–é¡µé¢URLå¤±è´¥: {e}")
                log_failure(account_name, 0, "ensure_template_id", "", "",
                           f"è·å–é¡µé¢URLå¤±è´¥: {e}")
                browser_pool.remove_context(account_name)
                return None

            if 'login' in current_url.lower():
                print(f"   âŒ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆï¼ˆé‡å®šå‘åˆ°ç™»å½•é¡µï¼‰")
                print(f"   å½“å‰URL: {current_url}")
                report_auth_invalid(account_name)
                return None

            try:
                has_content = page.evaluate("() => document.body.textContent.length > 100")
                if not has_content:
                    print(f"   âŒ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆï¼ˆé¡µé¢å†…å®¹ä¸ºç©ºï¼‰")
                    report_auth_invalid(account_name)
                    return None
            except Exception as e:
                print(f"   âš ï¸ é¡µé¢å†…å®¹æ£€æµ‹å¤±è´¥: {e}")

            print(f"   âœ… ç™»å½•çŠ¶æ€æœ‰æ•ˆ")

            # ========== è·³è½¬åˆ°æŠ¥è¡¨ä¸­å¿ƒé¡µé¢ ==========
            print(f"\nğŸ“ è·³è½¬åˆ°æŠ¥è¡¨ä¸­å¿ƒé¡µé¢...")
            print(f"   URL: {REPORT_CENTER_URL[:80]}...")

            # ä½¿ç”¨å®‰å…¨çš„é¡µé¢è·³è½¬
            if not wrapper.safe_goto(REPORT_CENTER_URL, wait_until='networkidle',
                                      timeout=BROWSER_PAGE_TIMEOUT, max_retries=2):
                print(f"   âŒ æŠ¥è¡¨ä¸­å¿ƒé¡µé¢è·³è½¬å¤±è´¥")
                log_failure(account_name, 0, "ensure_template_id", "", "",
                           "æŠ¥è¡¨ä¸­å¿ƒé¡µé¢è·³è½¬å¤±è´¥")
                return None

            random_delay(2, 3)
            print("   âœ… é¡µé¢åŠ è½½å®Œæˆ")

            # è°ƒç”¨ ensure_template_id è·å–æˆ–åˆ›å»ºæ¨¡æ¿ID
            templates_id = ensure_template_id(account_name, cookies, mtgsig)
            return templates_id

        except Exception as e:
            error_msg = str(e)
            print(f"âŒ æµè§ˆå™¨æ± æ¨¡å¼è·å–æ¨¡æ¿IDå¤±è´¥: {e}")

            # æ£€æµ‹æ˜¯å¦æ˜¯æµè§ˆå™¨å…³é—­é”™è¯¯
            if 'Target' in error_msg and 'closed' in error_msg.lower():
                print("   æ£€æµ‹åˆ°æµè§ˆå™¨å·²å…³é—­ï¼Œç§»é™¤å¤±æ•ˆ Context")
                try:
                    browser_pool.remove_context(account_name)
                except Exception:
                    pass

            # ä¸ŠæŠ¥é”™è¯¯
            log_failure(account_name, 0, "ensure_template_id", "", "",
                       f"æµè§ˆå™¨æ± æ¨¡å¼å¤±è´¥: {error_msg}")

            import traceback
            traceback.print_exc()
            return None

    # å•ä»»åŠ¡æ¨¡å¼ï¼ˆåˆ›å»ºç‹¬ç«‹ Playwright å®ä¾‹ï¼‰
    print("   ä½¿ç”¨å•ä»»åŠ¡æ¨¡å¼")
    playwright = None
    browser = None
    context = None

    try:
        playwright = sync_playwright().start()
        browser = playwright.chromium.launch(headless=headless, proxy=None)

        # è½¬æ¢cookiesä¸ºPlaywrightæ ¼å¼
        playwright_cookies = []
        for name, value in cookies.items():
            playwright_cookies.append({
                'name': name,
                'value': str(value),
                'domain': '.dianping.com',
                'path': '/'
            })

        context = browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            proxy=None,
            bypass_csp=True,
            ignore_https_errors=True
        )
        context.add_cookies(playwright_cookies)
        page = context.new_page()

        # ========== å…ˆæ£€æŸ¥ç™»å½•çŠ¶æ€ ==========
        print(f"\nğŸ” æ£€æŸ¥ç™»å½•çŠ¶æ€...")
        login_check_url = "https://e.dianping.com/app/vg-pc-platform-merchant-selfhelp/newNoticeCenter.html"
        try:
            page.goto(login_check_url, wait_until='domcontentloaded', timeout=30000)
            time.sleep(2)

            current_url = page.url
            # æ£€æŸ¥æ˜¯å¦è¢«é‡å®šå‘åˆ°ç™»å½•é¡µ
            if 'login' in current_url.lower():
                print(f"   âŒ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆï¼ˆé‡å®šå‘åˆ°ç™»å½•é¡µï¼‰")
                print(f"   å½“å‰URL: {current_url}")
                # ä¸ŠæŠ¥ç™»å½•å¤±æ•ˆçŠ¶æ€
                report_auth_invalid(account_name)
                return None

            # æ£€æŸ¥é¡µé¢æ˜¯å¦æœ‰å†…å®¹ï¼ˆé˜²æ­¢ç©ºé¡µé¢ï¼‰
            has_content = page.evaluate("() => document.body.textContent.length > 100")
            if not has_content:
                print(f"   âŒ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆï¼ˆé¡µé¢å†…å®¹ä¸ºç©ºï¼‰")
                # ä¸ŠæŠ¥ç™»å½•å¤±æ•ˆçŠ¶æ€
                report_auth_invalid(account_name)
                return None

            print(f"   âœ… ç™»å½•çŠ¶æ€æœ‰æ•ˆ")

        except Exception as e:
            error_msg = str(e).lower()
            if 'timeout' in error_msg:
                print(f"   âš ï¸ ç™»å½•æ£€æµ‹è¶…æ—¶ï¼Œç»§ç»­å°è¯•...")
            else:
                print(f"   âŒ ç™»å½•æ£€æµ‹å¤±è´¥: {e}")
                # ä¸ŠæŠ¥ç™»å½•å¤±æ•ˆçŠ¶æ€
                report_auth_invalid(account_name)
                return None

        # ========== ç™»å½•æœ‰æ•ˆï¼Œè·³è½¬åˆ°æŠ¥è¡¨ä¸­å¿ƒé¡µé¢ ==========
        print(f"\nğŸ“ è·³è½¬åˆ°æŠ¥è¡¨ä¸­å¿ƒé¡µé¢...")
        print(f"   URL: {REPORT_CENTER_URL[:80]}...")
        page.goto(REPORT_CENTER_URL, wait_until='networkidle', timeout=BROWSER_PAGE_TIMEOUT)
        random_delay(2, 3)
        print("   âœ… é¡µé¢åŠ è½½å®Œæˆ")

        # è°ƒç”¨ ensure_template_id è·å–æˆ–åˆ›å»ºæ¨¡æ¿ID
        templates_id = ensure_template_id(account_name, cookies, mtgsig)

        return templates_id

    except Exception as e:
        print(f"âŒ æµè§ˆå™¨è·å–æ¨¡æ¿IDå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

    finally:
        # å…³é—­æµè§ˆå™¨
        try:
            if context:
                context.close()
            if browser:
                browser.close()
            if playwright:
                playwright.stop()
            print("âœ“ æµè§ˆå™¨å·²å…³é—­")
        except Exception as e:
            print(f"âš ï¸ å…³é—­æµè§ˆå™¨æ—¶å‡ºé”™: {e}")


# ============================================================================
# kewen_daily_report ä»»åŠ¡
# ============================================================================
KEWEN_COLUMN_MAPPING = {
    0: ("report_date", "string"), 1: ("province", "string"), 2: ("city", "string"),
    3: ("shop_id", "number"), 4: ("shop_name", "string"), 5: ("dianping_star", "number"),
    6: ("meituan_star", "number"), 7: ("operation_score", "number"), 8: ("operation_level", "string"),
    9: ("promotion_cost", "number"), 10: ("merchant_cost", "number"), 11: ("platform_service_fee", "number"),
    12: ("commission_gtv", "number"), 13: ("exposure_users", "number"), 14: ("exposure_count", "number"),
    15: ("visit_users", "number"), 16: ("visit_count", "number"), 17: ("exposure_visit_rate", "string"),
    18: ("order_users", "number"), 19: ("lead_users", "number"), 20: ("intent_users", "number"),
    21: ("intent_rate", "string"), 22: ("new_collect_users", "number"), 23: ("total_collect_users", "number"),
    24: ("avg_stay_seconds", "number"), 25: ("promotion_exposure_count", "number"), 26: ("promotion_click_count", "number"),
    27: ("verify_sale_amount", "number"), 28: ("verify_after_discount", "number"), 29: ("verify_coupon_count", "number"),
    30: ("verify_order_count", "number"), 31: ("verify_person_count", "number"), 32: ("verify_new_customer", "number"),
    33: ("order_coupon_count", "number"), 34: ("order_sale_amount", "number"), 35: ("consult_users", "number"),
    36: ("consult_lead_count", "number"), 37: ("consult_lead_rate", "string"), 38: ("avg_response_seconds", "number"),
    39: ("reply_rate_30s", "string"), 40: ("reply_rate_5min", "string"), 41: ("refund_amount", "number"),
    42: ("refund_order_count", "number"), 43: ("refund_users", "number"), 44: ("complaint_count", "number"),
    45: ("compensation_order_count", "number"), 46: ("new_review_count", "number"), 47: ("new_good_review_count", "number"),
    48: ("new_medium_review_count", "number"), 49: ("new_bad_review_count", "number"), 50: ("bad_review_reply_rate", "string"),
    51: ("total_review_count", "number"), 52: ("total_bad_review_count", "number"),
    # ============ æ–°å¢å­—æ®µ: é—¨åº—ä¼˜æƒ ç  (BB-BHåˆ—) ============
    53: ("coupon_code_type", "string"),  # ç ç±»å‹
    54: ("coupon_pay_order_count", "number"),  # æ”¯ä»˜è®¢å•æ•°(ä¸ª)
    55: ("coupon_pay_amount", "number"),  # æ”¯ä»˜é‡‘é¢(å…ƒ)
    56: ("coupon_verify_amount", "number"),  # æ ¸é”€é‡‘é¢(å…ƒ)
    57: ("coupon_scan_users", "number"),  # æ‰«ç äººæ•°(äºº)
    58: ("coupon_scan_collect_count", "number"),  # æ‰«ç æ”¶è—æ•°(ä¸ª)
    59: ("coupon_scan_review_count", "number"),  # æ‰«ç è¯„ä»·æ•°(ä¸ª)
}

KEWEN_STRING_DEFAULTS = {
    "operation_level": "æš‚æ— ", "exposure_visit_rate": "0%", "intent_rate": "0%",
    "consult_lead_rate": "0%", "reply_rate_30s": "0%", "reply_rate_5min": "0%", "bad_review_reply_rate": "0%",
    "coupon_code_type": "",  # é—¨åº—ä¼˜æƒ ç ç±»å‹é»˜è®¤å€¼
}


def kewen_convert_value(value, data_type, field_name):
    """è½¬æ¢å€¼ä¸ºæŒ‡å®šç±»å‹"""
    if value is None or (isinstance(value, float) and math.isnan(value)) or (isinstance(value, str) and value.strip() == ''):
        if data_type == "number":
            return 0
        elif data_type == "string":
            return KEWEN_STRING_DEFAULTS.get(field_name, "")
        return None

    if data_type == "string":
        if hasattr(value, 'strftime'):
            return value.strftime("%Y-%m-%d")
        return str(value).strip()
    elif data_type == "number":
        try:
            if isinstance(value, str):
                value = value.replace(',', '')
            return float(value)
        except:
            return 0
    return value


def kewen_parse_excel_row(row):
    """è§£æExcelè¡Œæ•°æ®"""
    data = {}
    for col_idx, (field_name, data_type) in KEWEN_COLUMN_MAPPING.items():
        if col_idx < len(row):
            value = row.iloc[col_idx]
            converted = kewen_convert_value(value, data_type, field_name)
            if converted is not None:
                data[field_name] = converted
    return data


def kewen_is_empty_row(data):
    """æ£€æŸ¥æ˜¯å¦ä¸ºç©ºè¡Œ"""
    return not data.get('report_date') or data.get('shop_id', 0) == 0 or not data.get('shop_name')


def kewen_is_valid_coupon_type(data):
    """
    æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ä¼˜æƒ ç ç±»å‹ï¼ˆåªä¿ç•™"å…¨éƒ¨ç "ï¼‰

    Args:
        data: è§£æåçš„è¡Œæ•°æ®

    Returns:
        True: æ˜¯"å…¨éƒ¨ç "ï¼Œåº”è¯¥ä¿ç•™
        False: æ˜¯å…¶ä»–ç±»å‹ï¼ˆé—¨åº—ç /å•†å“ç /èŒäººç /å“ç‰Œç ï¼‰ï¼Œåº”è¯¥è·³è¿‡
    """
    coupon_code_type = data.get('coupon_code_type', '')
    return coupon_code_type == 'å…¨éƒ¨ç '


def run_kewen_daily_report(account_name: str, start_date: str, end_date: str, templates_id: Optional[int] = None,
                           cookies: Dict = None, mtgsig: str = None) -> Dict[str, Any]:
    """æ‰§è¡Œkewen_daily_reportä»»åŠ¡

    Args:
        account_name: è´¦æˆ·åç§°
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        templates_id: æŠ¥è¡¨æ¨¡æ¿IDï¼ˆå¯é€‰ï¼Œå¦‚æœä¼ å…¥åˆ™ä¼˜å…ˆä½¿ç”¨ï¼Œä¸å†ä»APIé‡æ–°è·å–ï¼‰
        cookies: å¤–éƒ¨ä¼ å…¥çš„Cookieï¼ˆå¯é€‰ï¼Œé¿å…é‡å¤è°ƒç”¨APIï¼‰
        mtgsig: å¤–éƒ¨ä¼ å…¥çš„ç­¾åï¼ˆå¯é€‰ï¼‰
    """
    table_name = "kewen_daily_report"
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š {table_name}")
    print(f"{'=' * 60}")

    result = {"task_name": table_name, "success": False, "record_count": 0, "error_message": "æ— "}
    session = None
    save_path = None  # ç”¨äºè·Ÿè¸ªä¸‹è½½çš„ä¸´æ—¶æ–‡ä»¶

    try:
        disable_proxy()
        Path(SAVE_DIR).mkdir(parents=True, exist_ok=True)

        # ä¼˜å…ˆä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„æ•°æ®ï¼ˆé¡µé¢é©±åŠ¨æ¨¡å¼ï¼‰
        if cookies and mtgsig:
            print(f"ğŸ“Œ ä½¿ç”¨å…±äº« Cookie/ç­¾åï¼ˆæ— éœ€è°ƒç”¨APIï¼‰")
            shop_info = []  # kewen_daily_report ä¸éœ€è¦ shop_info
        else:
            # æ²¡æœ‰å¤–éƒ¨æ•°æ®ï¼Œä»APIè·å–
            api_data = load_cookies_from_api(account_name)
            cookies = api_data['cookies']
            mtgsig = api_data['mtgsig']
            shop_info = api_data['shop_info']
            if not templates_id:
                templates_id = api_data['templates_id']

        # å¦‚æœå¤–éƒ¨ä¼ å…¥äº† templates_idï¼Œä¼˜å…ˆä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„å€¼
        if templates_id:
            print(f"ğŸ“Œ ä½¿ç”¨ templates_id: {templates_id}")

        if not templates_id:
            raise Exception("æœªè·å–åˆ°æŠ¥è¡¨æ¨¡æ¿ID")

        shop_ids = get_shop_ids(shop_info)

        headers = {
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9',
            'Referer': 'https://e.dianping.com/',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        session = get_session()

        # æŠ¥è¡¨ä¸‹è½½é‡è¯•æœºåˆ¶ï¼ˆä½¿ç”¨æŒ‡æ•°é€€é¿ï¼‰
        file_record = None
        last_error_message = ""

        for retry_attempt in range(1, MAX_RETRY_ATTEMPTS + 1):
            print(f"\nğŸ” æ­£åœ¨è¯·æ±‚ç”ŸæˆæŠ¥è¡¨... (ç¬¬ {retry_attempt}/{MAX_RETRY_ATTEMPTS} æ¬¡å°è¯•)")
            url = "https://e.dianping.com/gateway/adviser/report/template/download"
            params = {
                'source': '1', 'device': 'pc', 'id': templates_id,
                'date': f"{start_date},{end_date}",
                'yodaReady': 'h5', 'csecplatform': '4', 'csecversion': '4.1.1',
                'mtgsig': generate_mtgsig(cookies, mtgsig)
            }
            response = session.get(url, params=params, headers=headers, cookies=cookies, timeout=API_TIMEOUT)

            # å®‰å…¨è§£æJSONå“åº”
            resp_json, json_error = safe_json_parse(response, {})
            if json_error:
                raise Exception(f"APIå“åº”è§£æå¤±è´¥: {json_error}")
            print(f"ğŸ“Š è¯·æ±‚å“åº”: {resp_json}")

            # æ£€æŸ¥æ˜¯å¦ç™»å½•å¤±æ•ˆï¼ˆcode 606 æˆ– message åŒ…å«ç™»å½•å¤±æ•ˆå…³é”®è¯ï¼‰
            resp_code = resp_json.get('code')
            resp_msg = resp_json.get('msg') or resp_json.get('message') or ''
            if is_auth_invalid_error(resp_code, resp_msg):
                error_msg = f"ç™»å½•å¤±æ•ˆ (code={resp_code}, msg={resp_msg})"
                print(f"ğŸš¨ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆ: {error_msg}")
                handle_auth_invalid(account_name, start_date, end_date, table_name, error_msg)
                raise AuthInvalidError(error_msg)

            # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
            result_type = resp_json.get('data', {}).get('resultType')
            result_msg = resp_json.get('data', {}).get('resultMsg', '')
            if result_type == 3:
                # æœåŠ¡å¼‚å¸¸ï¼Œéœ€è¦é‡è¯•ï¼ˆä½¿ç”¨æŒ‡æ•°é€€é¿ï¼‰
                # ä¸Šä¼ å®Œæ•´çš„ç¾å›¢è¿”å›çš„ resultMsgï¼Œè€Œä¸æ˜¯ç®€åŒ–çš„é”™è¯¯ä¿¡æ¯
                if result_msg:
                    last_error_message = f"æœåŠ¡å¼‚å¸¸ (resultType={result_type}): {result_msg}"
                else:
                    last_error_message = f"æœåŠ¡å¼‚å¸¸ (resultType={result_type})"
                print(f"âš ï¸ ç¬¬ {retry_attempt} æ¬¡å°è¯•å¤±è´¥: {last_error_message}")
                if retry_attempt < MAX_RETRY_ATTEMPTS:
                    delay = calculate_retry_delay(retry_attempt)
                    print(f"   ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    continue
                else:
                    raise Exception(f"æŠ¥è¡¨ä¸‹è½½é‡è¯• {MAX_RETRY_ATTEMPTS} æ¬¡å‡å¤±è´¥: {last_error_message}")

            random_delay()  # åçˆ¬è™«ç­‰å¾…

            # ç­‰å¾…æŠ¥è¡¨ç”Ÿæˆ
            print(f"\nâ³ ç­‰å¾…æŠ¥è¡¨ç”Ÿæˆ...")
            date_keyword = f"{start_date.replace('-', '')}-{end_date.replace('-', '')}"

            for _ in range(60):
                time.sleep(2)
                list_url = "https://e.dianping.com/gateway/merchant/downloadcenter/list"
                list_params = {'pageNo': 1, 'pageSize': 20, 'yodaReady': 'h5', 'csecplatform': '4', 'csecversion': '4.1.1', 'mtgsig': generate_mtgsig(cookies, mtgsig)}
                list_resp = session.get(list_url, params=list_params, headers=headers, cookies=cookies, timeout=API_TIMEOUT)

                # å®‰å…¨è§£æJSONå“åº”
                list_data, json_error = safe_json_parse(list_resp, {})
                if json_error:
                    logger.warning(f"ä¸‹è½½åˆ—è¡¨è§£æå¤±è´¥: {json_error}")
                    continue

                # æ£€æŸ¥æ˜¯å¦ç™»å½•å¤±æ•ˆ
                list_code = list_data.get('code')
                list_msg = list_data.get('msg') or list_data.get('message') or ''
                if is_auth_invalid_error(list_code, list_msg):
                    error_msg = f"ç™»å½•å¤±æ•ˆ (code={list_code}, msg={list_msg})"
                    print(f"ğŸš¨ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆ: {error_msg}")
                    handle_auth_invalid(account_name, start_date, end_date, table_name, error_msg)
                    raise AuthInvalidError(error_msg)

                if list_data.get('code') == 200:
                    for record in list_data.get('data', {}).get('records', []):
                        if record.get('recordStatus') == 300 and record.get('downloadable') == "1" and record.get('fileUrl'):
                            if date_keyword in record.get('fileName', ''):
                                file_record = record
                                print(f"   âœ… æ–‡ä»¶å·²å°±ç»ª: {record.get('fileName')}")
                                break
                if file_record:
                    break

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æˆåŠŸç”Ÿæˆ
            if file_record:
                print(f"âœ… ç¬¬ {retry_attempt} æ¬¡å°è¯•æˆåŠŸï¼Œæ–‡ä»¶å·²å°±ç»ª")
                break  # æˆåŠŸè·å–æ–‡ä»¶ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
            else:
                # æ–‡ä»¶æœªç”Ÿæˆï¼Œéœ€è¦é‡è¯•ï¼ˆä½¿ç”¨æŒ‡æ•°é€€é¿ï¼‰
                last_error_message = "æŠ¥è¡¨ç”Ÿæˆè¶…æ—¶ï¼Œæ–‡ä»¶æœªå°±ç»ª"
                print(f"âš ï¸ ç¬¬ {retry_attempt} æ¬¡å°è¯•å¤±è´¥: {last_error_message}")
                if retry_attempt < MAX_RETRY_ATTEMPTS:
                    delay = calculate_retry_delay(retry_attempt)
                    print(f"   ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    continue
                else:
                    raise Exception(f"æŠ¥è¡¨ä¸‹è½½é‡è¯• {MAX_RETRY_ATTEMPTS} æ¬¡å‡å¤±è´¥: {last_error_message}")

        random_delay()  # åçˆ¬è™«ç­‰å¾…

        # ä¸‹è½½æ–‡ä»¶
        file_url = file_record['fileUrl']
        file_name = file_record.get('fileName', f'report_{templates_id}.xlsx')
        save_path = str(Path(SAVE_DIR) / file_name)

        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½æ–‡ä»¶...")
        dl_resp = session.get(file_url, timeout=DOWNLOAD_TIMEOUT, stream=True)
        try:
            with open(save_path, 'wb') as f:
                for chunk in dl_resp.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
        finally:
            dl_resp.close()  # ç¡®ä¿å…³é—­æµå¼å“åº”
        print(f"âœ… æ–‡ä»¶å·²ä¿å­˜åˆ°: {save_path}")

        # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
        is_valid, validation_error = validate_excel_file(save_path)
        if not is_valid:
            raise Exception(f"ä¸‹è½½çš„æ–‡ä»¶æ— æ•ˆ: {validation_error}")

        # è§£æExcel
        print(f"\nğŸ“„ å¼€å§‹è§£æExcelæ–‡ä»¶")
        df = pd.read_excel(save_path, header=None)
        print(f"âœ… è¯»å–æˆåŠŸï¼Œå…± {len(df)} è¡Œï¼Œ{len(df.columns)} åˆ—")
        data_list = []
        skip_count = 0
        coupon_type_skip_count = 0
        for idx in range(2, len(df)):
            row = df.iloc[idx]
            data = kewen_parse_excel_row(row)
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºè¡Œ
            if kewen_is_empty_row(data):
                skip_count += 1
                continue
            # æ£€æŸ¥ä¼˜æƒ ç ç±»å‹ï¼Œåªä¿ç•™"å…¨éƒ¨ç "
            if not kewen_is_valid_coupon_type(data):
                coupon_type_skip_count += 1
                continue
            data_list.append(data)
        print(f"âœ… è§£æå®Œæˆ:")
        print(f"   æœ‰æ•ˆæ•°æ®: {len(data_list)} æ¡ (å…¨éƒ¨ç )")
        print(f"   è·³è¿‡ç©ºè¡Œ: {skip_count} æ¡")
        print(f"   è·³è¿‡å…¶ä»–ç ç±»å‹: {coupon_type_skip_count} æ¡ (é—¨åº—ç /å•†å“ç /èŒäººç /å“ç‰Œç )")

        # ä¸Šä¼ æ•°æ®
        print(f"\nğŸ“¤ å¼€å§‹ä¸Šä¼ æ•°æ®åˆ°: {UPLOAD_APIS[table_name]}")
        success_count = 0
        fail_count = 0
        shop_record_counts = {}

        for idx, data in enumerate(data_list, 1):
            try:
                print(f"\n   [{idx}/{len(data_list)}] ä¸Šä¼ æ•°æ®:")
                print(f"      shop_id={data.get('shop_id')}, report_date={data.get('report_date')}, shop_name={data.get('shop_name')}")
                resp = session.post(UPLOAD_APIS[table_name], json=data, headers={'Content-Type': 'application/json'}, timeout=30)
                print(f"      HTTPçŠ¶æ€ç : {resp.status_code}")
                print(f"      å“åº”: {resp.text[:200] if resp.text else '(ç©º)'}")
                if resp.status_code in [200, 201]:
                    success_count += 1
                    shop_id = int(data.get('shop_id', 0))
                    shop_record_counts[shop_id] = shop_record_counts.get(shop_id, 0) + 1
                    print(f"      âœ… æˆåŠŸ")
                else:
                    fail_count += 1
                    print(f"      âŒ å¤±è´¥")
            except Exception as e:
                fail_count += 1
                print(f"      âŒ å¼‚å¸¸: {e}")

        print(f"\nâœ… ä¸Šä¼ å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}")

        if fail_count == 0:
            result["success"] = True
            result["record_count"] = success_count
            for shop_id, count in shop_record_counts.items():
                log_success(account_name, shop_id, table_name, start_date, end_date, count)
            # ä»»åŠ¡æˆåŠŸååˆ é™¤ä¸´æ—¶æ–‡ä»¶
            if save_path:
                delete_file_safely(save_path)
        else:
            result["error_message"] = f"éƒ¨åˆ†ä¸Šä¼ å¤±è´¥: æˆåŠŸ{success_count}, å¤±è´¥{fail_count}"
            for shop_id in shop_ids:
                log_failure(account_name, shop_id, table_name, start_date, end_date, result["error_message"])

    except AuthInvalidError as e:
        # ç™»å½•å¤±æ•ˆå¼‚å¸¸ - å·²åœ¨æ£€æµ‹æ—¶è°ƒç”¨ handle_auth_invalidï¼Œè¿™é‡Œåªè®°å½•ç»“æœ
        result["error_message"] = str(e)
        print(f"âŒ ç™»å½•å¤±æ•ˆï¼Œä»»åŠ¡ç»ˆæ­¢: {e}")

    except Exception as e:
        result["error_message"] = str(e)
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        log_failure(account_name, 0, table_name, start_date, end_date, str(e))

    finally:
        # ç¡®ä¿å…³é—­Session
        if session:
            session.close()

    return result


# ============================================================================
# promotion_daily_report ä»»åŠ¡
# ============================================================================
def run_promotion_daily_report(account_name: str, start_date: str, end_date: str,
                               cookies: Dict = None, mtgsig: str = None) -> Dict[str, Any]:
    """æ‰§è¡Œpromotion_daily_reportä»»åŠ¡

    Args:
        account_name: è´¦æˆ·åç§°
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        cookies: å¤–éƒ¨ä¼ å…¥çš„Cookieï¼ˆå¯é€‰ï¼Œé¿å…é‡å¤è°ƒç”¨APIï¼‰
        mtgsig: å¤–éƒ¨ä¼ å…¥çš„ç­¾åï¼ˆå¯é€‰ï¼‰
    """
    table_name = "promotion_daily_report"
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š {table_name}")
    print(f"{'=' * 60}")

    result = {"task_name": table_name, "success": False, "record_count": 0, "error_message": "æ— "}
    session = None
    save_path = None  # ç”¨äºè·Ÿè¸ªä¸‹è½½çš„ä¸´æ—¶æ–‡ä»¶

    try:
        disable_proxy()
        Path(SAVE_DIR).mkdir(parents=True, exist_ok=True)

        # ä¼˜å…ˆä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„æ•°æ®ï¼ˆé¡µé¢é©±åŠ¨æ¨¡å¼ï¼‰
        if cookies and mtgsig:
            print(f"ğŸ“Œ ä½¿ç”¨å…±äº« Cookie/ç­¾åï¼ˆæ— éœ€è°ƒç”¨APIï¼‰")
            shop_info = []  # promotion_daily_report ä¸éœ€è¦ shop_info
        else:
            # æ²¡æœ‰å¤–éƒ¨æ•°æ®ï¼Œä»APIè·å–
            api_data = load_cookies_from_api(account_name)
            cookies = api_data['cookies']
            mtgsig = api_data['mtgsig']
            shop_info = api_data['shop_info']
        shop_ids = get_shop_ids(shop_info)
        year = start_date.split('-')[0]

        headers = {
            'Accept': '*/*',
            'Referer': 'https://e.dianping.com/shopdiy-node/report',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'X-Requested-With': 'XMLHttpRequest'
        }

        session = get_session()

        # è¯·æ±‚ä¸‹è½½æŠ¥è¡¨
        print(f"\nğŸ” æ­£åœ¨è¯·æ±‚ç”Ÿæˆé—¨åº—æ•°æ®æŠ¥è¡¨...")
        url = "https://e.dianping.com/shopdiy/report/datareport/pc/ajax/downloadReport"

        begin_dt = datetime.strptime(start_date, '%Y-%m-%d')
        end_dt = datetime.strptime(end_date, '%Y-%m-%d')
        days_diff = (end_dt - begin_dt).days
        compare_end_dt = begin_dt - timedelta(days=1)
        compare_begin_dt = compare_end_dt - timedelta(days=days_diff)

        params = {
            'shopIds': '0', 'launchIds': '0', 'launchPremiumIds': '0', 'planIds': '0',
            'objectUnit': '', 'groupUnit': 'shopId', 'platform': '0',
            'beginDate': start_date, 'endDate': end_date, 'timeUnit': 'day', 'compareEnabled': '0',
            'compareBeginDate': compare_begin_dt.strftime('%Y-%m-%d'),
            'compareEndDate': compare_end_dt.strftime('%Y-%m-%d'),
            'tabIds': 'T30001,T30002,T30003,T30004,T30005,T30048,T30020,T30029,T30006,T30007,T30013,T30014,T30009,T30012,T30011',
            'yodaReady': 'h5', 'csecplatform': '4', 'csecversion': '4.0.4',
            'mtgsig': generate_mtgsig(cookies, mtgsig)
        }

        response = session.get(url, params=params, headers=headers, cookies=cookies, timeout=API_TIMEOUT)
        resp_json, json_error = safe_json_parse(response, {})
        if json_error:
            raise Exception(f"APIå“åº”è§£æå¤±è´¥: {json_error}")
        print(f"ğŸ“Š è¯·æ±‚å“åº”: {resp_json}")

        # æ£€æŸ¥æ˜¯å¦ç™»å½•å¤±æ•ˆï¼ˆcode 401 æˆ– message åŒ…å«ç™»å½•å¤±æ•ˆå…³é”®è¯ï¼‰
        resp_code = resp_json.get('code')
        resp_msg = resp_json.get('msg') or resp_json.get('message') or ''
        if is_auth_invalid_error(resp_code, resp_msg):
            error_msg = f"ç™»å½•å¤±æ•ˆ (code={resp_code}, msg={resp_msg})"
            print(f"ğŸš¨ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆ: {error_msg}")
            handle_auth_invalid(account_name, start_date, end_date, table_name, error_msg)
            raise AuthInvalidError(error_msg)

        random_delay()  # åçˆ¬è™«ç­‰å¾…

        # æ£€æŸ¥æ˜¯å¦ç›´æ¥è¿”å›URL
        file_url = None
        if resp_json.get('code') == 200:
            msg = resp_json.get('msg', {})
            if isinstance(msg, dict) and 'S3Url' in msg:
                s3_url = msg.get('S3Url')
                if isinstance(s3_url, list) and s3_url:
                    file_url = s3_url[0]
                elif isinstance(s3_url, str):
                    file_url = s3_url

        # å¦‚æœæ²¡æœ‰ç›´æ¥è¿”å›URLï¼Œç­‰å¾…ä¸‹è½½å†å²
        if not file_url:
            print(f"\nâ³ ç­‰å¾…æŠ¥è¡¨ç”Ÿæˆ...")
            history_url = "https://e.dianping.com/shopdiy/report/datareport/subAccount/common/queryDownloadHistory"

            for _ in range(60):
                time.sleep(5)
                hist_params = {'types': '3,9,10', 'beginDate': '', 'endDate': '', 'pageNum': 1, 'pageSize': 20,
                               'yodaReady': 'h5', 'csecplatform': '4', 'csecversion': '4.0.4', 'mtgsig': generate_mtgsig(cookies, mtgsig)}
                hist_resp = session.get(history_url, params=hist_params, headers=headers, cookies=cookies, timeout=API_TIMEOUT)
                hist_data, json_error = safe_json_parse(hist_resp, {})
                if json_error:
                    logger.warning(f"ä¸‹è½½å†å²è§£æå¤±è´¥: {json_error}")
                    continue

                # æ£€æŸ¥æ˜¯å¦ç™»å½•å¤±æ•ˆ
                hist_code = hist_data.get('code')
                hist_msg = hist_data.get('msg') or hist_data.get('message') or ''
                if is_auth_invalid_error(hist_code, hist_msg):
                    error_msg = f"ç™»å½•å¤±æ•ˆ (code={hist_code}, msg={hist_msg})"
                    print(f"ğŸš¨ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆ: {error_msg}")
                    handle_auth_invalid(account_name, start_date, end_date, table_name, error_msg)
                    raise AuthInvalidError(error_msg)

                for record in hist_data.get('records', []):
                    if record.get('status') == 2:
                        file_path = record.get('filePath', '')
                        if isinstance(file_path, list) and file_path:
                            file_url = file_path[0]
                        elif isinstance(file_path, str):
                            file_url = file_path
                        if file_url:
                            print(f"   âœ… æŠ¥è¡¨å·²å°±ç»ª")
                            break
                if file_url:
                    break

        if not file_url:
            raise Exception("æŠ¥è¡¨ç”Ÿæˆè¶…æ—¶")

        random_delay()  # åçˆ¬è™«ç­‰å¾…

        # ä¸‹è½½æ–‡ä»¶
        file_name = f'é—¨åº—æŠ¥è¡¨_{start_date.replace("-", "")}_{end_date.replace("-", "")}.xlsx'
        save_path = str(Path(SAVE_DIR) / file_name)

        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½æ–‡ä»¶...")
        dl_resp = session.get(file_url, timeout=DOWNLOAD_TIMEOUT, stream=True)
        try:
            with open(save_path, 'wb') as f:
                for chunk in dl_resp.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
        finally:
            dl_resp.close()  # ç¡®ä¿å…³é—­æµå¼å“åº”
        print(f"âœ… æ–‡ä»¶å·²ä¿å­˜åˆ°: {save_path}")

        # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
        is_valid, validation_error = validate_excel_file(save_path)
        if not is_valid:
            raise Exception(f"ä¸‹è½½çš„æ–‡ä»¶æ— æ•ˆ: {validation_error}")

        # ä¸Šä¼ æ•°æ®
        print(f"\nğŸ“¤ å¼€å§‹ä¸Šä¼ æŠ¥è¡¨æ•°æ®åˆ°: {UPLOAD_APIS[table_name]}")
        df = pd.read_excel(save_path)
        print(f"   Excelè¡Œæ•°: {len(df)}")
        success_count = 0
        fail_count = 0
        shop_ids_uploaded = set()

        def parse_value(val, default=0):
            if pd.isna(val) or val == '/' or val == '-' or val == '':
                return default
            try:
                return float(val) if '.' in str(val) else int(val)
            except:
                return default

        def format_date(date_str):
            if '-' in str(date_str):
                parts = str(date_str).split('-')
                if len(parts) == 2:
                    return f"{year}-{parts[0].zfill(2)}-{parts[1].zfill(2)}"
            return str(date_str)

        for idx, row in df.iterrows():
            try:
                json_param = {
                    "report_date": format_date(row['æ—¥æœŸ']),
                    "shop_id": int(row['é—¨åº—ID']),
                    "shop_name": str(row['æ¨å¹¿é—¨åº—']),
                    "city_name": str(row['é—¨åº—æ‰€åœ¨åŸå¸‚']),
                    "cost": parse_value(row['èŠ±è´¹ï¼ˆå…ƒï¼‰'], 0.0),
                    "exposure_count": parse_value(row['æ›å…‰ï¼ˆæ¬¡ï¼‰']),
                    "click_count": parse_value(row['ç‚¹å‡»ï¼ˆæ¬¡ï¼‰']),
                    "click_avg_price": parse_value(row['ç‚¹å‡»å‡ä»·ï¼ˆå…ƒï¼‰'], 0.0),
                    "shop_view_count": parse_value(row['å•†æˆ·æµè§ˆé‡ï¼ˆæ¬¡ï¼‰']),
                    "coupon_order_count": parse_value(row['ä¼˜æƒ é¢„è®¢è®¢å•é‡ï¼ˆä¸ªï¼‰']),
                    "groupbuy_order_count": parse_value(row['å›¢è´­è®¢å•é‡ï¼ˆä¸ªï¼‰']),
                    "order_count": parse_value(row['è®¢å•é‡ï¼ˆä¸ªï¼‰']),
                    "view_pic_count": parse_value(row['æŸ¥çœ‹å›¾ç‰‡ï¼ˆæ¬¡ï¼‰']),
                    "view_comment_count": parse_value(row['æŸ¥çœ‹è¯„è®ºï¼ˆæ¬¡ï¼‰']),
                    "view_address_count": parse_value(row['æŸ¥çœ‹åœ°å€ï¼ˆæ¬¡ï¼‰']),
                    "view_phone_count": parse_value(row['æŸ¥çœ‹ç”µè¯ï¼ˆæ¬¡ï¼‰']),
                    "view_groupbuy_count": parse_value(row['æŸ¥çœ‹å›¢è´­ï¼ˆæ¬¡ï¼‰']),
                    "collect_count": parse_value(row['æ”¶è—ï¼ˆæ¬¡ï¼‰']),
                    "share_count": parse_value(row['åˆ†äº«ï¼ˆæ¬¡ï¼‰'])
                }
                print(f"\n   [{idx+1}/{len(df)}] ä¸Šä¼ æ•°æ®:")
                print(f"      shop_id={json_param['shop_id']}, report_date={json_param['report_date']}, shop_name={json_param['shop_name']}")
                resp = requests.post(UPLOAD_APIS[table_name], headers={'Content-Type': 'application/json'},
                                     data=json.dumps(json_param), proxies={'http': None, 'https': None})
                print(f"      HTTPçŠ¶æ€ç : {resp.status_code}")
                print(f"      å“åº”: {resp.text[:200] if resp.text else '(ç©º)'}")
                if resp.status_code == 200:
                    success_count += 1
                    shop_ids_uploaded.add(json_param['shop_id'])
                    print(f"      âœ… æˆåŠŸ")
                else:
                    fail_count += 1
                    print(f"      âŒ å¤±è´¥")
            except Exception as e:
                fail_count += 1
                print(f"      âŒ å¼‚å¸¸: {e}")

        print(f"\nâœ… ä¸Šä¼ å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}")

        if fail_count == 0:
            result["success"] = True
            result["record_count"] = success_count
            for shop_id in shop_ids_uploaded:
                log_success(account_name, shop_id, table_name, start_date, end_date, success_count // len(shop_ids_uploaded) if shop_ids_uploaded else success_count)
            # ä»»åŠ¡æˆåŠŸååˆ é™¤ä¸´æ—¶æ–‡ä»¶
            if save_path:
                delete_file_safely(save_path)
        else:
            result["error_message"] = f"éƒ¨åˆ†ä¸Šä¼ å¤±è´¥: æˆåŠŸ{success_count}, å¤±è´¥{fail_count}"
            for shop_id in shop_ids:
                log_failure(account_name, shop_id, table_name, start_date, end_date, result["error_message"])

    except AuthInvalidError as e:
        # ç™»å½•å¤±æ•ˆå¼‚å¸¸ - å·²åœ¨æ£€æµ‹æ—¶è°ƒç”¨ handle_auth_invalidï¼Œè¿™é‡Œåªè®°å½•ç»“æœ
        result["error_message"] = str(e)
        print(f"âŒ ç™»å½•å¤±æ•ˆï¼Œä»»åŠ¡ç»ˆæ­¢: {e}")

    except Exception as e:
        result["error_message"] = str(e)
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        log_failure(account_name, 0, table_name, start_date, end_date, str(e))

    finally:
        # ç¡®ä¿å…³é—­Session
        if session:
            session.close()

    return result


# ============================================================================
# review_detail_dianping ä»»åŠ¡
# ============================================================================
def run_review_detail_dianping(account_name: str, start_date: str, end_date: str,
                               cookies: Dict = None, mtgsig: str = None, shop_info: List = None) -> Dict[str, Any]:
    """æ‰§è¡Œreview_detail_dianpingä»»åŠ¡

    Args:
        account_name: è´¦æˆ·åç§°
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        cookies: å¤–éƒ¨ä¼ å…¥çš„Cookieï¼ˆå¯é€‰ï¼Œé¿å…é‡å¤è°ƒç”¨APIï¼‰
        mtgsig: å¤–éƒ¨ä¼ å…¥çš„ç­¾åï¼ˆå¯é€‰ï¼‰
        shop_info: å¤–éƒ¨ä¼ å…¥çš„é—¨åº—ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    """
    table_name = "review_detail_dianping"
    print(f"\n{'=' * 60}")
    print(f"ğŸ’¬ {table_name}")
    print(f"{'=' * 60}")

    result = {"task_name": table_name, "success": False, "record_count": 0, "error_message": "æ— "}

    try:
        disable_proxy()

        # ä¼˜å…ˆä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„æ•°æ®ï¼ˆé¡µé¢é©±åŠ¨æ¨¡å¼ï¼‰
        if cookies and mtgsig:
            print(f"ğŸ“Œ ä½¿ç”¨å…±äº« Cookie/ç­¾åï¼ˆæ— éœ€è°ƒç”¨APIï¼‰")
            if not shop_info:
                shop_info = []
        else:
            # æ²¡æœ‰å¤–éƒ¨æ•°æ®ï¼Œä»APIè·å–
            api_data = load_cookies_from_api(account_name)
            cookies = api_data['cookies']
            mtgsig = api_data['mtgsig']
            shop_info = api_data['shop_info']
        shop_ids = get_shop_ids(shop_info)

        headers = {
            'Accept': 'application/json, text/plain, */*',
            'Referer': 'https://e.dianping.com/vg-platform-reviewmanage/shop-comment-dp/index.html',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        session = get_session()

        def timestamp_to_datetime(ts, default="1997-12-08 00:00:00"):
            if not ts or ts == 0:
                return default
            try:
                return datetime.fromtimestamp(ts / 1000).strftime('%Y-%m-%d %H:%M:%S')
            except:
                return default

        def safe_int(val, default=0):
            if val is None or val == '':
                return default
            try:
                return int(val)
            except:
                return default

        def safe_float(val, default=0.0):
            if val is None or val == '':
                return default
            try:
                return float(val)
            except:
                return default

        def safe_str(val, default=''):
            return str(val) if val is not None else default

        def get_review_shop_id(review):
            """
            è·å–æ­£ç¡®çš„ shop_id
            ä¼˜å…ˆçº§: shopIdStr > shopIdLong > shopId
            APIçš„shopIdå­—æ®µåœ¨IDè¶…è¿‡int32èŒƒå›´æ—¶ä¼šæº¢å‡ºä¸º0
            """
            # 1. ä¼˜å…ˆä½¿ç”¨ shopIdStrï¼ˆå­—ç¬¦ä¸²ï¼Œæœ€å®‰å…¨ï¼‰
            shop_id_str = review.get('shopIdStr')
            if shop_id_str and str(shop_id_str) != '0':
                return str(shop_id_str)

            # 2. å…¶æ¬¡ä½¿ç”¨ shopIdLongï¼ˆé•¿æ•´å‹ï¼‰
            shop_id_long = review.get('shopIdLong')
            if shop_id_long and shop_id_long != 0:
                return str(shop_id_long)

            # 3. æœ€åä½¿ç”¨ shopIdï¼ˆå¯èƒ½æº¢å‡ºä¸º0ï¼‰
            shop_id = review.get('shopId')
            if shop_id and shop_id != 0:
                return str(shop_id)

            # 4. éƒ½æ²¡æœ‰ï¼Œè¿”å› "0"
            return "0"

        all_reviews = []
        upload_stats = {"success": 0, "failed": 0}
        shop_ids_found = set()
        page_no = 1

        while True:
            print(f"\nğŸ“¡ è·å–ç‚¹è¯„è¯„ä»·æ•°æ® ç¬¬{page_no}é¡µ...")
            url = "https://e.dianping.com/review/app/index/ajax/pcreview/listV2"
            params = {
                'platform': 0, 'shopIdStr': '0', 'tagId': 0,
                'startDate': start_date, 'endDate': end_date,
                'pageNo': page_no, 'pageSize': 50, 'referType': 0, 'category': 0,
                'yodaReady': 'h5', 'csecplatform': '4', 'csecversion': '4.1.1',
                'mtgsig': generate_mtgsig(cookies, mtgsig)
            }
            print(f"   è¯·æ±‚å‚æ•°: platform=0, startDate={start_date}, endDate={end_date}")

            resp = session.get(url, params=params, headers=headers, cookies=cookies, timeout=60, proxies={'http': None, 'https': None})
            resp_json = resp.json()

            print(f"   APIå“åº”ç : {resp_json.get('code')}")

            # æ£€æŸ¥æ˜¯å¦ç™»å½•å¤±æ•ˆ
            resp_code = resp_json.get('code')
            resp_msg = resp_json.get('msg') or resp_json.get('message') or ''
            if is_auth_invalid_error(resp_code, resp_msg):
                error_msg = f"ç™»å½•å¤±æ•ˆ (code={resp_code}, msg={resp_msg})"
                print(f"ğŸš¨ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆ: {error_msg}")
                handle_auth_invalid(account_name, start_date, end_date, table_name, error_msg)
                raise AuthInvalidError(error_msg)

            if resp_json.get('code') != 200:
                print(f"   âŒ APIè¿”å›é”™è¯¯: {resp_json}")
                break

            msg_data = resp_json.get('msg', {})
            reviews = msg_data.get('reviewDetailDTOs', [])
            total = msg_data.get('totalReivewNum', 0)

            print(f"   è·å–åˆ° {len(reviews)} æ¡, æ€»æ•° {total}")
            if not reviews:
                print(f"   âš ï¸ è¯¥æ—¥æœŸèŒƒå›´å†…æ²¡æœ‰ç‚¹è¯„è¯„ä»·æ•°æ®")
                break

            for review in reviews:
                # è·å–æ­£ç¡®çš„ shop_idï¼ˆå­—ç¬¦ä¸²æ ¼å¼ï¼Œå¤„ç†å¤§æ•´æ•°æº¢å‡ºé—®é¢˜ï¼‰
                # ä¼˜å…ˆçº§: shopIdStr > shopIdLong > shopId
                shop_id = get_review_shop_id(review)
                if shop_id and shop_id != "0":
                    try:
                        shop_ids_found.add(int(shop_id))
                    except ValueError:
                        pass

                # æ˜ å°„æ•°æ®
                star_raw = safe_int(review.get('star'), 0)
                add_time = timestamp_to_datetime(review.get('addTime'))
                update_time = timestamp_to_datetime(review.get('updateTime'), add_time)
                edit_time = timestamp_to_datetime(review.get('editTime'), "1997-12-08 00:00:00")
                score_map = review.get('scoreMap', {}) or {}
                pic_info = review.get('picInfo', []) or []
                video_info = review.get('videoInfo', []) or []
                reply_list = review.get('reviewFollowNoteDtoList', []) or []

                shop_reply = ""
                shop_reply_time = "1997-12-08 00:00:00"
                reply_list_formatted = []
                for reply in reply_list:
                    reply_content = safe_str(reply.get('noteBody', ''))
                    reply_time_str = timestamp_to_datetime(reply.get('addDate', 0), "1997-12-08 00:00:00")
                    reply_list_formatted.append({"reply_time": reply_time_str, "reply_content": reply_content})
                    if not shop_reply:
                        shop_reply = reply_content
                        shop_reply_time = reply_time_str

                upload_data = {
                    "review_id": safe_str(review.get('reviewId'), f"DP_{int(time.time())}"),
                    "shop_id": shop_id,
                    "shop_name": safe_str(review.get('shopName'), 'æœªçŸ¥é—¨åº—'),
                    "city_name": safe_str(review.get('cityName'), 'æœªçŸ¥'),
                    "city_id": safe_int(review.get('cityId'), 0),
                    "user_id": safe_str(review.get('userId'), '0'),
                    "user_nickname": safe_str(review.get('userNickName'), 'åŒ¿åç”¨æˆ·'),
                    "user_face": safe_str(review.get('userFace'), ''),
                    "user_power": safe_str(review.get('userPower'), '') or 'æ™®é€šç”¨æˆ·',
                    "vip_level": safe_int(review.get('vipLevel'), 0),
                    "add_time": add_time,
                    "update_time": update_time,
                    "edit_time": edit_time,
                    "star": star_raw,
                    "star_display": star_raw // 10 if star_raw else 0,
                    "accurate_star": safe_int(review.get('accurateStar'), star_raw),
                    "content": safe_str(review.get('content'), '') or 'æ— ',
                    "score_technician": safe_float(score_map.get('æŠ€å¸ˆ', 0)),
                    "score_service": safe_float(score_map.get('æœåŠ¡', 0)),
                    "score_environment": safe_float(score_map.get('ç¯å¢ƒ', 0)),
                    "score_map": json.dumps(score_map, ensure_ascii=False),
                    "pic_count": len(pic_info),
                    "video_count": len(video_info),
                    "pic_info": json.dumps(pic_info, ensure_ascii=False),
                    "video_info": json.dumps(video_info, ensure_ascii=False),
                    "shop_reply": shop_reply or 'æš‚æ— å›å¤',
                    "shop_reply_time": shop_reply_time,
                    "is_reply_with_photo": safe_int(review.get('isReplyWithPhoto'), 0),
                    "reply_list": json.dumps(reply_list_formatted, ensure_ascii=False),
                    "order_id": safe_int(review.get('orderId'), 0),
                    "deal_group_id": safe_int(review.get('dealGroupId'), 0),
                    "refer_type": safe_int(review.get('referType'), 0),
                    "avg_price": safe_float(review.get('avgPrice'), 0),
                    "serial_numbers": safe_str(review.get('serialNumbers'), '') or 'æ— ',
                    "total_cost": safe_float(review.get('totalCost'), 0),
                    "consume_date": review.get('consumeDate') or "1997-12-08",
                    "status": safe_int(review.get('status'), 1),
                    "quality_score": safe_int(review.get('qualityScore'), 0),
                    "case_status": safe_int(review.get('caseStatus'), 0),
                    "case_status_desc": safe_str(review.get('caseStatusDesc'), ''),
                    "report_status": safe_int(review.get('reportStatus'), 0),
                    "report_status_desc": safe_str(review.get('reportStatusDesc'), '') or 'æ— ',
                    "case_id": safe_int(review.get('caseId'), 0),
                    "show_deal": 1 if review.get('showDeal', True) else 0,
                    "raw_data": json.dumps(review, ensure_ascii=False)
                }

                try:
                    print(f"\n      ä¸Šä¼ ç‚¹è¯„è¯„ä»· review_id={upload_data.get('review_id')}, shop_id={upload_data.get('shop_id')}")
                    print(f"         user_nickname={upload_data.get('user_nickname')}, content={upload_data.get('content', '')[:50]}...")
                    upload_resp = session.post(UPLOAD_APIS[table_name], headers={'Content-Type': 'application/json'},
                                               json=upload_data, timeout=30, proxies={'http': None, 'https': None})
                    print(f"         HTTPçŠ¶æ€ç : {upload_resp.status_code}")
                    print(f"         å“åº”: {upload_resp.text[:200] if upload_resp.text else '(ç©º)'}")
                    if upload_resp.status_code == 200:
                        upload_stats["success"] += 1
                        print(f"         âœ… æˆåŠŸ")
                    else:
                        upload_stats["failed"] += 1
                        print(f"         âŒ å¤±è´¥")
                        print(f"         åŸå§‹æ•°æ®: {json.dumps(review, ensure_ascii=False)[:500]}")
                except Exception as e:
                    upload_stats["failed"] += 1
                    print(f"         âŒ å¼‚å¸¸: {e}")
                    print(f"         åŸå§‹æ•°æ®: {json.dumps(review, ensure_ascii=False)[:500]}")
                time.sleep(0.3)

            all_reviews.extend(reviews)
            if len(all_reviews) >= total:
                break
            page_no += 1
            random_delay()  # åçˆ¬è™«ç­‰å¾…

        print(f"\nğŸ“Š ç‚¹è¯„è¯„ä»·å®Œæˆ: è·å– {len(all_reviews)} æ¡, ä¸Šä¼ æˆåŠŸ {upload_stats['success']}, å¤±è´¥ {upload_stats['failed']}")

        if upload_stats["failed"] == 0:
            result["success"] = True
            result["record_count"] = upload_stats["success"]
            for shop_id in (shop_ids_found or shop_ids):
                log_success(account_name, shop_id, table_name, start_date, end_date, upload_stats["success"])
        else:
            result["error_message"] = f"éƒ¨åˆ†ä¸Šä¼ å¤±è´¥: æˆåŠŸ{upload_stats['success']}, å¤±è´¥{upload_stats['failed']}"
            for shop_id in shop_ids:
                log_failure(account_name, shop_id, table_name, start_date, end_date, result["error_message"])

    except AuthInvalidError as e:
        # ç™»å½•å¤±æ•ˆå¼‚å¸¸ - å·²åœ¨æ£€æµ‹æ—¶è°ƒç”¨ handle_auth_invalidï¼Œè¿™é‡Œåªè®°å½•ç»“æœ
        result["error_message"] = str(e)
        print(f"âŒ ç™»å½•å¤±æ•ˆï¼Œä»»åŠ¡ç»ˆæ­¢: {e}")

    except Exception as e:
        result["error_message"] = str(e)
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        log_failure(account_name, 0, table_name, start_date, end_date, str(e))

    return result


# ============================================================================
# review_detail_meituan ä»»åŠ¡
# ============================================================================
def run_review_detail_meituan(account_name: str, start_date: str, end_date: str,
                              cookies: Dict = None, mtgsig: str = None, shop_info: List = None) -> Dict[str, Any]:
    """æ‰§è¡Œreview_detail_meituanä»»åŠ¡

    Args:
        account_name: è´¦æˆ·åç§°
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        cookies: å¤–éƒ¨ä¼ å…¥çš„Cookieï¼ˆå¯é€‰ï¼Œé¿å…é‡å¤è°ƒç”¨APIï¼‰
        mtgsig: å¤–éƒ¨ä¼ å…¥çš„ç­¾åï¼ˆå¯é€‰ï¼‰
        shop_info: å¤–éƒ¨ä¼ å…¥çš„é—¨åº—ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    """
    table_name = "review_detail_meituan"
    print(f"\n{'=' * 60}")
    print(f"ğŸ” {table_name}")
    print(f"{'=' * 60}")

    result = {"task_name": table_name, "success": False, "record_count": 0, "error_message": "æ— "}

    try:
        disable_proxy()

        # ä¼˜å…ˆä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„æ•°æ®ï¼ˆé¡µé¢é©±åŠ¨æ¨¡å¼ï¼‰
        if cookies and mtgsig:
            print(f"ğŸ“Œ ä½¿ç”¨å…±äº« Cookie/ç­¾åï¼ˆæ— éœ€è°ƒç”¨APIï¼‰")
            if not shop_info:
                shop_info = []
        else:
            # æ²¡æœ‰å¤–éƒ¨æ•°æ®ï¼Œä»APIè·å–
            api_data = load_cookies_from_api(account_name)
            cookies = api_data['cookies']
            mtgsig = api_data['mtgsig']
            shop_info = api_data['shop_info']
        shop_ids = get_shop_ids(shop_info)

        headers = {
            'Accept': 'application/json, text/plain, */*',
            'Referer': 'https://e.dianping.com/vg-platform-reviewmanage/shop-comment-mt/index.html',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        session = get_session()

        def timestamp_to_datetime(ts, default="1997-12-08 00:00:00"):
            if not ts or ts == 0:
                return default
            try:
                return datetime.fromtimestamp(ts / 1000).strftime('%Y-%m-%d %H:%M:%S')
            except:
                return default

        def safe_int(val, default=0):
            if val is None or val == '':
                return default
            try:
                return int(val)
            except:
                return default

        def safe_float(val, default=0.0):
            if val is None or val == '':
                return default
            try:
                return float(val)
            except:
                return default

        def safe_str(val, default=''):
            return str(val) if val is not None else default

        def extract_order_info(order_info_list, field_id, default=''):
            if not order_info_list:
                return default
            for item in order_info_list:
                if item.get('id') == field_id:
                    return safe_str(item.get('content'), default)
            return default

        def get_review_shop_id(review):
            """
            è·å–æ­£ç¡®çš„ shop_id
            ä¼˜å…ˆçº§: shopIdStr > shopIdLong > shopId
            APIçš„shopIdå­—æ®µåœ¨IDè¶…è¿‡int32èŒƒå›´æ—¶ä¼šæº¢å‡ºä¸º0
            """
            # 1. ä¼˜å…ˆä½¿ç”¨ shopIdStrï¼ˆå­—ç¬¦ä¸²ï¼Œæœ€å®‰å…¨ï¼‰
            shop_id_str = review.get('shopIdStr')
            if shop_id_str and str(shop_id_str) != '0':
                return str(shop_id_str)

            # 2. å…¶æ¬¡ä½¿ç”¨ shopIdLongï¼ˆé•¿æ•´å‹ï¼‰
            shop_id_long = review.get('shopIdLong')
            if shop_id_long and shop_id_long != 0:
                return str(shop_id_long)

            # 3. æœ€åä½¿ç”¨ shopIdï¼ˆå¯èƒ½æº¢å‡ºä¸º0ï¼‰
            shop_id = review.get('shopId')
            if shop_id and shop_id != 0:
                return str(shop_id)

            # 4. éƒ½æ²¡æœ‰ï¼Œè¿”å› "0"
            return "0"

        all_reviews = []
        upload_stats = {"success": 0, "failed": 0}
        shop_ids_found = set()
        page_no = 1

        while True:
            print(f"\nğŸ“¡ è·å–ç¾å›¢è¯„ä»·æ•°æ® ç¬¬{page_no}é¡µ...")
            url = "https://e.dianping.com/review/app/index/ajax/pcreview/listV2"
            params = {
                'platform': 1, 'shopIdStr': '0', 'tagId': 0,
                'startDate': start_date, 'endDate': end_date,
                'pageNo': page_no, 'pageSize': 50, 'referType': 0, 'category': 0,
                'yodaReady': 'h5', 'csecplatform': '4', 'csecversion': '4.1.1',
                'mtgsig': generate_mtgsig(cookies, mtgsig)
            }
            print(f"   è¯·æ±‚å‚æ•°: platform=1, startDate={start_date}, endDate={end_date}")

            resp = session.get(url, params=params, headers=headers, cookies=cookies, timeout=60, proxies={'http': None, 'https': None})
            resp_json = resp.json()

            print(f"   APIå“åº”ç : {resp_json.get('code')}")

            # æ£€æŸ¥æ˜¯å¦ç™»å½•å¤±æ•ˆ
            resp_code = resp_json.get('code')
            resp_msg = resp_json.get('msg') or resp_json.get('message') or ''
            if is_auth_invalid_error(resp_code, resp_msg):
                error_msg = f"ç™»å½•å¤±æ•ˆ (code={resp_code}, msg={resp_msg})"
                print(f"ğŸš¨ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆ: {error_msg}")
                handle_auth_invalid(account_name, start_date, end_date, table_name, error_msg)
                raise AuthInvalidError(error_msg)

            if resp_json.get('code') != 200:
                print(f"   âŒ APIè¿”å›é”™è¯¯: {resp_json}")
                break

            msg_data = resp_json.get('msg', {})
            reviews = msg_data.get('reviewDetailDTOs', [])
            total = msg_data.get('totalReivewNum', 0)

            print(f"   è·å–åˆ° {len(reviews)} æ¡, æ€»æ•° {total}")
            if not reviews:
                print(f"   âš ï¸ è¯¥æ—¥æœŸèŒƒå›´å†…æ²¡æœ‰ç¾å›¢è¯„ä»·æ•°æ®")
                break

            for review in reviews:
                # è·å–æ­£ç¡®çš„ shop_idï¼ˆå­—ç¬¦ä¸²æ ¼å¼ï¼Œå¤„ç†å¤§æ•´æ•°æº¢å‡ºé—®é¢˜ï¼‰
                # ä¼˜å…ˆçº§: shopIdStr > shopIdLong > shopId
                shop_id = get_review_shop_id(review)
                if shop_id and shop_id != "0":
                    try:
                        shop_ids_found.add(int(shop_id))
                    except ValueError:
                        pass

                star_raw = safe_int(review.get('star'), 0)
                add_time = timestamp_to_datetime(review.get('addTime'))
                update_time = timestamp_to_datetime(review.get('updateTime'), add_time)
                edit_time = timestamp_to_datetime(review.get('editTime'), "1997-12-08 00:00:00")
                pic_info = review.get('picInfo', []) or []
                video_info = review.get('videoInfo', []) or []
                shop_reply = safe_str(review.get('shopReply'), '') or 'æš‚æ— å›å¤'
                shop_reply_time = timestamp_to_datetime(review.get('shopReplyTime'), "1997-12-08 00:00:00")

                reply_list_formatted = []
                if review.get('shopReply'):
                    reply_list_formatted.append({"reply_time": shop_reply_time, "reply_content": review.get('shopReply')})

                order_info_list = review.get('orderInfoDTOList', [])
                business_type = extract_order_info(order_info_list, 9, 'æ— ')
                coupon_code = extract_order_info(order_info_list, 1, 'æ— ')
                product_name = extract_order_info(order_info_list, 2, 'æ— ')
                order_time = extract_order_info(order_info_list, 3, '1997-12-08').strip()
                consume_time = extract_order_info(order_info_list, 4, '1997-12-08').strip()
                quantity = safe_int(extract_order_info(order_info_list, 5, '0'), 0)
                price = safe_float(extract_order_info(order_info_list, 6, '0'), 0)

                upload_data = {
                    "review_id": safe_str(review.get('reviewId'), f"MT_{int(time.time())}"),
                    "feedback_id": safe_int(review.get('feedbackId'), 0),
                    "shop_id": shop_id,
                    "shop_name": safe_str(review.get('shopName'), 'æœªçŸ¥é—¨åº—'),
                    "city_name": safe_str(review.get('cityName'), 'æœªçŸ¥'),
                    "city_id": safe_int(review.get('cityId'), 0),
                    "user_id": safe_str(review.get('userId'), '0'),
                    "user_nickname": safe_str(review.get('userNickName'), 'åŒ¿åç”¨æˆ·'),
                    "user_face": safe_str(review.get('userFace'), ''),
                    "user_power": safe_str(review.get('userPower'), '') or 'æ™®é€šç”¨æˆ·',
                    "anonymous": 1 if review.get('anonymous', False) else 0,
                    "add_time": add_time,
                    "update_time": update_time,
                    "edit_time": edit_time,
                    "star": star_raw,
                    "star_display": star_raw // 10 if star_raw else 0,
                    "accurate_star": safe_int(review.get('accurateStar'), star_raw),
                    "content": safe_str(review.get('content'), '') or 'æ— ',
                    "pic_count": len(pic_info),
                    "video_count": len(video_info),
                    "pic_info": json.dumps(pic_info, ensure_ascii=False),
                    "video_info": json.dumps(video_info, ensure_ascii=False),
                    "shop_reply": shop_reply,
                    "shop_reply_time": shop_reply_time,
                    "reply_list": json.dumps(reply_list_formatted, ensure_ascii=False),
                    "order_id": safe_int(review.get('orderId'), 0),
                    "refer_type": safe_int(review.get('referType'), 0),
                    "business_type": business_type,
                    "coupon_code": coupon_code,
                    "product_name": product_name,
                    "order_time": order_time,
                    "consume_time": consume_time,
                    "quantity": quantity,
                    "price": price,
                    "case_status": safe_int(review.get('caseStatus'), 0),
                    "report_status": safe_int(review.get('reportStatus'), 0),
                    "case_id": safe_int(review.get('caseId'), 0),
                    "show_deal": 1 if review.get('showDeal', True) else 0,
                    "raw_data": json.dumps(review, ensure_ascii=False)
                }

                try:
                    print(f"\n      ä¸Šä¼ ç¾å›¢è¯„ä»· review_id={upload_data.get('review_id')}, shop_id={upload_data.get('shop_id')}")
                    print(f"         user_nickname={upload_data.get('user_nickname')}, content={upload_data.get('content', '')[:50]}...")
                    upload_resp = session.post(UPLOAD_APIS[table_name], headers={'Content-Type': 'application/json'},
                                               json=upload_data, timeout=30, proxies={'http': None, 'https': None})
                    print(f"         HTTPçŠ¶æ€ç : {upload_resp.status_code}")
                    print(f"         å“åº”: {upload_resp.text[:200] if upload_resp.text else '(ç©º)'}")
                    if upload_resp.status_code == 200:
                        upload_stats["success"] += 1
                        print(f"         âœ… æˆåŠŸ")
                    else:
                        upload_stats["failed"] += 1
                        print(f"         âŒ å¤±è´¥")
                        print(f"         åŸå§‹æ•°æ®: {json.dumps(review, ensure_ascii=False)[:500]}")
                except Exception as e:
                    upload_stats["failed"] += 1
                    print(f"         âŒ å¼‚å¸¸: {e}")
                    print(f"         åŸå§‹æ•°æ®: {json.dumps(review, ensure_ascii=False)[:500]}")
                time.sleep(0.3)

            all_reviews.extend(reviews)
            if len(all_reviews) >= total:
                break
            page_no += 1
            random_delay()  # åçˆ¬è™«ç­‰å¾…

        print(f"\nğŸ“Š ç¾å›¢è¯„ä»·å®Œæˆ: è·å– {len(all_reviews)} æ¡, ä¸Šä¼ æˆåŠŸ {upload_stats['success']}, å¤±è´¥ {upload_stats['failed']}")

        if upload_stats["failed"] == 0:
            result["success"] = True
            result["record_count"] = upload_stats["success"]
            for shop_id in (shop_ids_found or shop_ids):
                log_success(account_name, shop_id, table_name, start_date, end_date, upload_stats["success"])
        else:
            result["error_message"] = f"éƒ¨åˆ†ä¸Šä¼ å¤±è´¥: æˆåŠŸ{upload_stats['success']}, å¤±è´¥{upload_stats['failed']}"
            for shop_id in shop_ids:
                log_failure(account_name, shop_id, table_name, start_date, end_date, result["error_message"])

    except AuthInvalidError as e:
        # ç™»å½•å¤±æ•ˆå¼‚å¸¸ - å·²åœ¨æ£€æµ‹æ—¶è°ƒç”¨ handle_auth_invalidï¼Œè¿™é‡Œåªè®°å½•ç»“æœ
        result["error_message"] = str(e)
        print(f"âŒ ç™»å½•å¤±æ•ˆï¼Œä»»åŠ¡ç»ˆæ­¢: {e}")

    except Exception as e:
        result["error_message"] = str(e)
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        log_failure(account_name, 0, table_name, start_date, end_date, str(e))

    return result


# ============================================================================
# review_summary_dianping ä»»åŠ¡
# ============================================================================
def run_review_summary_dianping(account_name: str, start_date: str, end_date: str,
                                cookies: Dict = None, mtgsig: str = None, shop_info: List = None) -> Dict[str, Any]:
    """æ‰§è¡Œreview_summary_dianpingä»»åŠ¡

    Args:
        account_name: è´¦æˆ·åç§°
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        cookies: å¤–éƒ¨ä¼ å…¥çš„Cookieï¼ˆå¯é€‰ï¼Œé¿å…é‡å¤è°ƒç”¨APIï¼‰
        mtgsig: å¤–éƒ¨ä¼ å…¥çš„ç­¾åï¼ˆå¯é€‰ï¼‰
        shop_info: å¤–éƒ¨ä¼ å…¥çš„é—¨åº—ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    """
    table_name = "review_summary_dianping"
    print(f"\n{'=' * 60}")
    print(f"ğŸ’¬ {table_name}")
    print(f"{'=' * 60}")

    result = {"task_name": table_name, "success": False, "record_count": 0, "error_message": "æ— "}

    try:
        disable_proxy()
        Path(SAVE_DIR).mkdir(parents=True, exist_ok=True)

        # ä¼˜å…ˆä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„æ•°æ®ï¼ˆé¡µé¢é©±åŠ¨æ¨¡å¼ï¼‰
        if cookies and mtgsig:
            print(f"ğŸ“Œ ä½¿ç”¨å…±äº« Cookie/ç­¾åï¼ˆæ— éœ€è°ƒç”¨APIï¼‰")
            if not shop_info:
                shop_info = []
        else:
            # æ²¡æœ‰å¤–éƒ¨æ•°æ®ï¼Œä»APIè·å–
            api_data = load_cookies_from_api(account_name)
            cookies = api_data['cookies']
            mtgsig = api_data['mtgsig']
            shop_info = api_data['shop_info']
        shop_ids = get_shop_ids(shop_info)

        headers = {
            'Accept': 'application/json, text/plain, */*',
            'Content-Type': 'application/json',
            'Origin': 'https://e.dianping.com',
            'Referer': 'https://e.dianping.com/app/merchant-workbench/index.html',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        session = get_session()

        # è§¦å‘ä¸‹è½½
        print(f"\nğŸ“¤ è§¦å‘ä¸‹è½½ä»»åŠ¡...")
        trigger_url = "https://e.dianping.com/gateway/merchant/review/pc/reviewdownload"
        trigger_params = {"yodaReady": "h5", "csecplatform": "4", "csecversion": "4.1.1", "mtgsig": generate_mtgsig(cookies, mtgsig)}
        trigger_payload = {"tagId": 0, "platform": 1, "shopIdStr": "0", "startDate": start_date, "endDate": end_date}

        trigger_resp = session.post(trigger_url, params=trigger_params, headers=headers, cookies=cookies, json=trigger_payload, timeout=60)
        trigger_json = trigger_resp.json()
        print(f"   å“åº”: {trigger_json}")

        # æ£€æŸ¥è§¦å‘å“åº”æ˜¯å¦ç™»å½•å¤±æ•ˆ
        trigger_code = trigger_json.get('code')
        trigger_msg = trigger_json.get('msg') or trigger_json.get('message') or ''
        if is_auth_invalid_error(trigger_code, trigger_msg):
            error_msg = f"ç™»å½•å¤±æ•ˆ (code={trigger_code}, msg={trigger_msg})"
            print(f"ğŸš¨ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆ: {error_msg}")
            handle_auth_invalid(account_name, start_date, end_date, table_name, error_msg)
            raise AuthInvalidError(error_msg)

        random_delay()  # åçˆ¬è™«ç­‰å¾…

        # ç­‰å¾…æ–‡ä»¶ç”Ÿæˆ
        print(f"\nâ³ ç­‰å¾…æ–‡ä»¶ç”Ÿæˆ...")
        trigger_time = time.time()
        file_record = None

        for _ in range(30):
            time.sleep(2)
            list_url = "https://e.dianping.com/gateway/merchant/downloadcenter/list"
            list_params = {'pageNo': 1, 'pageSize': 20, 'yodaReady': 'h5', 'csecplatform': '4', 'csecversion': '4.1.1', 'mtgsig': generate_mtgsig(cookies, mtgsig)}
            list_resp = session.get(list_url, params=list_params, headers=headers, cookies=cookies, timeout=30)
            list_data = list_resp.json()

            # æ£€æŸ¥æ˜¯å¦ç™»å½•å¤±æ•ˆ
            list_code = list_data.get('code')
            list_msg = list_data.get('msg') or list_data.get('message') or ''
            if is_auth_invalid_error(list_code, list_msg):
                error_msg = f"ç™»å½•å¤±æ•ˆ (code={list_code}, msg={list_msg})"
                print(f"ğŸš¨ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆ: {error_msg}")
                handle_auth_invalid(account_name, start_date, end_date, table_name, error_msg)
                raise AuthInvalidError(error_msg)

            if list_data.get('code') == 200:
                for record in list_data.get('data', {}).get('records', []):
                    file_name = record.get('fileName', '')
                    if 'é—¨åº—è¯„ä»·' in file_name and record.get('recordStatus') == 300 and record.get('downloadable') == "1" and record.get('fileUrl'):
                        add_time = record.get('addTime', '')
                        try:
                            file_time = datetime.strptime(add_time, '%Y-%m-%d %H:%M:%S')
                            if file_time.timestamp() >= trigger_time - 10:
                                file_record = record
                                print(f"   âœ… æ–‡ä»¶å·²å°±ç»ª: {file_name}")
                                break
                        except:
                            file_record = record
                            break
            if file_record:
                break

        if not file_record:
            raise Exception("æ–‡ä»¶ç”Ÿæˆè¶…æ—¶")

        random_delay()  # åçˆ¬è™«ç­‰å¾…

        # ä¸‹è½½æ–‡ä»¶
        file_url = file_record['fileUrl']
        file_name = file_record.get('fileName', f'ç‚¹è¯„è¯„ä»·_{start_date}_{end_date}.xlsx')
        save_path = str(Path(SAVE_DIR) / file_name)

        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½æ–‡ä»¶...")
        print(f"   URL: {file_url[:80]}...")
        dl_resp = session.get(file_url, timeout=120, stream=True)
        with open(save_path, 'wb') as f:
            for chunk in dl_resp.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
        file_size = Path(save_path).stat().st_size
        print(f"âœ… æ–‡ä»¶å·²ä¿å­˜åˆ°: {save_path}")
        print(f"   æ–‡ä»¶å¤§å°: {file_size / 1024:.2f} KB")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©ºæˆ–æ— æ•ˆ
        if file_size < 1000:  # å°äº1KBå¯èƒ½æ˜¯ç©ºæ–‡ä»¶
            print(f"âš ï¸ æ–‡ä»¶å¯èƒ½ä¸ºç©ºæˆ–æ— æ•ˆ (å¤§å°: {file_size} å­—èŠ‚)")

        # ä¸Šä¼ æ•°æ®
        print(f"\nğŸ“¤ å¼€å§‹ä¸Šä¼ è¯„ä»·æ•°æ®...")
        try:
            df = pd.read_excel(save_path)
        except ValueError as e:
            if "Worksheet index" in str(e) or "0 worksheets found" in str(e):
                print(f"âš ï¸ Excelæ–‡ä»¶ä¸ºç©º(æ²¡æœ‰å·¥ä½œè¡¨)ï¼Œè¯¥æ—¥æœŸèŒƒå›´å¯èƒ½æ²¡æœ‰ç‚¹è¯„è¯„ä»·æ•°æ®")
                result["success"] = True
                result["record_count"] = 0
                result["error_message"] = "æ— æ•°æ®"
                return result
            raise
        success_count = 0
        fail_count = 0
        shop_ids_found = set()

        EMPTY_DATETIME = "1970-01-01 00:00:00"

        def format_datetime(dt_str):
            if pd.isna(dt_str) or str(dt_str).strip() == '':
                return EMPTY_DATETIME
            dt_str = str(dt_str).strip()
            for fmt in ["%Y-%m-%d %H:%M:%S", "%Y-%m-%d %H:%M", "%Y/%m/%d %H:%M:%S", "%Y/%m/%d %H:%M"]:
                try:
                    return datetime.strptime(dt_str, fmt).strftime("%Y-%m-%d %H:%M:%S")
                except:
                    continue
            return dt_str

        def safe_int(val, default=0):
            if pd.isna(val):
                return default
            try:
                return int(val)
            except:
                return default

        def safe_str(val, default=""):
            if pd.isna(val):
                return default
            return str(val).strip()

        for idx, row in df.iterrows():
            try:
                content = safe_str(row.get('è¯„ä»·å†…å®¹')) or 'æ— '
                is_replied = "æ˜¯" if row.get('å•†å®¶æ˜¯å¦å·²ç»å›å¤') == 'å·²å›å¤' else "å¦"
                is_after_consume = "æ˜¯" if row.get('æ˜¯å¦æ¶ˆè´¹åè¯„ä»·') == 'æ˜¯' else "å¦"
                dp_shop_id = safe_int(row.get('ç‚¹è¯„é—¨åº—ID'), None)
                if dp_shop_id:
                    shop_ids_found.add(dp_shop_id)

                params = {
                    "review_time": format_datetime(row.get('è¯„ä»·æ—¶é—´')),
                    "city": safe_str(row.get('åŸå¸‚')),
                    "shop_name": safe_str(row.get('è¯„ä»·é—¨åº—')),
                    "dianping_shop_id": dp_shop_id,
                    "meituan_shop_id": safe_int(row.get('ç¾å›¢é—¨åº—ID'), None),
                    "user_nickname": safe_str(row.get('ç”¨æˆ·æ˜µç§°')),
                    "star": safe_str(row.get('æ˜Ÿçº§')),
                    "score_detail": safe_str(row.get('è¯„åˆ†')),
                    "content": content,
                    "content_length": safe_int(row.get('è¯„ä»·æ­£æ–‡å­—æ•°'), len(content)),
                    "pic_count": safe_int(row.get('å›¾ç‰‡æ•°'), 0),
                    "video_count": safe_int(row.get('è§†é¢‘æ•°'), 0),
                    "is_replied": is_replied,
                    "first_reply_time": format_datetime(row.get('å•†å®¶é¦–æ¬¡å›å¤æ—¶é—´')),
                    "is_after_consume": is_after_consume,
                    "consume_time": format_datetime(row.get('æ¶ˆè´¹æ—¶é—´'))
                }

                print(f"\n   [{idx+1}/{len(df)}] ä¸Šä¼ ç‚¹è¯„è¯„ä»·:")
                print(f"      shop_name={params.get('shop_name')}, dianping_shop_id={params.get('dianping_shop_id')}")
                print(f"      user_nickname={params.get('user_nickname')}, content={params.get('content', '')[:50]}...")
                resp = requests.post(UPLOAD_APIS[table_name], headers={'Content-Type': 'application/json'},
                                     data=json.dumps(params, ensure_ascii=False).encode('utf-8'),
                                     timeout=30, proxies={'http': None, 'https': None})
                print(f"      HTTPçŠ¶æ€ç : {resp.status_code}")
                print(f"      å“åº”: {resp.text[:200] if resp.text else '(ç©º)'}")
                if resp.status_code == 200:
                    success_count += 1
                    print(f"      âœ… æˆåŠŸ")
                else:
                    fail_count += 1
                    print(f"      âŒ å¤±è´¥")
                    print(f"      å®Œæ•´å‚æ•°: {json.dumps(params, ensure_ascii=False)}")
            except Exception as e:
                fail_count += 1
                print(f"      âŒ å¼‚å¸¸: {e}")
                print(f"      å®Œæ•´å‚æ•°: {json.dumps(params, ensure_ascii=False)}")

        print(f"\nâœ… ä¸Šä¼ å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}")

        if fail_count == 0:
            result["success"] = True
            result["record_count"] = success_count
            for shop_id in (shop_ids_found or shop_ids):
                log_success(account_name, shop_id, table_name, start_date, end_date, success_count)
        else:
            result["error_message"] = f"éƒ¨åˆ†ä¸Šä¼ å¤±è´¥: æˆåŠŸ{success_count}, å¤±è´¥{fail_count}"
            for shop_id in shop_ids:
                log_failure(account_name, shop_id, table_name, start_date, end_date, result["error_message"])

    except AuthInvalidError as e:
        # ç™»å½•å¤±æ•ˆå¼‚å¸¸ - å·²åœ¨æ£€æµ‹æ—¶è°ƒç”¨ handle_auth_invalidï¼Œè¿™é‡Œåªè®°å½•ç»“æœ
        result["error_message"] = str(e)
        print(f"âŒ ç™»å½•å¤±æ•ˆï¼Œä»»åŠ¡ç»ˆæ­¢: {e}")

    except Exception as e:
        result["error_message"] = str(e)
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        log_failure(account_name, 0, table_name, start_date, end_date, str(e))

    return result


# ============================================================================
# review_summary_meituan ä»»åŠ¡
# ============================================================================
def run_review_summary_meituan(account_name: str, start_date: str, end_date: str,
                               cookies: Dict = None, mtgsig: str = None, shop_info: List = None) -> Dict[str, Any]:
    """æ‰§è¡Œreview_summary_meituanä»»åŠ¡

    Args:
        account_name: è´¦æˆ·åç§°
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        cookies: å¤–éƒ¨ä¼ å…¥çš„Cookieï¼ˆå¯é€‰ï¼Œé¿å…é‡å¤è°ƒç”¨APIï¼‰
        mtgsig: å¤–éƒ¨ä¼ å…¥çš„ç­¾åï¼ˆå¯é€‰ï¼‰
        shop_info: å¤–éƒ¨ä¼ å…¥çš„é—¨åº—ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    """
    table_name = "review_summary_meituan"
    print(f"\n{'=' * 60}")
    print(f"ğŸ” {table_name}")
    print(f"{'=' * 60}")

    result = {"task_name": table_name, "success": False, "record_count": 0, "error_message": "æ— "}

    try:
        disable_proxy()
        Path(SAVE_DIR).mkdir(parents=True, exist_ok=True)

        # ä¼˜å…ˆä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„æ•°æ®ï¼ˆé¡µé¢é©±åŠ¨æ¨¡å¼ï¼‰
        if cookies and mtgsig:
            print(f"ğŸ“Œ ä½¿ç”¨å…±äº« Cookie/ç­¾åï¼ˆæ— éœ€è°ƒç”¨APIï¼‰")
            if not shop_info:
                shop_info = []
        else:
            # æ²¡æœ‰å¤–éƒ¨æ•°æ®ï¼Œä»APIè·å–
            api_data = load_cookies_from_api(account_name)
            cookies = api_data['cookies']
            mtgsig = api_data['mtgsig']
            shop_info = api_data['shop_info']
        shop_ids = get_shop_ids(shop_info)

        headers = {
            'Accept': 'application/json, text/plain, */*',
            'Content-Type': 'application/json',
            'Origin': 'https://e.dianping.com',
            'Referer': 'https://e.dianping.com/vg-platform-reviewmanage/shop-comment-mt/index.html',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        session = get_session()

        # è§¦å‘ä¸‹è½½
        print(f"\nğŸ“¤ è§¦å‘ç¾å›¢è¯„ä»·ä¸‹è½½ä»»åŠ¡...")
        trigger_url = "https://e.dianping.com/gateway/merchant/review/pc/reviewdownload"
        trigger_params = {"yodaReady": "h5", "csecplatform": "4", "csecversion": "4.1.1", "mtgsig": generate_mtgsig(cookies, mtgsig)}
        trigger_payload = {"tagId": 0, "platform": 2, "shopIdStr": "0", "startDate": start_date, "endDate": end_date}

        trigger_resp = session.post(trigger_url, params=trigger_params, headers=headers, cookies=cookies, json=trigger_payload, timeout=60)
        trigger_json = trigger_resp.json()
        print(f"   å“åº”: {trigger_json}")

        # æ£€æŸ¥è§¦å‘å“åº”æ˜¯å¦ç™»å½•å¤±æ•ˆ
        trigger_code = trigger_json.get('code')
        trigger_msg = trigger_json.get('msg') or trigger_json.get('message') or ''
        if is_auth_invalid_error(trigger_code, trigger_msg):
            error_msg = f"ç™»å½•å¤±æ•ˆ (code={trigger_code}, msg={trigger_msg})"
            print(f"ğŸš¨ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆ: {error_msg}")
            handle_auth_invalid(account_name, start_date, end_date, table_name, error_msg)
            raise AuthInvalidError(error_msg)

        random_delay()  # åçˆ¬è™«ç­‰å¾…

        # ç­‰å¾…æ–‡ä»¶ç”Ÿæˆ
        print(f"\nâ³ ç­‰å¾…æ–‡ä»¶ç”Ÿæˆ...")
        trigger_time = time.time()
        file_record = None

        for _ in range(30):
            time.sleep(2)
            list_url = "https://e.dianping.com/gateway/merchant/downloadcenter/list"
            list_params = {'pageNo': 1, 'pageSize': 20, 'yodaReady': 'h5', 'csecplatform': '4', 'csecversion': '4.1.1', 'mtgsig': generate_mtgsig(cookies, mtgsig)}
            list_resp = session.get(list_url, params=list_params, headers=headers, cookies=cookies, timeout=30)
            list_data = list_resp.json()

            # æ£€æŸ¥æ˜¯å¦ç™»å½•å¤±æ•ˆ
            list_code = list_data.get('code')
            list_msg = list_data.get('msg') or list_data.get('message') or ''
            if is_auth_invalid_error(list_code, list_msg):
                error_msg = f"ç™»å½•å¤±æ•ˆ (code={list_code}, msg={list_msg})"
                print(f"ğŸš¨ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆ: {error_msg}")
                handle_auth_invalid(account_name, start_date, end_date, table_name, error_msg)
                raise AuthInvalidError(error_msg)

            if list_data.get('code') == 200:
                for record in list_data.get('data', {}).get('records', []):
                    file_name = record.get('fileName', '')
                    if ('è¯„ä»·' in file_name or 'é—¨åº—è¯„ä»·' in file_name) and record.get('recordStatus') == 300 and record.get('downloadable') == "1" and record.get('fileUrl'):
                        add_time = record.get('addTime', '')
                        try:
                            file_time = datetime.strptime(add_time, '%Y-%m-%d %H:%M:%S')
                            if file_time.timestamp() >= trigger_time - 10:
                                file_record = record
                                print(f"   âœ… æ–‡ä»¶å·²å°±ç»ª: {file_name}")
                                break
                        except:
                            file_record = record
                            break
            if file_record:
                break

        if not file_record:
            raise Exception("æ–‡ä»¶ç”Ÿæˆè¶…æ—¶")

        random_delay()  # åçˆ¬è™«ç­‰å¾…

        # ä¸‹è½½æ–‡ä»¶
        file_url = file_record['fileUrl']
        file_name = file_record.get('fileName', f'ç¾å›¢è¯„ä»·_{start_date}_{end_date}.xlsx')
        save_path = str(Path(SAVE_DIR) / file_name)

        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½æ–‡ä»¶...")
        print(f"   URL: {file_url[:80]}...")
        dl_resp = session.get(file_url, timeout=120, stream=True)
        with open(save_path, 'wb') as f:
            for chunk in dl_resp.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
        file_size = Path(save_path).stat().st_size
        print(f"âœ… æ–‡ä»¶å·²ä¿å­˜åˆ°: {save_path}")
        print(f"   æ–‡ä»¶å¤§å°: {file_size / 1024:.2f} KB")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©ºæˆ–æ— æ•ˆ
        if file_size < 1000:
            print(f"âš ï¸ æ–‡ä»¶å¯èƒ½ä¸ºç©ºæˆ–æ— æ•ˆ (å¤§å°: {file_size} å­—èŠ‚)")

        # ä¸Šä¼ æ•°æ®
        print(f"\nğŸ“¤ å¼€å§‹ä¸Šä¼ ç¾å›¢è¯„ä»·æ•°æ®...")
        try:
            df = pd.read_excel(save_path)
        except ValueError as e:
            if "Worksheet index" in str(e) or "0 worksheets found" in str(e):
                print(f"âš ï¸ Excelæ–‡ä»¶ä¸ºç©º(æ²¡æœ‰å·¥ä½œè¡¨)ï¼Œè¯¥æ—¥æœŸèŒƒå›´å¯èƒ½æ²¡æœ‰ç¾å›¢è¯„ä»·æ•°æ®")
                result["success"] = True
                result["record_count"] = 0
                result["error_message"] = "æ— æ•°æ®"
                return result
            raise
        success_count = 0
        fail_count = 0
        shop_ids_found = set()

        EMPTY_DATETIME = "1970-01-01 00:00:00"

        def format_datetime(dt_str):
            if pd.isna(dt_str) or str(dt_str).strip() == '':
                return EMPTY_DATETIME
            dt_str = str(dt_str).strip()
            for fmt in ["%Y-%m-%d %H:%M:%S", "%Y-%m-%d %H:%M", "%Y/%m/%d %H:%M:%S", "%Y/%m/%d %H:%M", "%Y-%m-%d", "%Y/%m/%d"]:
                try:
                    dt = datetime.strptime(dt_str, fmt)
                    if fmt in ["%Y-%m-%d", "%Y/%m/%d"]:
                        return dt.strftime("%Y-%m-%d")
                    return dt.strftime("%Y-%m-%d %H:%M:%S")
                except:
                    continue
            return dt_str

        def safe_int(val, default=0):
            if pd.isna(val):
                return default
            try:
                return int(val)
            except:
                return default

        def safe_str(val, default=""):
            if pd.isna(val):
                return default
            return str(val).strip()

        for idx, row in df.iterrows():
            try:
                content = safe_str(row.get('è¯„ä»·å†…å®¹')) or 'æ— '
                is_replied_raw = row.get('å•†å®¶æ˜¯å¦å·²ç»å›å¤')
                is_replied = "æ˜¯" if is_replied_raw == 'å·²å›å¤' or is_replied_raw == 'æ˜¯' else "å¦"
                is_after_consume = "æ˜¯" if row.get('æ˜¯å¦æ¶ˆè´¹åè¯„ä»·') == 'æ˜¯' else "å¦"
                mt_shop_id = safe_int(row.get('ç¾å›¢é—¨åº—ID'), None)
                if mt_shop_id:
                    shop_ids_found.add(mt_shop_id)

                params = {
                    "review_time": format_datetime(row.get('è¯„ä»·æ—¶é—´')),
                    "city": safe_str(row.get('åŸå¸‚')),
                    "shop_name": safe_str(row.get('è¯„ä»·é—¨åº—')),
                    "dianping_shop_id": safe_int(row.get('ç‚¹è¯„é—¨åº—ID'), None),
                    "meituan_shop_id": mt_shop_id,
                    "user_nickname": safe_str(row.get('ç”¨æˆ·æ˜µç§°')),
                    "star": safe_str(row.get('æ˜Ÿçº§')),
                    "content": content,
                    "content_length": safe_int(row.get('è¯„ä»·æ­£æ–‡å­—æ•°'), len(content)),
                    "pic_count": safe_int(row.get('å›¾ç‰‡æ•°'), 0),
                    "video_count": safe_int(row.get('è§†é¢‘æ•°'), 0),
                    "is_replied": is_replied,
                    "first_reply_time": format_datetime(row.get('å•†å®¶é¦–æ¬¡å›å¤æ—¶é—´')),
                    "is_after_consume": is_after_consume,
                    "consume_time": format_datetime(row.get('æ¶ˆè´¹æ—¶é—´'))
                }

                print(f"\n   [{idx+1}/{len(df)}] ä¸Šä¼ ç¾å›¢è¯„ä»·:")
                print(f"      shop_name={params.get('shop_name')}, meituan_shop_id={params.get('meituan_shop_id')}")
                print(f"      user_nickname={params.get('user_nickname')}, content={params.get('content', '')[:50]}...")
                resp = requests.post(UPLOAD_APIS[table_name], headers={'Content-Type': 'application/json'},
                                     data=json.dumps(params, ensure_ascii=False).encode('utf-8'),
                                     timeout=30, proxies={'http': None, 'https': None})
                print(f"      HTTPçŠ¶æ€ç : {resp.status_code}")
                print(f"      å“åº”: {resp.text[:200] if resp.text else '(ç©º)'}")
                if resp.status_code == 200:
                    success_count += 1
                    print(f"      âœ… æˆåŠŸ")
                else:
                    fail_count += 1
                    print(f"      âŒ å¤±è´¥")
                    print(f"      å®Œæ•´å‚æ•°: {json.dumps(params, ensure_ascii=False)}")
            except Exception as e:
                fail_count += 1
                print(f"      âŒ å¼‚å¸¸: {e}")
                print(f"      å®Œæ•´å‚æ•°: {json.dumps(params, ensure_ascii=False)}")

        print(f"\nâœ… ä¸Šä¼ å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}")

        if fail_count == 0:
            result["success"] = True
            result["record_count"] = success_count
            for shop_id in (shop_ids_found or shop_ids):
                log_success(account_name, shop_id, table_name, start_date, end_date, success_count)
        else:
            result["error_message"] = f"éƒ¨åˆ†ä¸Šä¼ å¤±è´¥: æˆåŠŸ{success_count}, å¤±è´¥{fail_count}"
            for shop_id in shop_ids:
                log_failure(account_name, shop_id, table_name, start_date, end_date, result["error_message"])

    except AuthInvalidError as e:
        # ç™»å½•å¤±æ•ˆå¼‚å¸¸ - å·²åœ¨æ£€æµ‹æ—¶è°ƒç”¨ handle_auth_invalidï¼Œè¿™é‡Œåªè®°å½•ç»“æœ
        result["error_message"] = str(e)
        print(f"âŒ ç™»å½•å¤±æ•ˆï¼Œä»»åŠ¡ç»ˆæ­¢: {e}")

    except Exception as e:
        result["error_message"] = str(e)
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        log_failure(account_name, 0, table_name, start_date, end_date, str(e))

    return result


# ============================================================================
# DianpingStoreStats ç±» (é—¨åº—ç»Ÿè®¡æ•°æ®é‡‡é›†ï¼Œä½¿ç”¨Playwrightæµè§ˆå™¨)
# ============================================================================
class DianpingStoreStats:
    """å¤§ä¼—ç‚¹è¯„é—¨åº—ç»Ÿè®¡æ•°æ®é‡‡é›†ç±»ï¼ˆå¸¦Playwrightæ”¯æŒï¼‰"""

    def __init__(self, account_name: str, platform_api_url: str, headless: bool = True, disable_proxy: bool = True,
                 external_page=None, cookies: Dict = None, mtgsig: str = None, shop_info: List = None,
                 compare_regions: Dict = None, brands_json: List = None):
        """åˆå§‹åŒ–

        Args:
            account_name: è´¦æˆ·åç§°
            platform_api_url: å¹³å°API URL
            headless: æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼
            disable_proxy: æ˜¯å¦ç¦ç”¨ä»£ç†
            external_page: å¤–éƒ¨ä¼ å…¥çš„ Playwright page å¯¹è±¡ï¼ˆç”¨äºé¡µé¢é©±åŠ¨æ¨¡å¼ï¼‰
            cookies: å¤–éƒ¨ä¼ å…¥çš„Cookieï¼ˆå¯é€‰ï¼Œé¿å…é‡å¤è°ƒç”¨APIï¼‰
            mtgsig: å¤–éƒ¨ä¼ å…¥çš„ç­¾åï¼ˆå¯é€‰ï¼‰
            shop_info: å¤–éƒ¨ä¼ å…¥çš„é—¨åº—ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            compare_regions: å¤–éƒ¨ä¼ å…¥çš„é—¨åº—å•†åœˆä¿¡æ¯ï¼ˆå¯é€‰ï¼Œç”¨äºåŒè¡Œæ’åï¼‰
            brands_json: å¤–éƒ¨ä¼ å…¥çš„å›¢è´­IDæ˜ å°„ï¼ˆå¯é€‰ï¼Œç”¨äºå¹¿å‘Šå•ï¼‰
        """
        self.account_name = account_name
        self.platform_api_url = platform_api_url
        self.headless = headless
        self.disable_proxy = disable_proxy
        self.state_file = os.path.join(STATE_DIR, f'dianping_state_{account_name}.json')

        # Playwrightç›¸å…³
        self.playwright = None
        self.browser = None
        self.context = None
        self.page = None

        # å¤–éƒ¨ä¼ å…¥çš„ page å¯¹è±¡ï¼ˆé¡µé¢é©±åŠ¨æ¨¡å¼ä½¿ç”¨ï¼‰
        self.external_page = external_page
        self.use_external_page = external_page is not None

        # ç™»å½•å¤±æ•ˆæ ‡å¿— - ä¸€æ—¦æ£€æµ‹åˆ°å¤±æ•ˆï¼Œåœæ­¢åç»­æ•°æ®è·å–
        self.login_invalid = False
        self.login_invalid_error = ""

        # ä»APIè·å–çš„æ•°æ®
        self.cookies = {}
        self.mtgsig_from_api = None
        self.shop_id = None
        self.shop_list = []
        self.product_mapping = []
        self.shop_region_info = {}
        self.cookie_data = None

        # å¤–éƒ¨ä¼ å…¥çš„æ•°æ®ï¼ˆé¡µé¢é©±åŠ¨æ¨¡å¼ï¼Œé¿å…é‡å¤è°ƒç”¨APIï¼‰
        self._external_cookies = cookies
        self._external_mtgsig = mtgsig
        self._external_shop_info = shop_info
        self._external_compare_regions = compare_regions
        self._external_brands_json = brands_json

        if self.disable_proxy:
            self._disable_proxy()

        self._load_account_info_from_api()

    def _disable_proxy(self):
        """ç¦ç”¨ç³»ç»Ÿä»£ç†"""
        proxy_vars = [
            'HTTP_PROXY', 'HTTPS_PROXY', 'FTP_PROXY', 'SOCKS_PROXY',
            'http_proxy', 'https_proxy', 'ftp_proxy', 'socks_proxy',
            'ALL_PROXY', 'all_proxy', 'NO_PROXY', 'no_proxy'
        ]
        for var in proxy_vars:
            os.environ.pop(var, None)
        os.environ['NO_PROXY'] = '*'
        os.environ['no_proxy'] = '*'
        print("âœ… å·²ç¦ç”¨ç³»ç»Ÿä»£ç†")

    def _get_session(self) -> requests.Session:
        """è·å–ç¦ç”¨ä»£ç†çš„session"""
        session = requests.Session()
        session.trust_env = False
        session.proxies = {'http': None, 'https': None, 'ftp': None, 'socks': None, 'no_proxy': '*'}
        session.mount('http://', requests.adapters.HTTPAdapter())
        session.mount('https://', requests.adapters.HTTPAdapter())
        return session

    def _load_account_info_from_api(self):
        """åŠ è½½è´¦æˆ·ä¿¡æ¯ï¼ˆä¼˜å…ˆä½¿ç”¨å¤–éƒ¨ä¼ å…¥æ•°æ®ï¼Œæ²¡æœ‰æ‰è°ƒç”¨APIï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¤–éƒ¨ä¼ å…¥çš„æ•°æ®ï¼ˆé¡µé¢é©±åŠ¨æ¨¡å¼ï¼‰
            if self._external_cookies and self._external_shop_info:
                print(f"ğŸ“Œ ä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„ Cookie/ç­¾å/é—¨åº—ä¿¡æ¯ï¼ˆæ— éœ€è°ƒç”¨APIï¼‰")

                # ä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„æ•°æ®
                self.cookies = self._external_cookies
                print(f"âœ… æˆåŠŸåŠ è½½ {len(self.cookies)} ä¸ªcookiesï¼ˆæ¥è‡ªå…±äº«æ•°æ®ï¼‰")

                if self._external_mtgsig:
                    self.mtgsig_from_api = self._external_mtgsig
                    print(f"   å·²è·å–mtgsig: {self.mtgsig_from_api[:50]}...")

                # å¤„ç†é—¨åº—ä¿¡æ¯ï¼ˆå¯èƒ½æ˜¯åˆ—è¡¨æˆ–å­—å…¸æ ¼å¼ï¼‰
                if isinstance(self._external_shop_info, list):
                    self.shop_list = self._external_shop_info
                elif isinstance(self._external_shop_info, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå–é—¨åº—åˆ—è¡¨
                    self.shop_list = [self._external_shop_info] if self._external_shop_info.get('shop_id') else []
                else:
                    self.shop_list = []

                if self.shop_list:
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(self.shop_list)} ä¸ªé—¨åº—ï¼ˆæ¥è‡ªå…±äº«æ•°æ®ï¼‰")
                    for shop in self.shop_list:
                        print(f"   - {shop.get('shop_name')} ({shop.get('shop_id')})")
                else:
                    # é—¨åº—ä¿¡æ¯ä¸ºç©ºï¼Œéœ€è¦ä»APIè·å–
                    print(f"âš ï¸ å…±äº«æ•°æ®ä¸­æ— é—¨åº—ä¿¡æ¯ï¼Œä»APIè¡¥å……è·å–...")
                    self._fetch_additional_info_from_api()

                # å¤„ç†é—¨åº—å•†åœˆä¿¡æ¯ï¼ˆç”¨äºåŒè¡Œæ’åï¼‰
                if self._external_compare_regions:
                    self.shop_region_info = self._external_compare_regions
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(self.shop_region_info)} ä¸ªé—¨åº—å•†åœˆä¿¡æ¯ï¼ˆæ¥è‡ªå…±äº«æ•°æ®ï¼‰")

                # å¤„ç†å›¢è´­IDæ˜ å°„ï¼ˆç”¨äºå¹¿å‘Šå•ï¼‰
                if self._external_brands_json:
                    self.product_mapping = self._external_brands_json
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(self.product_mapping)} ä¸ªå›¢è´­IDæ˜ å°„ï¼ˆæ¥è‡ªå…±äº«æ•°æ®ï¼‰")

                # è·å–åº—é“ºID
                self.shop_id = self.cookies.get('mpmerchant_portal_shopid', '')
                if not self.shop_id and self.shop_list:
                    self.shop_id = self.shop_list[0].get('shop_id')

                # æ£€æµ‹å¹¶è¡¥å…¨é—¨åº—/å•†åœˆæ•°æ®ï¼ˆä»»ä¸€ä¸ºç©ºåˆ™è§¦å‘ï¼‰
                self._check_and_complete_stores_regions()

                return

            # æ²¡æœ‰å¤–éƒ¨æ•°æ®ï¼Œä»APIè·å–å®Œæ•´ä¿¡æ¯
            print(f"ğŸ” æ­£åœ¨ä»APIè·å–è´¦æˆ· [{self.account_name}] çš„å®Œæ•´ä¿¡æ¯...")
            headers = {'Content-Type': 'application/json'}
            data = json.dumps({"account": self.account_name})

            session = self._get_session()
            response = session.post(self.platform_api_url, headers=headers, data=data, timeout=30)
            response.raise_for_status()
            result = response.json()

            if not result or not result.get('success'):
                raise Exception(f"APIè¿”å›å¤±è´¥")

            data = result.get('data', {})
            if not data:
                raise Exception(f"APIè¿”å›çš„dataä¸ºç©º")

            self.cookie_data = data

            # è·å–cookies
            cookie_data = data.get('cookie', {})
            if cookie_data:
                self.cookies = cookie_data
                print(f"âœ… æˆåŠŸåŠ è½½ {len(self.cookies)} ä¸ªcookies")
            else:
                raise Exception("æœªè·å–åˆ°cookieæ•°æ®")

            # è·å–mtgsig
            mtgsig_data = data.get('mtgsig')
            if mtgsig_data:
                if isinstance(mtgsig_data, str):
                    self.mtgsig_from_api = mtgsig_data
                else:
                    self.mtgsig_from_api = json.dumps(mtgsig_data)
                print(f"   å·²è·å–mtgsig: {self.mtgsig_from_api[:50]}...")

            # è·å–é—¨åº—åˆ—è¡¨ï¼ˆä½¿ç”¨ or [] ç¡®ä¿ null/None ä¹Ÿèƒ½æ­£ç¡®è½¬ä¸ºç©ºåˆ—è¡¨ï¼‰
            stores_json = data.get('stores_json') or []
            if stores_json:
                self.shop_list = stores_json
                print(f"âœ… æˆåŠŸåŠ è½½ {len(self.shop_list)} ä¸ªé—¨åº—")
                for shop in self.shop_list:
                    print(f"   - {shop.get('shop_name')} ({shop.get('shop_id')})")
            else:
                # APIæœªè¿”å›é—¨åº—åˆ—è¡¨ï¼Œå°è¯•ä»å¤§ä¼—ç‚¹è¯„ç›´æ¥è·å–ï¼ˆå…œåº•ï¼‰
                print(f"âš ï¸ APIæœªè¿”å›é—¨åº—åˆ—è¡¨ï¼Œå°è¯•ä»å¤§ä¼—ç‚¹è¯„ç›´æ¥è·å–...")
                fetched_shops = self._fetch_shop_list_from_dianping()
                if fetched_shops:
                    self.shop_list = [{'shop_id': s['shop_id'], 'shop_name': s['shop_name']} for s in fetched_shops]
                    print(f"âœ… å…œåº•æˆåŠŸï¼ŒåŠ è½½ {len(self.shop_list)} ä¸ªé—¨åº—")
                else:
                    raise Exception("æœªè·å–åˆ°é—¨åº—åˆ—è¡¨")

            # è·å–å›¢è´­IDæ˜ å°„
            brands_json = data.get('brands_json', [])
            if brands_json:
                self.product_mapping = brands_json
                print(f"âœ… æˆåŠŸåŠ è½½ {len(self.product_mapping)} ä¸ªå›¢è´­IDæ˜ å°„")

            # è·å–é—¨åº—å•†åœˆä¿¡æ¯
            compare_regions = data.get('compareRegions_json', {})
            if compare_regions:
                self.shop_region_info = compare_regions
                print(f"âœ… æˆåŠŸåŠ è½½ {len(self.shop_region_info)} ä¸ªé—¨åº—å•†åœˆä¿¡æ¯")

            # è·å–åº—é“ºID
            self.shop_id = self.cookies.get('mpmerchant_portal_shopid', '')
            if not self.shop_id and stores_json:
                self.shop_id = stores_json[0].get('shop_id')

            # æ£€æµ‹å¹¶è¡¥å…¨é—¨åº—/å•†åœˆæ•°æ®ï¼ˆä»»ä¸€ä¸ºç©ºåˆ™è§¦å‘ï¼‰
            self._check_and_complete_stores_regions()

        except Exception as e:
            print(f"âŒ åŠ è½½è´¦æˆ·ä¿¡æ¯å¤±è´¥: {e}")
            raise

    def _fetch_additional_info_from_api(self):
        """ä»APIè¡¥å……è·å–é¢å¤–ä¿¡æ¯ï¼ˆé—¨åº—åˆ—è¡¨ã€å›¢è´­æ˜ å°„ã€å•†åœˆä¿¡æ¯ï¼‰"""
        try:
            headers = {'Content-Type': 'application/json'}
            data = json.dumps({"account": self.account_name})

            session = self._get_session()
            response = session.post(self.platform_api_url, headers=headers, data=data, timeout=30)
            response.raise_for_status()
            result = response.json()

            if not result or not result.get('success'):
                return

            data = result.get('data', {})
            if not data:
                return

            self.cookie_data = data

            # è·å–é—¨åº—åˆ—è¡¨
            stores_json = data.get('stores_json', [])
            if stores_json:
                self.shop_list = stores_json
                print(f"âœ… æˆåŠŸåŠ è½½ {len(self.shop_list)} ä¸ªé—¨åº—")
                for shop in self.shop_list:
                    print(f"   - {shop.get('shop_name')} ({shop.get('shop_id')})")

            # è·å–å›¢è´­IDæ˜ å°„
            brands_json = data.get('brands_json', [])
            if brands_json:
                self.product_mapping = brands_json
                print(f"âœ… æˆåŠŸåŠ è½½ {len(self.product_mapping)} ä¸ªå›¢è´­IDæ˜ å°„")

            # è·å–é—¨åº—å•†åœˆä¿¡æ¯
            compare_regions = data.get('compareRegions_json', {})
            if compare_regions:
                self.shop_region_info = compare_regions
                print(f"âœ… æˆåŠŸåŠ è½½ {len(self.shop_region_info)} ä¸ªé—¨åº—å•†åœˆä¿¡æ¯")

        except Exception as e:
            print(f"âš ï¸ è¡¥å……è·å–ä¿¡æ¯å¤±è´¥: {e}")

    def _fetch_shop_list_from_dianping(self) -> list:
        """
        ä»å¤§ä¼—ç‚¹è¯„APIè·å–é—¨åº—åˆ—è¡¨
        API: POST https://e.dianping.com/gateway/merchant/general/shopinfo
        è¿”å›: stores_json æ ¼å¼çš„é—¨åº—åˆ—è¡¨
        """
        try:
            print(f"\nğŸ“¡ æ­£åœ¨ä»å¤§ä¼—ç‚¹è¯„è·å–é—¨åº—åˆ—è¡¨...")
            url = "https://e.dianping.com/gateway/merchant/general/shopinfo"
            params = {
                'yodaReady': 'h5',
                'csecplatform': '4',
                'csecversion': '4.1.1'
            }
            payload = {
                "bizType": "pc-shouye",
                "device": "pc",
                "currentTab": "city",
                "shopIds": "0"
            }
            headers = {
                'Accept': 'application/json, text/plain, */*',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Connection': 'keep-alive',
                'Content-Type': 'application/json',
                'Referer': 'https://e.dianping.com/codejoy/2703/home/index.html',
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }

            session = self._get_session()
            response = session.post(
                url,
                params=params,
                headers=headers,
                cookies=self.cookies,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            data = response.json()

            if data.get('code') == 200 and data.get('data') and data['data'].get('shopInfoList'):
                shop_list = []
                for shop in data['data']['shopInfoList']:
                    if shop.get('type') != 0:  # è¿‡æ»¤ type=0 çš„
                        shop_name = shop.get('shopName', '')
                        branch_name = shop.get('branchName') or ''
                        full_name = shop_name + branch_name
                        shop_list.append({
                            'shop_id': str(shop.get('shopId', '')),
                            'shop_name': full_name,
                            'shopName': shop_name,
                            'branchName': branch_name if branch_name else None,
                            'cityId': shop.get('cityId') or None
                        })
                print(f"âœ… æˆåŠŸè·å– {len(shop_list)} ä¸ªé—¨åº—")
                return shop_list
            else:
                print(f"âš ï¸ é—¨åº—åˆ—è¡¨è¿”å›æ•°æ®æ ¼å¼é”™è¯¯: {data}")
                return []

        except Exception as e:
            print(f"âš ï¸ è·å–é—¨åº—åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def _fetch_shop_regions_from_dianping(self, shop_list: list) -> dict:
        """
        ä»å¤§ä¼—ç‚¹è¯„APIè·å–æ‰€æœ‰é—¨åº—çš„å•†åœˆæ•°æ®
        API: GET https://e.dianping.com/gateway/adviser/complexfilter
        è¿”å›: compareRegions_json æ ¼å¼çš„å•†åœˆæ•°æ®
        """
        if not shop_list:
            return {}

        print(f"\nğŸ“¡ å¼€å§‹è·å– {len(shop_list)} ä¸ªé—¨åº—çš„å•†åœˆæ•°æ®...")
        compare_regions_data = {}

        for i, shop in enumerate(shop_list):
            shop_id = shop['shop_id']
            shop_name = shop.get('shopName', shop.get('shop_name', ''))

            print(f"   [{i + 1}/{len(shop_list)}] æ­£åœ¨è·å–é—¨åº— {shop_name} (ID: {shop_id}) çš„å•†åœˆæ•°æ®...")

            try:
                url = "https://e.dianping.com/gateway/adviser/complexfilter"
                params = {
                    'device': 'pc',
                    'source': '1',
                    'pageType': 'compareRegions',
                    'sign': '',
                    'shopIds': shop_id,
                    'yodaReady': 'h5',
                    'csecplatform': '4',
                    'csecversion': '4.1.1',
                    'mtgsig': self._generate_mtgsig() if hasattr(self, '_generate_mtgsig') else ''
                }
                headers = {
                    'Accept': 'application/json, text/plain, */*',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Connection': 'keep-alive',
                    'Referer': 'https://e.dianping.com/codejoy/2703/home/index.html',
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }

                session = self._get_session()
                response = session.get(
                    url,
                    params=params,
                    headers=headers,
                    cookies=self.cookies,
                    timeout=30
                )
                response.raise_for_status()
                data = response.json()

                if data.get('success') and data.get('data') and data['data'].get('compareRegions'):
                    regions = data['data']['compareRegions'].get('content', [])

                    # è§£æå•†åœˆæ•°æ®
                    regions_dict = {}
                    for region in regions:
                        region_type = region.get('type', '')
                        if region_type == 'åŸå¸‚':
                            regions_dict['city'] = {
                                'regionId': region.get('regionId'),
                                'regionName': region.get('regionName')
                            }
                        elif region_type == 'è¡Œæ”¿åŒº':
                            regions_dict['district'] = {
                                'regionId': region.get('regionId'),
                                'regionName': region.get('regionName')
                            }
                        elif region_type == 'å•†åœˆ':
                            regions_dict['business'] = {
                                'regionId': region.get('regionId'),
                                'regionName': region.get('regionName')
                            }

                    compare_regions_data[shop_id] = {
                        'shopName': shop.get('shopName', ''),
                        'branchName': shop.get('branchName'),
                        'cityId': shop.get('cityId'),
                        'regions': regions_dict
                    }
                    print(f"      âœ… æˆåŠŸ: {regions_dict}")
                else:
                    print(f"      âš ï¸ å¤±è´¥: {data.get('msg', 'è¿”å›æ•°æ®æ ¼å¼é”™è¯¯')}")

            except Exception as e:
                print(f"      âš ï¸ å¤±è´¥: {e}")

            # é—´éš”å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
            if i < len(shop_list) - 1:
                time.sleep(2)

        print(f"\nâœ… å•†åœˆæ•°æ®è·å–å®Œæˆï¼ŒæˆåŠŸ {len(compare_regions_data)}/{len(shop_list)} ä¸ª")
        return compare_regions_data

    def _post_stores_regions_to_api(self, stores_json: list, compare_regions_json: dict) -> bool:
        """
        å›ä¼ é—¨åº—å’Œå•†åœˆæ•°æ®åˆ°åç«¯API
        API: POST http://8.146.210.145:3000/api/post/platform_accounts
        """
        try:
            print(f"\nğŸ“¤ æ­£åœ¨å›ä¼ é—¨åº—å’Œå•†åœˆæ•°æ®...")

            payload = {
                "account": self.account_name,
                "stores_json": json.dumps(stores_json, ensure_ascii=False),
                "compareRegions_json": json.dumps(compare_regions_json, ensure_ascii=False)
            }

            session = self._get_session()
            response = session.post(
                POST_STORES_REGIONS_API_URL,
                headers={'Content-Type': 'application/json'},
                json=payload,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                if result.get('success'):
                    print(f"âœ… é—¨åº—å’Œå•†åœˆæ•°æ®å›ä¼ æˆåŠŸ")
                    return True
                else:
                    print(f"âš ï¸ å›ä¼ è¿”å›å¤±è´¥: {result}")
                    return False
            else:
                print(f"âš ï¸ å›ä¼ HTTPçŠ¶æ€ç å¼‚å¸¸: {response.status_code}")
                return False

        except Exception as e:
            print(f"âš ï¸ å›ä¼ é—¨åº—å’Œå•†åœˆæ•°æ®å¤±è´¥: {e}")
            return False

    def _check_and_complete_stores_regions(self):
        """
        æ£€æµ‹å¹¶è¡¥å…¨é—¨åº—/å•†åœˆæ•°æ®
        è§¦å‘æ¡ä»¶: stores_json ä¸ºç©º OR compareRegions_json ä¸ºç©º
        æ­¤ä»»åŠ¡å¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œä¸è®°å½•å¤±è´¥æ—¥å¿—
        """
        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è¡¥å…¨
            stores_empty = not self.shop_list or len(self.shop_list) == 0
            regions_empty = not self.shop_region_info or len(self.shop_region_info) == 0

            if not stores_empty and not regions_empty:
                # æ•°æ®å®Œæ•´ï¼Œæ— éœ€è¡¥å…¨
                return

            print(f"\nğŸ”„ æ£€æµ‹åˆ°é—¨åº—/å•†åœˆæ•°æ®ä¸å®Œæ•´ï¼Œå¼€å§‹è‡ªåŠ¨è¡¥å…¨...")
            print(f"   é—¨åº—æ•°æ®: {'ä¸ºç©º' if stores_empty else f'{len(self.shop_list)} ä¸ª'}")
            print(f"   å•†åœˆæ•°æ®: {'ä¸ºç©º' if regions_empty else f'{len(self.shop_region_info)} ä¸ª'}")

            # å¦‚æœé—¨åº—æ•°æ®ä¸ºç©ºï¼Œå…ˆè·å–é—¨åº—åˆ—è¡¨
            if stores_empty:
                fetched_shops = self._fetch_shop_list_from_dianping()
                if fetched_shops:
                    # è½¬æ¢ä¸º stores_json æ ¼å¼
                    self.shop_list = [{'shop_id': s['shop_id'], 'shop_name': s['shop_name']} for s in fetched_shops]
                    stores_empty = False
                else:
                    print(f"âš ï¸ æ— æ³•è·å–é—¨åº—åˆ—è¡¨ï¼Œè·³è¿‡è¡¥å…¨")
                    return
            else:
                # é—¨åº—æ•°æ®ä¸ä¸ºç©ºï¼Œç”¨äºè·å–å•†åœˆ
                fetched_shops = []
                for shop in self.shop_list:
                    fetched_shops.append({
                        'shop_id': shop.get('shop_id', ''),
                        'shop_name': shop.get('shop_name', ''),
                        'shopName': shop.get('shop_name', '').split('åº—')[0] if 'åº—' in shop.get('shop_name', '') else shop.get('shop_name', ''),
                        'branchName': None,
                        'cityId': None
                    })

            # è·å–å•†åœˆæ•°æ®
            if regions_empty and fetched_shops:
                fetched_regions = self._fetch_shop_regions_from_dianping(fetched_shops)
                if fetched_regions:
                    self.shop_region_info = fetched_regions

            # å‡†å¤‡å›ä¼ æ•°æ®
            stores_to_post = self.shop_list if self.shop_list else []
            regions_to_post = self.shop_region_info if self.shop_region_info else {}

            # å›ä¼ æ•°æ®
            if stores_to_post or regions_to_post:
                self._post_stores_regions_to_api(stores_to_post, regions_to_post)

            print(f"âœ… é—¨åº—/å•†åœˆæ•°æ®è¡¥å…¨å®Œæˆ")

        except Exception as e:
            # è¡¥å…¨å¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œé™é»˜å¤„ç†
            print(f"âš ï¸ é—¨åº—/å•†åœˆæ•°æ®è¡¥å…¨å¤±è´¥ï¼ˆä¸å½±å“ä¸»ä»»åŠ¡ï¼‰: {e}")

    def _install_browser(self):
        """è‡ªåŠ¨å®‰è£…Playwrightæµè§ˆå™¨"""
        print("\nâš ï¸ æ£€æµ‹åˆ°Chromiumæµè§ˆå™¨æœªå®‰è£…ï¼Œæ­£åœ¨è‡ªåŠ¨ä¸‹è½½...")
        try:
            process = subprocess.Popen(
                [sys.executable, '-m', 'playwright', 'install', 'chromium'],
                stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1
            )
            for line in process.stdout:
                print(line.strip())
            process.wait()
            return process.returncode == 0
        except Exception as e:
            print(f"å®‰è£…å¤±è´¥: {e}")
            return False

    def _convert_cookies_to_playwright_format(self, cookie_dict: dict) -> list:
        """å°†cookieå­—å…¸è½¬æ¢ä¸ºPlaywrightæ ¼å¼"""
        playwright_cookies = []
        for name, value in cookie_dict.items():
            cookie = {'name': name, 'value': str(value), 'domain': '.dianping.com', 'path': '/'}
            playwright_cookies.append(cookie)
        return playwright_cookies

    def _check_login_status(self, max_retries: int = 2) -> Tuple[bool, str]:
        """æ£€æŸ¥æ˜¯å¦å¤„äºç™»å½•çŠ¶æ€

        Args:
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

        Returns:
            (æ˜¯å¦ç™»å½•, çŠ¶æ€è¯´æ˜)
            - (True, "logged_in") - å·²ç™»å½•
            - (False, "not_logged_in") - æœªç™»å½•ï¼ˆæ£€æµ‹åˆ°ç™»å½•é¡µé¢ï¼‰
            - (False, "timeout") - è¶…æ—¶ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜ï¼‰
            - (False, "error") - å…¶ä»–é”™è¯¯
        """
        for attempt in range(1, max_retries + 1):
            try:
                # ä½¿ç”¨ domcontentloaded è€Œä¸æ˜¯ networkidleï¼Œé¿å…å› æŒç»­ç½‘ç»œè¯·æ±‚å¯¼è‡´è¶…æ—¶
                self.page.goto(
                    "https://e.dianping.com/app/vg-pc-platform-merchant-selfhelp/newNoticeCenter.html",
                    wait_until='domcontentloaded',
                    timeout=LOGIN_CHECK_TIMEOUT
                )
                # ç­‰å¾…é¡µé¢è·³è½¬å®Œå…¨ç¨³å®šï¼Œé¿å… evaluate æ—¶ä¸Šä¸‹æ–‡è¢«é”€æ¯
                try:
                    self.page.wait_for_load_state('networkidle', timeout=5000)
                except Exception:
                    pass
                time.sleep(2)

                current_url = self.page.url
                if 'login' in current_url.lower():
                    logger.warning("æ£€æµ‹åˆ°ç™»å½•é¡µé¢URLï¼Œè´¦æˆ·ç™»å½•çŠ¶æ€å·²å¤±æ•ˆ")
                    return False, "not_logged_in"

                has_content = self.page.evaluate("() => document.body.textContent.length > 100")
                if has_content:
                    return True, "logged_in"
                else:
                    logger.warning("é¡µé¢å†…å®¹ä¸ºç©ºï¼Œå¯èƒ½æœªæ­£ç¡®åŠ è½½")
                    return False, "not_logged_in"

            except Exception as e:
                error_str = str(e).lower()
                is_timeout = 'timeout' in error_str
                is_navigation = 'execution context was destroyed' in error_str or \
                                'most likely because of a navigation' in error_str

                if is_timeout or is_navigation:
                    if attempt < max_retries:
                        delay = calculate_retry_delay(attempt)
                        reason = "è¶…æ—¶" if is_timeout else "é¡µé¢è·³è½¬å¯¼è‡´ä¸Šä¸‹æ–‡é”€æ¯"
                        logger.warning(f"ç™»å½•æ£€æµ‹{reason}ï¼Œç¬¬ {attempt}/{max_retries} æ¬¡å°è¯•ï¼Œ"
                                       f"{delay:.1f} ç§’åé‡è¯•...")
                        time.sleep(delay)
                        continue
                    else:
                        logger.error(f"ç™»å½•æ£€æµ‹å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {e}")
                        return False, "timeout"
                else:
                    logger.error(f"ç™»å½•æ£€æµ‹å¤±è´¥: {e}")
                    return False, "error"

        return False, "error"

    def start_browser(self):
        """å¯åŠ¨æµè§ˆå™¨å¹¶ç™»å½•"""
        # å¦‚æœä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„ pageï¼Œåˆ™ä¸å¯åŠ¨æ–°æµè§ˆå™¨
        if self.use_external_page:
            self.page = self.external_page
            print("âœ“ ä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„æµè§ˆå™¨é¡µé¢ï¼ˆé¡µé¢é©±åŠ¨æ¨¡å¼ï¼‰")
            return

        if not PLAYWRIGHT_AVAILABLE:
            raise Exception("Playwrightæœªå®‰è£…ï¼Œæ— æ³•å¯åŠ¨æµè§ˆå™¨")

        print("\nğŸŒ å¯åŠ¨æµè§ˆå™¨")
        self.playwright = sync_playwright().start()

        max_retries = 2
        for attempt in range(max_retries):
            try:
                self.browser = self.playwright.chromium.launch(headless=self.headless, proxy=None)
                break
            except Exception as e:
                if "Executable doesn't exist" in str(e) and attempt == 0:
                    if self._install_browser():
                        continue
                    else:
                        raise Exception("æµè§ˆå™¨å®‰è£…å¤±è´¥")
                raise e

        use_saved_state = os.path.exists(self.state_file)

        if use_saved_state:
            print(f"âœ“ æ£€æµ‹åˆ°çŠ¶æ€æ–‡ä»¶: {self.state_file}")
            try:
                self.context = self.browser.new_context(
                    storage_state=self.state_file,
                    viewport={'width': 1920, 'height': 1080},
                    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    proxy=None, bypass_csp=True, ignore_https_errors=True
                )
                self.page = self.context.new_page()
                is_logged_in, status = self._check_login_status()
                if is_logged_in:
                    print(f"âœ“ æµè§ˆå™¨å·²å¯åŠ¨ï¼ˆä½¿ç”¨ä¿å­˜çš„çŠ¶æ€ï¼‰")
                    return
                else:
                    self.context.close()
                    use_saved_state = False
            except Exception as e:
                print(f"âš ï¸ çŠ¶æ€æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
                if self.context:
                    self.context.close()
                use_saved_state = False

        if not use_saved_state:
            print("æ­£åœ¨ä½¿ç”¨Cookieç™»å½•...")
            playwright_cookies = self._convert_cookies_to_playwright_format(self.cookies)
            self.context = self.browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                proxy=None, bypass_csp=True, ignore_https_errors=True
            )
            self.context.add_cookies(playwright_cookies)
            self.page = self.context.new_page()

            is_logged_in, status = self._check_login_status()
            if not is_logged_in:
                if status == "not_logged_in":
                    # ç¡®å®æ˜¯ç™»å½•å¤±æ•ˆï¼Œä¸ŠæŠ¥è´¦æˆ·å¤±æ•ˆçŠ¶æ€
                    report_auth_invalid(self.account_name)
                    raise AuthInvalidError("Cookieç™»å½•å¤±è´¥ï¼Œè´¦æˆ·ç™»å½•çŠ¶æ€å·²å¤±æ•ˆ")
                elif status == "timeout":
                    # ç½‘ç»œè¶…æ—¶ï¼Œä¸åº”è¯¥æ ‡è®°ä¸ºç™»å½•å¤±æ•ˆ
                    raise Exception("ç™»å½•æ£€æµ‹è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•")
                else:
                    # å…¶ä»–é”™è¯¯
                    raise Exception(f"ç™»å½•æ£€æµ‹å¤±è´¥: {status}")

            self.context.storage_state(path=self.state_file)
            print(f"âœ“ æµè§ˆå™¨å·²å¯åŠ¨ï¼ˆCookieç™»å½•ï¼‰")

    def stop_browser(self):
        """å…³é—­æµè§ˆå™¨"""
        # å¦‚æœä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„ pageï¼Œåˆ™ä¸å…³é—­æµè§ˆå™¨ï¼ˆç”±å¤–éƒ¨ç®¡ç†ï¼‰
        if self.use_external_page:
            print("âœ“ å¤–éƒ¨æµè§ˆå™¨é¡µé¢ä¿æŒæ‰“å¼€ï¼ˆç”±å¤–éƒ¨ç®¡ç†ï¼‰")
            return

        if self.context:
            self.context.close()
        if self.browser:
            self.browser.close()
        if self.playwright:
            self.playwright.stop()
        print("âœ“ æµè§ˆå™¨å·²å…³é—­")

    def _get_mtgsig(self) -> str:
        """è·å–mtgsig"""
        if self.mtgsig_from_api:
            return self.mtgsig_from_api
        timestamp = int(time.time() * 1000)
        webdfpid = self.cookies.get('WEBDFPID', '')
        a3 = webdfpid.split('-')[0] if webdfpid and '-' in webdfpid else ''
        mtgsig = {"a1": "1.2", "a2": timestamp, "a3": a3, "a5": "", "a6": "", "a8": "", "a9": "4.1.1,7,139", "a10": "9a", "x0": 4, "d1": ""}
        return json.dumps(mtgsig)

    def _get_headers(self) -> Dict[str, str]:
        """è·å–é€šç”¨è¯·æ±‚å¤´"""
        return {
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9',
            'Connection': 'keep-alive',
            'Content-Type': 'application/x-www-form-urlencoded',
            'Origin': 'https://h5.dianping.com',
            'Referer': 'https://h5.dianping.com/',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

    def _calculate_flow_date_range(self) -> str:
        """è®¡ç®—å®¢æµæ•°æ®çš„æ—¥æœŸèŒƒå›´"""
        now = datetime.now()
        if now.hour < 7:
            end_date = now - timedelta(days=2)
        else:
            end_date = now - timedelta(days=1)
        start_date = end_date - timedelta(days=6)
        return f"{start_date.strftime('%Y-%m-%d')},{end_date.strftime('%Y-%m-%d')}"

    def _get_yesterday_date(self) -> str:
        """è·å–æ˜¨å¤©æ—¥æœŸ"""
        return (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')

    def _parse_rank_value(self, value) -> int:
        """è§£ææ’åå€¼"""
        if pd.isna(value) or value == '' or value is None:
            return 0
        value_str = str(value).strip().replace('+', '')
        try:
            return int(float(value_str))
        except:
            return 0

    def _navigate_to_page(self, page_key: str) -> bool:
        """è·³è½¬åˆ°æŒ‡å®šé¡µé¢ï¼ˆstore_statså†…éƒ¨ä½¿ç”¨ï¼‰

        Args:
            page_key: é¡µé¢é”®å (flow_analysis, rival_analysis, trade_analysis, notice_center)

        Returns:
            æ˜¯å¦è·³è½¬æˆåŠŸ
        """
        if not self.page:
            logger.debug("æ²¡æœ‰å¯ç”¨çš„æµè§ˆå™¨é¡µé¢ï¼Œè·³è¿‡é¡µé¢è·³è½¬")
            return True  # æ²¡æœ‰pageæ—¶ä»ç„¶å°è¯•æ‰§è¡Œ

        page_url = STORE_STATS_PAGE_URLS.get(page_key)
        page_name = STORE_STATS_PAGE_NAMES.get(page_key, page_key)

        if not page_url:
            logger.warning(f"æœªæ‰¾åˆ°é¡µé¢URL: {page_key}")
            return True

        return navigate_to_url(self.page, page_url, page_name)

    def get_force_offline_data(self, target_date: str) -> Dict[str, int]:
        """è·å–å¼ºåˆ¶ä¸‹çº¿æ•°æ®ï¼ˆä½¿ç”¨æµè§ˆå™¨ç¯å¢ƒï¼‰"""
        print("\nğŸ“‹ è·å–å¼ºåˆ¶ä¸‹çº¿æ•°æ®ï¼ˆæµè§ˆå™¨æ¨¡å¼ï¼‰")
        print(f"   ç›®æ ‡æ—¥æœŸ: {target_date}")
        force_offline_count = {}

        # è·³è½¬åˆ°æ¶ˆæ¯ä¸­å¿ƒé¡µé¢
        self._navigate_to_page("notice_center")
        random_delay(2, 4)

        if not self.page:
            logger.warning("æ²¡æœ‰å¯ç”¨çš„æµè§ˆå™¨é¡µé¢ï¼Œè·³è¿‡å¼ºåˆ¶ä¸‹çº¿æ•°æ®è·å–")
            return force_offline_count

        try:
            # æ£€æŸ¥é¡µé¢æ˜¯å¦è¢«é‡å®šå‘åˆ°ç™»å½•é¡µ
            current_url = self.page.url.lower()
            if 'login' in current_url or 'passport' in current_url:
                print(f"ğŸš¨ æ£€æµ‹åˆ°é¡µé¢è¢«é‡å®šå‘åˆ°ç™»å½•é¡µï¼ŒCookieå·²å¤±æ•ˆ")
                self.login_invalid = True
                self.login_invalid_error = "è·å–å¼ºåˆ¶ä¸‹çº¿æ•°æ®æ—¶æ£€æµ‹åˆ°Cookieå¤±æ•ˆï¼ˆé‡å®šå‘åˆ°ç™»å½•é¡µï¼‰"
                return force_offline_count

            api_url = "https://e.dianping.com/gateway/msg/MessageDzService/queryPcMessageList"
            target_date_obj = datetime.strptime(target_date, '%Y-%m-%d').date()

            script = f"""
            async () => {{
                try {{
                    const response = await fetch('{api_url}?yodaReady=h5&csecplatform=4&csecversion=4.1.1', {{
                        method: 'POST', credentials: 'include',
                        headers: {{'Content-Type': 'application/json'}},
                        body: JSON.stringify({{"messageCategoryCode": 0, "status": null, "subCategoryIdList": null, "important": 1, "pageNo": 1, "pageSize": 100}})
                    }});
                    const status = response.status;
                    const data = await response.json();
                    return {{success: true, status: status, data: data}};
                }} catch(e) {{
                    return {{success: false, error: e.message}};
                }}
            }}
            """

            result = self.page.evaluate(script)
            if not result.get('success'):
                print(f"âŒ APIè°ƒç”¨å¤±è´¥: {result.get('error')}")
                return force_offline_count

            # æ£€æŸ¥HTTPçŠ¶æ€ç æ˜¯å¦æ˜¯ç™»å½•å¤±æ•ˆ
            http_status = result.get('status', 200)
            if http_status == 401:
                print(f"ğŸš¨ æ£€æµ‹åˆ°HTTP 401ï¼ŒCookieå·²å¤±æ•ˆ")
                self.login_invalid = True
                self.login_invalid_error = "è·å–å¼ºåˆ¶ä¸‹çº¿æ•°æ®æ—¶æ£€æµ‹åˆ°Cookieå¤±æ•ˆï¼ˆHTTP 401ï¼‰"
                return force_offline_count

            api_result = result.get('data', {})
            api_status = api_result.get('status')
            api_msg = api_result.get('msg', '')

            # æ£€æŸ¥APIè¿”å›æ˜¯å¦æ˜¯ç™»å½•å¤±æ•ˆ
            if is_auth_invalid_error(api_status, api_msg):
                print(f"ğŸš¨ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆ: status={api_status}, msg={api_msg}")
                self.login_invalid = True
                self.login_invalid_error = f"è·å–å¼ºåˆ¶ä¸‹çº¿æ•°æ®æ—¶æ£€æµ‹åˆ°Cookieå¤±æ•ˆï¼ˆAPIè¿”å›: status={api_status}, msg={api_msg}ï¼‰"
                return force_offline_count

            if api_status != 0:
                print(f"âŒ APIè¿”å›é”™è¯¯: status={api_status}, msg={api_msg}")
                return force_offline_count

            message_list = api_result.get('messageList', [])
            print(f"   è·å–åˆ° {len(message_list)} æ¡æ¶ˆæ¯")

            for msg in message_list:
                title = msg.get('title', '')
                create_time = msg.get('createTime', 0)
                if 'å¼ºåˆ¶ä¸‹çº¿' not in title:
                    continue
                if create_time:
                    msg_date = datetime.fromtimestamp(create_time / 1000).date()
                    if msg_date != target_date_obj:
                        continue
                    shop_id = msg.get('mtShopId') or self.shop_id
                    if shop_id:
                        shop_id_str = str(shop_id)
                        force_offline_count[shop_id_str] = force_offline_count.get(shop_id_str, 0) + 1
                        print(f"   ğŸ“Œ å‘ç°å¼ºåˆ¶ä¸‹çº¿: é—¨åº—{shop_id_str}")

            print(f"âœ… å¼ºåˆ¶ä¸‹çº¿ç»Ÿè®¡å®Œæˆ: {force_offline_count}")
            return force_offline_count
        except Exception as e:
            print(f"âŒ è·å–å¼ºåˆ¶ä¸‹çº¿æ•°æ®å¤±è´¥: {e}")
            return force_offline_count

    def get_flow_data(self) -> Dict[str, int]:
        """è·å–å®¢æµæ•°æ®ï¼ˆæ‰“å¡æ•°ï¼‰"""
        print("\nğŸ“‹ è·å–å®¢æµæ•°æ®ï¼ˆæ‰“å¡æ•°ï¼‰")

        # è·³è½¬åˆ°å®¢æµåˆ†æé¡µé¢
        self._navigate_to_page("flow_analysis")
        random_delay(2, 4)

        url = "https://e.dianping.com/gateway/adviser/data"
        date_range = self._calculate_flow_date_range()
        print(f"   æ—¥æœŸèŒƒå›´: {date_range}")

        params = {'componentId': 'flowDataSummaryDownloadPCAsync', 'pageType': 'flowAnalysis',
                  'yodaReady': 'h5', 'csecplatform': '4', 'csecversion': '4.1.1', 'mtgsig': self._get_mtgsig()}
        post_data = {'source': '1', 'device': 'pc', 'pageType': 'flowAnalysis', 'shopIds': '0', 'platform': '0', 'date': date_range}
        checkin_data = {}

        try:
            session = self._get_session()
            response = session.post(url, params=params, data=post_data, headers=self._get_headers(), cookies=self.cookies, timeout=60)
            response.raise_for_status()
            result = response.json()

            if result.get('code') != 200:
                print(f"âŒ APIè¿”å›é”™è¯¯")
                return checkin_data

            data_list = result.get('data', [])
            file_url = None
            for item in data_list:
                body = item.get('body', {})
                if body.get('fileUrl'):
                    file_url = body.get('fileUrl')
                    break

            if not file_url:
                print("âŒ æœªè·å–åˆ°æ–‡ä»¶URL")
                return checkin_data

            random_delay()  # åçˆ¬è™«ç­‰å¾…
            print(f"   ğŸ“¥ ä¸‹è½½æ–‡ä»¶...")
            file_response = session.get(file_url, timeout=60)
            df = pd.read_excel(BytesIO(file_response.content))
            print(f"   ğŸ“Š è¯»å–åˆ° {len(df)} è¡Œæ•°æ®")

            date_col = df.columns[0]
            df[date_col] = pd.to_datetime(df[date_col])
            latest_date = df[date_col].max()
            latest_df = df[df[date_col] == latest_date]

            shop_id_col = df.columns[3]
            checkin_col = df.columns[36]  # AMåˆ— - ç¬¬37åˆ— - æ‰“å¡æ•°

            for _, row in latest_df.iterrows():
                shop_id = str(int(row[shop_id_col])) if pd.notna(row[shop_id_col]) else None
                checkin_count = int(row[checkin_col]) if pd.notna(row[checkin_col]) else 0
                if shop_id:
                    checkin_data[shop_id] = checkin_count

            print(f"âœ… å®¢æµæ•°æ®è·å–å®Œæˆ: {len(checkin_data)} ä¸ªé—¨åº—")
            return checkin_data
        except Exception as e:
            print(f"âŒ è·å–å®¢æµæ•°æ®å¤±è´¥: {e}")
            return checkin_data

    def get_rival_rank_data(self) -> Dict[str, Dict[str, int]]:
        """è·å–åŒè¡Œæ’åæ•°æ®"""
        print("\nğŸ“‹ è·å–åŒè¡Œæ’åæ•°æ®")

        # è·³è½¬åˆ°åŒè¡Œåˆ†æé¡µé¢
        self._navigate_to_page("rival_analysis")
        random_delay(2, 4)

        rank_data = {}

        if not self.shop_region_info:
            print("âš ï¸ æ²¡æœ‰é—¨åº—å•†åœˆä¿¡æ¯ï¼Œè·³è¿‡æ’åæ•°æ®è·å–")
            for shop in self.shop_list:
                rank_data[shop['shop_id']] = {'order_user_rank': 0, 'verify_amount_rank': 0}
            return rank_data

        for shop in self.shop_list:
            shop_id = shop['shop_id']
            shop_name = shop['shop_name']
            shop_info = self.shop_region_info.get(shop_id, {})
            regions = shop_info.get('regions', {})
            business = regions.get('business', {})
            region_id = business.get('regionId')

            if not region_id:
                rank_data[shop_id] = {'order_user_rank': 0, 'verify_amount_rank': 0}
                continue

            print(f"   ğŸª è·å–é—¨åº— {shop_name}({shop_id}) çš„æ’åæ•°æ®...")
            shop_rank = self._get_rival_rank_by_shop(shop_id, region_id)
            rank_data[shop_id] = shop_rank
            print(f"      ä¸‹å•æ’å: {shop_rank['order_user_rank']}, æ ¸é”€æ’å: {shop_rank['verify_amount_rank']}")
            random_delay()  # åçˆ¬è™«ç­‰å¾…

        print(f"âœ… åŒè¡Œæ’åæ•°æ®è·å–å®Œæˆ: {len(rank_data)} ä¸ªé—¨åº—")
        return rank_data

    def _get_rival_rank_by_shop(self, shop_id: str, region_id: int) -> Dict[str, int]:
        """è·å–æŒ‡å®šé—¨åº—çš„åŒè¡Œæ’åæ•°æ®"""
        url = "https://e.dianping.com/gateway/adviser/data"
        params = {
            'device': 'pc', 'source': '1', 'pageType': 'rivalAnalysisV2', 'sign': '', 'dateType': '1',
            'platform': '0', 'shopIds': shop_id, 'regionId': str(region_id), 'regionType': 'å•†åœˆ',
            'componentId': 'shopRankListDownload', 'yodaReady': 'h5', 'csecplatform': '4', 'csecversion': '4.1.1', 'mtgsig': self._get_mtgsig()
        }
        headers = {
            'Accept': 'application/json, text/plain, */*', 'Referer': 'https://e.dianping.com/codejoy/2703/home/index.html',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        default_result = {'order_user_rank': 0, 'verify_amount_rank': 0}

        try:
            session = self._get_session()
            response = session.get(url, params=params, headers=headers, cookies=self.cookies, timeout=60)
            response.raise_for_status()
            result = response.json()

            if result.get('code') != 200:
                return default_result

            data_list = result.get('data', [])
            file_url = None
            for item in data_list:
                body = item.get('body', {})
                if body.get('fileUrl'):
                    file_url = body.get('fileUrl')
                    break

            if not file_url:
                return default_result

            file_response = session.get(file_url, timeout=60)
            df = pd.read_excel(BytesIO(file_response.content))

            if len(df) == 0:
                return default_result

            shop_id_col = df.columns[4]
            order_rank_col = df.columns[10]
            verify_rank_col = df.columns[14]

            for _, row in df.iterrows():
                row_shop_id = str(int(row[shop_id_col])) if pd.notna(row[shop_id_col]) else None
                if row_shop_id == shop_id:
                    return {
                        'order_user_rank': self._parse_rank_value(row[order_rank_col]),
                        'verify_amount_rank': self._parse_rank_value(row[verify_rank_col])
                    }
            return default_result
        except Exception as e:
            print(f"      âŒ è·å–æ’åæ•°æ®å¤±è´¥: {e}")
            return default_result

    def get_trade_data(self) -> Dict[str, int]:
        """è·å–å•†å“äº¤æ˜“æ•°æ®ï¼ˆå¹¿å‘Šå•ï¼‰"""
        print("\nğŸ“‹ è·å–å•†å“äº¤æ˜“æ•°æ®ï¼ˆå¹¿å‘Šå•ï¼‰")

        # è·³è½¬åˆ°äº¤æ˜“åˆ†æé¡µé¢
        self._navigate_to_page("trade_analysis")
        random_delay(2, 4)

        ad_data = {}
        for shop in self.shop_list:
            ad_data[shop['shop_id']] = 0

        if not self.product_mapping:
            print("âš ï¸ æ²¡æœ‰å›¢è´­IDæ˜ å°„ï¼Œè·³è¿‡å¹¿å‘Šå•æ•°æ®è·å–")
            return ad_data

        shop_to_brands = {item['shop_id']: item['brands_id'] for item in self.product_mapping}
        url = "https://e.dianping.com/gateway/adviser/data"
        yesterday = self._get_yesterday_date()
        timestamp = int(time.time() * 1000)

        params = {'componentId': 'shopTradeProductRankDownload', 'pageType': 'v5Trade',
                  'yodaReady': 'h5', 'csecplatform': '4', 'csecversion': '4.1.1', 'mtgsig': self._get_mtgsig()}
        post_data = {
            'optionType': 'v5Trade', 'typeIds': '7', 'sortTypeId': '7',
            'prdIds': '1,2,3,4,5,6,11,12,13,14,15,16,17,18,19,20', 'source': '1', 'device': 'pc',
            'date': f'{yesterday},{yesterday}', 'platform': '0', 'pageType': 'v5Trade',
            'shopIds': '', 'excludeShopIds': '', 'cityId': '', 'spuId': '', 'pageNum': '', 'pageSize': '',
            'sign': '', 'fromPage': '', 'storeKey': self.shop_id, 'timeStamp': str(timestamp), 'downloadAllPrdIds': 'true'
        }

        try:
            session = self._get_session()
            response = session.post(url, params=params, data=post_data, headers=self._get_headers(), cookies=self.cookies, timeout=60)
            response.raise_for_status()
            result = response.json()

            if result.get('code') != 200:
                return ad_data

            data_list = result.get('data', [])
            file_url = None
            for item in data_list:
                body = item.get('body', {})
                if body.get('fileUrl'):
                    file_url = body.get('fileUrl')
                    break

            if not file_url:
                return ad_data

            random_delay()  # åçˆ¬è™«ç­‰å¾…
            print(f"   ğŸ“¥ ä¸‹è½½æ–‡ä»¶...")
            file_response = session.get(file_url, timeout=60)
            df = pd.read_excel(BytesIO(file_response.content))
            print(f"   ğŸ“Š è¯»å–åˆ° {len(df)} è¡Œæ•°æ®")

            product_id_col = df.columns[2]
            shop_id_col = df.columns[6]
            order_count_col = df.columns[8]

            for _, row in df.iterrows():
                product_id = str(int(row[product_id_col])) if pd.notna(row[product_id_col]) else None
                row_shop_id = str(int(row[shop_id_col])) if pd.notna(row[shop_id_col]) else None
                order_count = int(row[order_count_col]) if pd.notna(row[order_count_col]) else 0

                if row_shop_id and row_shop_id in shop_to_brands:
                    if product_id == shop_to_brands[row_shop_id]:
                        ad_data[row_shop_id] = order_count
                        print(f"   ğŸ“Œ æ‰¾åˆ°: é—¨åº—ID={row_shop_id}, ä¸‹å•äººæ•°={order_count}")

            print(f"âœ… å•†å“äº¤æ˜“æ•°æ®è·å–å®Œæˆ")
            return ad_data
        except Exception as e:
            print(f"âŒ è·å–å•†å“äº¤æ˜“æ•°æ®å¤±è´¥: {e}")
            return ad_data

    def get_finance_balance(self) -> float:
        """
        è·å–è´¢åŠ¡ä½™é¢ï¼ˆç»¼åˆæ¨å¹¿ä½™é¢ï¼‰

        Returns:
            ä½™é¢é‡‘é¢ï¼Œå¤±è´¥æ—¶è¿”å›0
        """
        print("\nğŸ’° è·å–è´¢åŠ¡ä½™é¢æ•°æ®")

        url = "https://e.dianping.com/adpaccount/finance/account/r/getHomeFinancialDetail"

        headers = {
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'Referer': 'https://e.dianping.com/app/peon-promo-finance/html/flow-home.html',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-origin',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36',
            'X-Requested-With': 'XMLHttpRequest',
            'sec-ch-ua': '"Google Chrome";v="143", "Chromium";v="143", "Not A(Brand";v="24"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"'
        }

        try:
            session = self._get_session()
            response = session.get(
                url,
                headers=headers,
                cookies=self.cookies,
                timeout=30
            )

            # æ£€æŸ¥HTTPçŠ¶æ€ç æ˜¯å¦æ˜¯ç™»å½•å¤±æ•ˆ
            if response.status_code == 401:
                print(f"ğŸš¨ æ£€æµ‹åˆ°HTTP 401ï¼ŒCookieå·²å¤±æ•ˆ")
                self.login_invalid = True
                self.login_invalid_error = "è·å–è´¢åŠ¡ä½™é¢æ—¶æ£€æµ‹åˆ°Cookieå¤±æ•ˆï¼ˆHTTP 401ï¼‰"
                return 0.0

            response.raise_for_status()
            result = response.json()

            # æ£€æŸ¥APIè¿”å›æ˜¯å¦æ˜¯ç™»å½•å¤±æ•ˆ
            api_code = result.get('code')
            api_msg = result.get('msg', '')
            if is_auth_invalid_error(api_code, api_msg):
                print(f"ğŸš¨ æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆ: code={api_code}, msg={api_msg}")
                self.login_invalid = True
                self.login_invalid_error = f"è·å–è´¢åŠ¡ä½™é¢æ—¶æ£€æµ‹åˆ°Cookieå¤±æ•ˆï¼ˆAPIè¿”å›: code={api_code}, msg={api_msg}ï¼‰"
                return 0.0

            if api_code != 0:
                print(f"âŒ APIè¿”å›é”™è¯¯: {api_msg}")
                return 0.0

            data_list = result.get('data', [])
            if not data_list:
                print("âŒ æœªè·å–åˆ°è´¢åŠ¡æ•°æ®")
                return 0.0

            # æŸ¥æ‰¾"ç»¼åˆæ¨å¹¿"çš„ä½™é¢
            for item in data_list:
                product_name = item.get('productName', '')
                if product_name == 'ç»¼åˆæ¨å¹¿':
                    balance = item.get('totalBalance', 0)
                    # ç¡®ä¿balanceæ˜¯æ•°å­—ç±»å‹ï¼Œå»é™¤å¯èƒ½çš„Â¥ç¬¦å·
                    if isinstance(balance, str):
                        balance = balance.replace('Â¥', '').replace('ï¿¥', '').replace(',', '').strip()
                    balance = float(balance) if balance else 0.0
                    print(f"âœ… è´¢åŠ¡ä½™é¢è·å–æˆåŠŸ")
                    print(f"   ç»¼åˆæ¨å¹¿ä½™é¢: {balance:.2f} å…ƒ")
                    return balance

            # å¦‚æœæ²¡æ‰¾åˆ°"ç»¼åˆæ¨å¹¿"ï¼Œè¿”å›ç¬¬ä¸€ä¸ªäº§å“çš„ä½™é¢
            if data_list:
                first_item = data_list[0]
                balance = first_item.get('totalBalance', 0)
                # ç¡®ä¿balanceæ˜¯æ•°å­—ç±»å‹ï¼Œå»é™¤å¯èƒ½çš„Â¥ç¬¦å·
                if isinstance(balance, str):
                    balance = balance.replace('Â¥', '').replace('ï¿¥', '').replace(',', '').strip()
                balance = float(balance) if balance else 0.0
                product_name = first_item.get('productName', 'æœªçŸ¥')
                print(f"âš ï¸ æœªæ‰¾åˆ°'ç»¼åˆæ¨å¹¿'ï¼Œä½¿ç”¨'{product_name}'çš„ä½™é¢")
                print(f"   ä½™é¢: {balance:.2f} å…ƒ")
                return balance

            return 0.0

        except Exception as e:
            print(f"âŒ è·å–è´¢åŠ¡ä½™é¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 0.0

    def collect_and_upload(self, target_date: str, upload_api_url: str) -> bool:
        """æ”¶é›†æ‰€æœ‰æ•°æ®å¹¶ä¸Šä¼ 

        Raises:
            AuthInvalidError: å½“æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆæ—¶æŠ›å‡º
        """
        print("\nğŸš€ å¼€å§‹æ”¶é›†å’Œä¸Šä¼ æ•°æ®")
        print(f"   ç›®æ ‡æ—¥æœŸ: {target_date}")
        print(f"   é—¨åº—æ•°é‡: {len(self.shop_list)}")

        try:
            self.start_browser()

            # è·å–å¼ºåˆ¶ä¸‹çº¿æ•°æ®
            force_offline_data = self.get_force_offline_data(target_date)
            if self.login_invalid:
                raise AuthInvalidError(self.login_invalid_error)
            random_delay()  # åçˆ¬è™«ç­‰å¾…

            # è·å–è´¢åŠ¡ä½™é¢æ•°æ®
            finance_balance = self.get_finance_balance()
            if self.login_invalid:
                raise AuthInvalidError(self.login_invalid_error)
            random_delay()  # åçˆ¬è™«ç­‰å¾…

            # è·å–å®¢æµæ•°æ®
            checkin_data = self.get_flow_data()
            if self.login_invalid:
                raise AuthInvalidError(self.login_invalid_error)
            random_delay()  # åçˆ¬è™«ç­‰å¾…

            # è·å–åŒè¡Œæ’åæ•°æ®
            rank_data = self.get_rival_rank_data()
            if self.login_invalid:
                raise AuthInvalidError(self.login_invalid_error)
            random_delay()  # åçˆ¬è™«ç­‰å¾…

            # è·å–å¹¿å‘Šå•æ•°æ®
            ad_data = self.get_trade_data()
            if self.login_invalid:
                raise AuthInvalidError(self.login_invalid_error)
        finally:
            self.stop_browser()

        # æ›´æ–°å…±äº«ç­¾å
        global SHARED_SIGNATURE
        SHARED_SIGNATURE['mtgsig'] = self.mtgsig_from_api
        SHARED_SIGNATURE['cookies'] = self.cookies
        SHARED_SIGNATURE['updated_at'] = datetime.now()
        SHARED_SIGNATURE['shop_list'] = self.shop_list
        print(f"âœ… å·²æ›´æ–°å…±äº«ç­¾åï¼Œä¾›åç»­ä»»åŠ¡ä½¿ç”¨")

        # æ•´åˆæ•°æ®
        print("\nğŸ“Š æ•´åˆæ•°æ®")
        upload_data_list = []

        for shop in self.shop_list:
            shop_id = shop['shop_id']
            shop_name = shop['shop_name']
            data = {
                "store_name": shop_name,
                "store_id": int(shop_id),
                "checkin_count": checkin_data.get(shop_id, 0),
                "order_user_rank": rank_data.get(shop_id, {}).get('order_user_rank', 0),
                "verify_amount_rank": rank_data.get(shop_id, {}).get('verify_amount_rank', 0),
                "ad_order_count": ad_data.get(shop_id, 0),
                "ad_balance": finance_balance,
                "is_force_offline": force_offline_data.get(shop_id, 0),
                "date": target_date
            }
            upload_data_list.append(data)
            print(f"   ğŸ“Œ é—¨åº—: {shop_name} ({shop_id}) - æ‰“å¡:{data['checkin_count']}, ä¸‹å•æ’å:{data['order_user_rank']}, å¹¿å‘Šå•:{data['ad_order_count']}, å¹¿å‘Šä½™é¢:{finance_balance:.2f}å…ƒ, å¼ºåˆ¶ä¸‹çº¿:{data['is_force_offline']}")

        # ä¸Šä¼ æ•°æ®
        print(f"\nğŸ“¤ ä¸Šä¼ æ•°æ®åˆ°API: {upload_api_url}")
        session = self._get_session()
        success_count = 0
        fail_count = 0

        for idx, data in enumerate(upload_data_list, 1):
            try:
                response = session.post(upload_api_url, json=data, headers={'Content-Type': 'application/json'}, timeout=API_TIMEOUT)
                if response.status_code in [200, 201]:
                    success_count += 1
                    print(f"   [{idx}/{len(upload_data_list)}] âœ… æˆåŠŸ - {data['store_name']}")
                else:
                    fail_count += 1
                    print(f"   [{idx}/{len(upload_data_list)}] âŒ å¤±è´¥ - {data['store_name']}")
                    print(f"      HTTPçŠ¶æ€ç : {response.status_code}")
                    print(f"      å“åº”å†…å®¹: {response.text[:200] if response.text else '(ç©º)'}")
            except Exception as e:
                fail_count += 1
                print(f"   [{idx}/{len(upload_data_list)}] âŒ å¤±è´¥ - {data['store_name']}: {e}")

        print(f"\nğŸ“Š ä¸Šä¼ å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}")
        return fail_count == 0


# ============================================================================
# run_store_stats ä»»åŠ¡å‡½æ•°
# ============================================================================
def run_store_stats(account_name: str, start_date: str, end_date: str, external_page=None,
                    cookies: Dict = None, mtgsig: str = None, shop_info: List = None,
                    compare_regions: Dict = None, brands_json: List = None) -> Dict[str, Any]:
    """æ‰§è¡Œstore_statsä»»åŠ¡ - é—¨åº—ç»Ÿè®¡æ•°æ®é‡‡é›†

    Args:
        account_name: è´¦æˆ·åç§°
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        external_page: å¤–éƒ¨ä¼ å…¥çš„ Playwright page å¯¹è±¡ï¼ˆç”¨äºé¡µé¢é©±åŠ¨æ¨¡å¼ï¼‰
        cookies: å¤–éƒ¨ä¼ å…¥çš„Cookieï¼ˆå¯é€‰ï¼Œé¿å…é‡å¤è°ƒç”¨APIï¼‰
        mtgsig: å¤–éƒ¨ä¼ å…¥çš„ç­¾åï¼ˆå¯é€‰ï¼‰
        shop_info: å¤–éƒ¨ä¼ å…¥çš„é—¨åº—ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        compare_regions: å¤–éƒ¨ä¼ å…¥çš„é—¨åº—å•†åœˆä¿¡æ¯ï¼ˆå¯é€‰ï¼Œç”¨äºåŒè¡Œæ’åï¼‰
        brands_json: å¤–éƒ¨ä¼ å…¥çš„å›¢è´­IDæ˜ å°„ï¼ˆå¯é€‰ï¼Œç”¨äºå¹¿å‘Šå•ï¼‰
    """
    table_name = "store_stats"
    print(f"\n{'=' * 60}")
    if external_page:
        print(f"ğŸª {table_name} (é—¨åº—ç»Ÿè®¡ - é¡µé¢é©±åŠ¨æ¨¡å¼)")
    else:
        print(f"ğŸª {table_name} (é—¨åº—ç»Ÿè®¡ - Playwrightæµè§ˆå™¨æ¨¡å¼)")
    print(f"{'=' * 60}")

    result = {"task_name": table_name, "success": False, "record_count": 0, "error_message": "æ— "}

    # æ£€æŸ¥Playwrightæ˜¯å¦å¯ç”¨ï¼ˆä»…åœ¨éé¡µé¢é©±åŠ¨æ¨¡å¼ä¸‹æ£€æŸ¥ï¼‰
    if not external_page and not PLAYWRIGHT_AVAILABLE:
        error_msg = "Playwrightæœªå®‰è£…ï¼Œstore_statsä»»åŠ¡è·³è¿‡"
        print(f"âŒ {error_msg}")
        result["error_message"] = error_msg
        log_failure(account_name, 0, table_name, start_date, end_date, error_msg)
        return result

    # è®¡ç®—ç›®æ ‡æ—¥æœŸï¼ˆä¼˜å…ˆä½¿ç”¨TARGET_DATEï¼Œå¦åˆ™ä½¿ç”¨END_DATEï¼‰
    if TARGET_DATE:
        target_date = TARGET_DATE
    else:
        target_date = END_DATE

    print(f"   ç›®æ ‡æ—¥æœŸ: {target_date}")
    if external_page:
        print(f"   æµè§ˆå™¨æ¨¡å¼: é¡µé¢é©±åŠ¨æ¨¡å¼ï¼ˆå¤ç”¨å¤–éƒ¨æµè§ˆå™¨ï¼‰")
    else:
        print(f"   æµè§ˆå™¨æ¨¡å¼: {'æ— å¤´æ¨¡å¼' if HEADLESS else 'å¯è§†æ¨¡å¼'}")

    try:
        disable_proxy()

        # åˆ›å»ºé‡‡é›†å™¨ï¼ˆä¼ é€’å¤–éƒ¨æ•°æ®ï¼Œé¿å…é‡å¤è°ƒç”¨APIï¼‰
        collector = DianpingStoreStats(
            account_name,
            PLATFORM_ACCOUNTS_API_URL,
            headless=HEADLESS,
            disable_proxy=True,
            external_page=external_page,
            cookies=cookies,
            mtgsig=mtgsig,
            shop_info=shop_info,
            compare_regions=compare_regions,
            brands_json=brands_json
        )

        # æ‰§è¡Œé‡‡é›†å’Œä¸Šä¼ 
        success = collector.collect_and_upload(
            target_date=target_date,
            upload_api_url=UPLOAD_APIS[table_name]
        )

        if success:
            result["success"] = True
            result["record_count"] = len(collector.shop_list)
            for shop in collector.shop_list:
                log_success(account_name, int(shop['shop_id']), table_name, target_date, target_date, 1)
        else:
            result["error_message"] = "éƒ¨åˆ†æ•°æ®ä¸Šä¼ å¤±è´¥"
            log_failure(account_name, 0, table_name, target_date, target_date, result["error_message"])

    except AuthInvalidError as e:
        # ç™»å½•å¤±æ•ˆå¼‚å¸¸ - è°ƒç”¨ä¸‰ä¸ªæ¥å£ä¸ŠæŠ¥
        error_msg = str(e)
        result["error_message"] = error_msg
        print(f"âŒ ç™»å½•å¤±æ•ˆ: {e}")
        # ä½¿ç”¨ç»Ÿä¸€çš„ç™»å½•å¤±æ•ˆå¤„ç†å‡½æ•°ä¸ŠæŠ¥åˆ°ä¸‰ä¸ªæ¥å£
        handle_auth_invalid(account_name, start_date, end_date, table_name, error_msg)

    except Exception as e:
        error_msg = str(e)
        result["error_message"] = error_msg
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        # ä¸ŠæŠ¥åˆ° /api/log
        log_failure(account_name, 0, table_name, start_date, end_date, error_msg)

    return result


# ============================================================================
# é¡µé¢é©±åŠ¨ä»»åŠ¡æ‰§è¡Œç±» - å…ˆè·³è½¬é¡µé¢å†æ‰§è¡Œå¯¹åº”ä»»åŠ¡
# ============================================================================
class PageDrivenTaskExecutor:
    """é¡µé¢é©±åŠ¨çš„ä»»åŠ¡æ‰§è¡Œå™¨

    å·¥ä½œæµç¨‹:
    1. å¯åŠ¨ Playwright æµè§ˆå™¨
    2. æŒ‰é¡ºåºè·³è½¬åˆ°å„ä¸ªé¡µé¢
    3. åœ¨æ¯ä¸ªé¡µé¢ä¸Šæ‰§è¡Œå¯¹åº”çš„ä»»åŠ¡
    4. å…³é—­æµè§ˆå™¨

    æ‰§è¡Œé¡ºåº:
    - æŠ¥è¡¨é¡µé¢: kewen_daily_report, promotion_daily_report
    - å®¢æµåˆ†æé¡µé¢: store_stats
    - è¯„ä»·é¡µé¢(æœ€å): review_detail_dianping, review_detail_meituan,
                      review_summary_dianping, review_summary_meituan
    """

    PAGE_NAME_MAP = {
        "report": "æŠ¥è¡¨é¡µé¢",
        "flow_analysis": "å®¢æµåˆ†æé¡µé¢",
        "review": "è¯„ä»·é¡µé¢",
    }

    def __init__(self, account_name: str, headless: bool = True, browser_pool: 'BrowserPoolManager' = None):
        """åˆå§‹åŒ–

        Args:
            account_name: è´¦æˆ·åç§°
            headless: æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼
            browser_pool: æµè§ˆå™¨æ± ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨æµè§ˆå™¨æ± æ¨¡å¼ï¼‰
        """
        self.account_name = account_name
        self.headless = headless
        self.state_file = os.path.join(STATE_DIR, f'dianping_state_{account_name}.json')

        # æµè§ˆå™¨æ± æ¨¡å¼
        self.browser_pool = browser_pool
        self.use_pool = browser_pool is not None
        self._context_wrapper = None  # æµè§ˆå™¨æ± æ¨¡å¼ä¸‹çš„ContextåŒ…è£…å™¨

        # Playwrightç›¸å…³
        self.playwright = None
        self.browser = None
        self.context = None
        self.page = None

        # ä»APIè·å–çš„æ•°æ®
        self.cookies = {}
        self.mtgsig = None
        self.shop_info = {}
        self.templates_id = None
        self.compare_regions = {}  # é—¨åº—å•†åœˆä¿¡æ¯ï¼ˆç”¨äºåŒè¡Œæ’åï¼‰
        self.brands_json = []      # å›¢è´­IDæ˜ å°„ï¼ˆç”¨äºå¹¿å‘Šå•ï¼‰

        # æ‰§è¡Œç»“æœ
        self.results = []

        # ç™»å½•å¤±æ•ˆæ ‡å¿— - ä¸€æ—¦æ£€æµ‹åˆ°å¤±æ•ˆï¼Œåœæ­¢åç»­æ‰€æœ‰ä»»åŠ¡
        self.login_invalid = False
        self.login_invalid_error = ""

    def _disable_proxy(self):
        """ç¦ç”¨ç³»ç»Ÿä»£ç†"""
        proxy_vars = [
            'HTTP_PROXY', 'HTTPS_PROXY', 'FTP_PROXY', 'SOCKS_PROXY',
            'http_proxy', 'https_proxy', 'ftp_proxy', 'socks_proxy',
            'ALL_PROXY', 'all_proxy', 'NO_PROXY', 'no_proxy'
        ]
        for var in proxy_vars:
            os.environ.pop(var, None)
        os.environ['NO_PROXY'] = '*'
        os.environ['no_proxy'] = '*'
        print("âœ… å·²ç¦ç”¨ç³»ç»Ÿä»£ç†")

    def _load_account_info(self):
        """åŠ è½½è´¦æˆ·ä¿¡æ¯ï¼ˆä¼˜å…ˆä»æµè§ˆå™¨æ± è·å–Cookieï¼Œæ²¡æœ‰æ‰è°ƒç”¨APIï¼‰

        ä¼˜å…ˆçº§ï¼š
        1. æµè§ˆå™¨æ± ä¸­å·²æœ‰è¯¥è´¦å·çš„Context -> ç›´æ¥ä½¿ç”¨å…¶Cookie
        2. æµè§ˆå™¨æ± æ²¡æœ‰ -> ä»APIè·å–å®Œæ•´ä¿¡æ¯

        æ³¨æ„ï¼šmtgsig, shop_info, templates_id å§‹ç»ˆä»APIè·å–ï¼ˆæµè§ˆå™¨æ± ä¸å­˜å‚¨è¿™äº›ï¼‰
        """
        # æ£€æŸ¥æµè§ˆå™¨æ± æ˜¯å¦å·²æœ‰è¯¥è´¦å·çš„Cookie
        pool_cookies = None
        if self.browser_pool and self.browser_pool.has_context(self.account_name):
            try:
                wrapper = self.browser_pool._contexts.get(self.account_name)
                if wrapper and wrapper.cookies:
                    pool_cookies = wrapper.cookies
                    print(f"\nâœ… ä»æµè§ˆå™¨æ± è·å– Cookieï¼ˆ{len(pool_cookies)} ä¸ªï¼‰")
            except Exception as e:
                print(f"\nâš ï¸ ä»æµè§ˆå™¨æ± è·å–Cookieå¤±è´¥: {e}ï¼Œå°†ä»APIè·å–")

        if pool_cookies:
            # ä½¿ç”¨æµè§ˆå™¨æ± çš„Cookie
            self.cookies = pool_cookies
            # ä½†ä»éœ€ä»APIè·å– mtgsig, shop_info, templates_id, compare_regions, brands_json
            print(f"ğŸ” æ­£åœ¨ä»APIè·å–è´¦æˆ· [{self.account_name}] çš„å…¶ä»–ä¿¡æ¯...")
            api_data = load_cookies_from_api(self.account_name)
            self.mtgsig = api_data['mtgsig']
            self.shop_info = api_data['shop_info']
            self.templates_id = api_data['templates_id']
            self.compare_regions = api_data.get('compare_regions', {})
            self.brands_json = api_data.get('brands_json', [])
            print(f"âœ… è´¦æˆ·ä¿¡æ¯åŠ è½½å®Œæˆï¼ˆCookieæ¥è‡ªæµè§ˆå™¨æ± ï¼‰")
        else:
            # æµè§ˆå™¨æ± æ²¡æœ‰ï¼Œä»APIè·å–å®Œæ•´ä¿¡æ¯
            print(f"\nğŸ” æ­£åœ¨ä»APIè·å–è´¦æˆ· [{self.account_name}] çš„å®Œæ•´ä¿¡æ¯...")
            api_data = load_cookies_from_api(self.account_name)
            self.cookies = api_data['cookies']
            self.mtgsig = api_data['mtgsig']
            self.shop_info = api_data['shop_info']
            self.templates_id = api_data['templates_id']
            self.compare_regions = api_data.get('compare_regions', {})
            self.brands_json = api_data.get('brands_json', [])
            print(f"âœ… è´¦æˆ·ä¿¡æ¯åŠ è½½å®Œæˆï¼ˆæ¥è‡ªAPIï¼‰")

        # åˆå§‹åŒ– SHARED_SIGNATUREï¼ˆä¾›åç»­ä»»åŠ¡å…±äº«ä½¿ç”¨ï¼‰
        global SHARED_SIGNATURE
        SHARED_SIGNATURE['cookies'] = self.cookies
        SHARED_SIGNATURE['mtgsig'] = self.mtgsig
        SHARED_SIGNATURE['shop_list'] = self.shop_info
        SHARED_SIGNATURE['compare_regions'] = self.compare_regions
        SHARED_SIGNATURE['brands_json'] = self.brands_json
        SHARED_SIGNATURE['updated_at'] = datetime.now()

    def _convert_cookies_to_playwright_format(self) -> list:
        """å°†cookieå­—å…¸è½¬æ¢ä¸ºPlaywrightæ ¼å¼"""
        playwright_cookies = []
        for name, value in self.cookies.items():
            cookie = {
                'name': name,
                'value': str(value),
                'domain': '.dianping.com',
                'path': '/'
            }
            playwright_cookies.append(cookie)
        return playwright_cookies

    def _check_login_status(self, max_retries: int = 2) -> Tuple[bool, str]:
        """æ£€æŸ¥æ˜¯å¦å¤„äºç™»å½•çŠ¶æ€

        Args:
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

        Returns:
            (æ˜¯å¦ç™»å½•, çŠ¶æ€è¯´æ˜)
            - (True, "logged_in") - å·²ç™»å½•
            - (False, "not_logged_in") - æœªç™»å½•ï¼ˆæ£€æµ‹åˆ°ç™»å½•é¡µé¢ï¼‰
            - (False, "timeout") - è¶…æ—¶ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜ï¼‰
            - (False, "error") - å…¶ä»–é”™è¯¯
        """
        for attempt in range(1, max_retries + 1):
            try:
                # ä½¿ç”¨ domcontentloaded è€Œä¸æ˜¯ networkidleï¼Œé¿å…å› æŒç»­ç½‘ç»œè¯·æ±‚å¯¼è‡´è¶…æ—¶
                self.page.goto(
                    "https://e.dianping.com/app/vg-pc-platform-merchant-selfhelp/newNoticeCenter.html",
                    wait_until='domcontentloaded',
                    timeout=LOGIN_CHECK_TIMEOUT
                )
                # ç­‰å¾…é¡µé¢è·³è½¬å®Œå…¨ç¨³å®šï¼Œé¿å… evaluate æ—¶ä¸Šä¸‹æ–‡è¢«é”€æ¯
                try:
                    self.page.wait_for_load_state('networkidle', timeout=5000)
                except Exception:
                    pass
                time.sleep(2)

                current_url = self.page.url
                if 'login' in current_url.lower():
                    logger.warning("æ£€æµ‹åˆ°ç™»å½•é¡µé¢URLï¼Œè´¦æˆ·ç™»å½•çŠ¶æ€å·²å¤±æ•ˆ")
                    return False, "not_logged_in"

                has_content = self.page.evaluate("() => document.body.textContent.length > 100")
                if has_content:
                    return True, "logged_in"
                else:
                    logger.warning("é¡µé¢å†…å®¹ä¸ºç©ºï¼Œå¯èƒ½æœªæ­£ç¡®åŠ è½½")
                    return False, "not_logged_in"

            except Exception as e:
                error_str = str(e).lower()
                is_timeout = 'timeout' in error_str
                is_navigation = 'execution context was destroyed' in error_str or \
                                'most likely because of a navigation' in error_str

                if is_timeout or is_navigation:
                    if attempt < max_retries:
                        delay = calculate_retry_delay(attempt)
                        reason = "è¶…æ—¶" if is_timeout else "é¡µé¢è·³è½¬å¯¼è‡´ä¸Šä¸‹æ–‡é”€æ¯"
                        logger.warning(f"ç™»å½•æ£€æµ‹{reason}ï¼Œç¬¬ {attempt}/{max_retries} æ¬¡å°è¯•ï¼Œ"
                                       f"{delay:.1f} ç§’åé‡è¯•...")
                        time.sleep(delay)
                        continue
                    else:
                        logger.error(f"ç™»å½•æ£€æµ‹å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {e}")
                        return False, "timeout"
                else:
                    logger.error(f"ç™»å½•æ£€æµ‹å¤±è´¥: {e}")
                    return False, "error"

        return False, "error"

    def _try_relogin(self) -> bool:
        """å°è¯•ä½¿ç”¨API Cookieé‡æ–°ç™»å½•

        å½“æ£€æµ‹åˆ°Cookieå¤±æ•ˆæ—¶è°ƒç”¨æ­¤æ–¹æ³•å°è¯•é‡æ–°ç™»å½•ã€‚

        æµç¨‹:
        1. å…³é—­å½“å‰æµè§ˆå™¨ä¸Šä¸‹æ–‡
        2. åˆ é™¤æ—§çŠ¶æ€æ–‡ä»¶
        3. é‡æ–°ä»APIè·å–Cookie
        4. ä½¿ç”¨æ–°Cookieåˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡
        5. æ£€æŸ¥ç™»å½•çŠ¶æ€
        6. å¦‚æœæˆåŠŸï¼Œä¿å­˜æ–°çŠ¶æ€æ–‡ä»¶å¹¶è¿”å›True
        7. å¦‚æœå¤±è´¥ï¼Œè¿”å›False

        Returns:
            bool: é‡æ–°ç™»å½•æ˜¯å¦æˆåŠŸ
        """
        print("\n" + "=" * 60)
        print("ğŸ”„ æ£€æµ‹åˆ°Cookieå¤±æ•ˆï¼Œå°è¯•ä½¿ç”¨API Cookieé‡æ–°ç™»å½•...")
        print("=" * 60)

        try:
            # 3. é‡æ–°ä»APIè·å–Cookie
            print(f"ğŸ” æ­£åœ¨ä»APIé‡æ–°è·å–è´¦æˆ· [{self.account_name}] çš„Cookie...")
            api_data = load_cookies_from_api(self.account_name)
            self.cookies = api_data['cookies']
            self.mtgsig = api_data['mtgsig']
            print(f"âœ… æˆåŠŸåŠ è½½ {len(self.cookies)} ä¸ªæ–°cookies")

            # ========== æµè§ˆå™¨æ± æ¨¡å¼ ==========
            if self.use_pool and self.browser_pool:
                print("   ä½¿ç”¨æµè§ˆå™¨æ± æ¨¡å¼é‡æ–°ç™»å½•...")

                # 1. ä»æ± ä¸­ç§»é™¤æ—§Context
                if self.browser_pool.has_context(self.account_name):
                    self.browser_pool.remove_context(self.account_name)
                    print(f"   âœ“ å·²ç§»é™¤æ—§Context")

                self.context = None
                self.page = None
                self._context_wrapper = None

                # 2. ä»æ± ä¸­åˆ›å»ºæ–°Context
                print(f"   æ­£åœ¨åˆ›å»ºæ–°Context...")
                self._context_wrapper = self.browser_pool.get_context(self.account_name, self.cookies)
                if not self._context_wrapper:
                    print(f"âŒ æ— æ³•ä»æµè§ˆå™¨æ± åˆ›å»ºæ–°Context")
                    return False

                self.context = self._context_wrapper.context
                self.page = self._context_wrapper.page

                # 3. è·³è½¬åˆ°é¦–é¡µéªŒè¯ç™»å½•
                try:
                    self.page.goto("https://e.dianping.com/app/merchant-platform/", timeout=30000)
                    time.sleep(2)
                except Exception as e:
                    print(f"   âš ï¸ é¦–é¡µåŠ è½½å¤±è´¥: {e}")

                # 4. æ£€æŸ¥ç™»å½•çŠ¶æ€
                is_logged_in, status = self._check_login_status()

                if is_logged_in:
                    self._context_wrapper.update_last_used()
                    print(f"âœ… é‡æ–°ç™»å½•æˆåŠŸï¼ï¼ˆæµè§ˆå™¨æ± æ¨¡å¼ï¼‰")
                    self.login_invalid = False
                    self.login_invalid_error = ""
                    return True
                else:
                    print(f"âŒ é‡æ–°ç™»å½•å¤±è´¥: {status}")
                    # ç§»é™¤å¤±è´¥çš„Context
                    self.browser_pool.remove_context(self.account_name)
                    return False

            # ========== ä¼ ç»Ÿæ¨¡å¼ ==========
            # 1. å…³é—­å½“å‰æµè§ˆå™¨ä¸Šä¸‹æ–‡ï¼ˆä¿ç•™browserå®ä¾‹ï¼‰
            if self.context:
                try:
                    self.context.close()
                except:
                    pass
                self.context = None
                self.page = None

            # 2. åˆ é™¤æ—§çŠ¶æ€æ–‡ä»¶
            if os.path.exists(self.state_file):
                os.remove(self.state_file)
                print(f"âœ“ å·²åˆ é™¤æ—§çŠ¶æ€æ–‡ä»¶: {self.state_file}")

            # 4. ä½¿ç”¨æ–°Cookieåˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡
            print("æ­£åœ¨ä½¿ç”¨æ–°Cookieç™»å½•...")
            playwright_cookies = self._convert_cookies_to_playwright_format()
            self.context = self.browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                proxy=None,
                bypass_csp=True,
                ignore_https_errors=True
            )
            self.context.add_cookies(playwright_cookies)
            self.page = self.context.new_page()

            # 5. æ£€æŸ¥ç™»å½•çŠ¶æ€
            is_logged_in, status = self._check_login_status()

            if is_logged_in:
                # 6. ç™»å½•æˆåŠŸï¼Œä¿å­˜æ–°çŠ¶æ€æ–‡ä»¶
                self.context.storage_state(path=self.state_file)
                print(f"âœ… é‡æ–°ç™»å½•æˆåŠŸï¼å·²ä¿å­˜æ–°çŠ¶æ€æ–‡ä»¶")
                # é‡ç½®ç™»å½•å¤±æ•ˆæ ‡å¿—
                self.login_invalid = False
                self.login_invalid_error = ""

                # 7. æ›´æ–° SHARED_SIGNATUREï¼ˆä¾›åç»­ä»»åŠ¡ä½¿ç”¨æ–°çš„Cookie/ç­¾åï¼‰
                global SHARED_SIGNATURE
                SHARED_SIGNATURE['cookies'] = self.cookies
                SHARED_SIGNATURE['mtgsig'] = self.mtgsig
                SHARED_SIGNATURE['updated_at'] = datetime.now()
                print(f"âœ… å·²æ›´æ–°å…±äº«ç­¾åï¼ˆé‡æ–°ç™»å½•åï¼‰")

                return True
            else:
                # 7. ç™»å½•å¤±è´¥
                print(f"âŒ é‡æ–°ç™»å½•å¤±è´¥: {status}")
                return False

        except Exception as e:
            print(f"âŒ é‡æ–°ç™»å½•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _install_browser(self):
        """è‡ªåŠ¨å®‰è£…Playwrightæµè§ˆå™¨"""
        print("\nâš ï¸ æ£€æµ‹åˆ°Chromiumæµè§ˆå™¨æœªå®‰è£…ï¼Œæ­£åœ¨è‡ªåŠ¨ä¸‹è½½...")
        try:
            process = subprocess.Popen(
                [sys.executable, '-m', 'playwright', 'install', 'chromium'],
                stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1
            )
            for line in process.stdout:
                print(line.strip())
            process.wait()
            return process.returncode == 0
        except Exception as e:
            print(f"å®‰è£…å¤±è´¥: {e}")
            return False

    def start_browser(self):
        """å¯åŠ¨æµè§ˆå™¨å¹¶ç™»å½•

        æµè§ˆå™¨æ± æ¨¡å¼ï¼šä»æ± ä¸­è·å–Contextï¼Œä¸åˆ›å»ºæ–°æµè§ˆå™¨
        ä¼ ç»Ÿæ¨¡å¼ï¼šåˆ›å»ºæ–°çš„æµè§ˆå™¨å®ä¾‹
        """
        if not PLAYWRIGHT_AVAILABLE:
            raise Exception("Playwrightæœªå®‰è£…ï¼Œæ— æ³•å¯åŠ¨æµè§ˆå™¨")

        # ========== æµè§ˆå™¨æ± æ¨¡å¼ ==========
        if self.use_pool and self.browser_pool:
            print("\nğŸŒ ä½¿ç”¨æµè§ˆå™¨æ± æ¨¡å¼")

            # æ£€æŸ¥æ± ä¸­æ˜¯å¦å·²æœ‰è¯¥è´¦å·çš„Context
            if self.browser_pool.has_context(self.account_name):
                print(f"   âœ“ å‘ç°è´¦å· {self.account_name} çš„ç°æœ‰Context")
                self._context_wrapper = self.browser_pool._contexts[self.account_name]
                self.context = self._context_wrapper.context
                self.page = self._context_wrapper.page

                # æ£€æŸ¥ç™»å½•çŠ¶æ€
                is_logged_in, status = self._check_login_status()
                if is_logged_in:
                    self._context_wrapper.update_last_used()
                    print(f"   âœ“ æµè§ˆå™¨å·²å°±ç»ªï¼ˆä½¿ç”¨æ± ä¸­Contextï¼‰")
                    return
                else:
                    print(f"   âš ï¸ æ± ä¸­Contextç™»å½•å·²å¤±æ•ˆï¼Œéœ€è¦åˆ·æ–°Cookie")
                    # ç§»é™¤å¤±æ•ˆçš„Context
                    self.browser_pool.remove_context(self.account_name)

            # ä»æ± ä¸­åˆ›å»ºæ–°Context
            print(f"   æ­£åœ¨ä¸ºè´¦å· {self.account_name} åˆ›å»ºæ–°Context...")
            self._context_wrapper = self.browser_pool.get_context(self.account_name, self.cookies)
            self.context = self._context_wrapper.context
            self.page = self._context_wrapper.page

            # è·³è½¬åˆ°é¦–é¡µéªŒè¯ç™»å½•
            try:
                self.page.goto("https://e.dianping.com/app/merchant-platform/", timeout=30000)
                time.sleep(2)
            except Exception as e:
                print(f"   âš ï¸ é¦–é¡µåŠ è½½å¤±è´¥: {e}")

            # æ£€æŸ¥ç™»å½•çŠ¶æ€
            is_logged_in, status = self._check_login_status()
            if not is_logged_in:
                if status == "not_logged_in":
                    report_auth_invalid(self.account_name)
                    self.browser_pool.remove_context(self.account_name)
                    raise AuthInvalidError("Cookieç™»å½•å¤±è´¥ï¼Œè´¦æˆ·ç™»å½•çŠ¶æ€å·²å¤±æ•ˆ")
                elif status == "timeout":
                    raise Exception("ç™»å½•æ£€æµ‹è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•")
                else:
                    raise Exception(f"ç™»å½•æ£€æµ‹å¤±è´¥: {status}")

            self._context_wrapper.update_last_used()
            print(f"   âœ“ æµè§ˆå™¨å·²å°±ç»ªï¼ˆæµè§ˆå™¨æ± æ¨¡å¼ï¼Œå·²è·³è½¬é¦–é¡µï¼‰")
            return

        # ========== ä¼ ç»Ÿæ¨¡å¼ ==========
        print("\nğŸŒ å¯åŠ¨æµè§ˆå™¨")
        self.playwright = sync_playwright().start()

        max_retries = 2
        for attempt in range(max_retries):
            try:
                # ä½¿ç”¨WebKitï¼ˆå¦‚æœæµè§ˆå™¨æ± æ¨¡å¼å¯ç”¨ï¼‰æˆ–Chromium
                if USE_BROWSER_POOL and BROWSER_POOL_AVAILABLE:
                    self.browser = self.playwright.webkit.launch(
                        headless=self.headless,
                        proxy=None
                    )
                    print("   ä½¿ç”¨ WebKit å¼•æ“")
                else:
                    self.browser = self.playwright.chromium.launch(
                        headless=self.headless,
                        proxy=None
                    )
                break
            except Exception as e:
                if "Executable doesn't exist" in str(e) and attempt == 0:
                    if self._install_browser():
                        continue
                    else:
                        raise Exception("æµè§ˆå™¨å®‰è£…å¤±è´¥")
                raise e

        use_saved_state = os.path.exists(self.state_file)

        if use_saved_state:
            print(f"âœ“ æ£€æµ‹åˆ°çŠ¶æ€æ–‡ä»¶: {self.state_file}")
            try:
                self.context = self.browser.new_context(
                    storage_state=self.state_file,
                    viewport={'width': 1920, 'height': 1080},
                    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    proxy=None,
                    bypass_csp=True,
                    ignore_https_errors=True
                )
                self.page = self.context.new_page()
                is_logged_in, status = self._check_login_status()
                if is_logged_in:
                    print(f"âœ“ æµè§ˆå™¨å·²å¯åŠ¨ï¼ˆä½¿ç”¨ä¿å­˜çš„çŠ¶æ€ï¼‰")
                    return
                else:
                    self.context.close()
                    use_saved_state = False
            except Exception as e:
                print(f"âš ï¸ çŠ¶æ€æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
                if self.context:
                    self.context.close()
                use_saved_state = False

        if not use_saved_state:
            print("æ­£åœ¨ä½¿ç”¨Cookieç™»å½•...")
            playwright_cookies = self._convert_cookies_to_playwright_format()
            self.context = self.browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                proxy=None,
                bypass_csp=True,
                ignore_https_errors=True
            )
            self.context.add_cookies(playwright_cookies)
            self.page = self.context.new_page()

            is_logged_in, status = self._check_login_status()
            if not is_logged_in:
                if status == "not_logged_in":
                    # ç¡®å®æ˜¯ç™»å½•å¤±æ•ˆï¼Œä¸ŠæŠ¥è´¦æˆ·å¤±æ•ˆçŠ¶æ€
                    report_auth_invalid(self.account_name)
                    raise AuthInvalidError("Cookieç™»å½•å¤±è´¥ï¼Œè´¦æˆ·ç™»å½•çŠ¶æ€å·²å¤±æ•ˆ")
                elif status == "timeout":
                    # ç½‘ç»œè¶…æ—¶ï¼Œä¸åº”è¯¥æ ‡è®°ä¸ºç™»å½•å¤±æ•ˆ
                    raise Exception("ç™»å½•æ£€æµ‹è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•")
                else:
                    # å…¶ä»–é”™è¯¯
                    raise Exception(f"ç™»å½•æ£€æµ‹å¤±è´¥: {status}")

            self.context.storage_state(path=self.state_file)
            print(f"âœ“ æµè§ˆå™¨å·²å¯åŠ¨ï¼ˆCookieç™»å½•ï¼‰")

    def stop_browser(self):
        """å…³é—­æµè§ˆå™¨

        æµè§ˆå™¨æ± æ¨¡å¼ï¼šä¸å…³é—­Contextï¼Œä¿ç•™åœ¨æ± ä¸­ä¾›ä¿æ´»ä½¿ç”¨
        ä¼ ç»Ÿæ¨¡å¼ï¼šå…³é—­æµè§ˆå™¨
        """
        # æµè§ˆå™¨æ± æ¨¡å¼ï¼šä¸å…³é—­ï¼Œä¿ç•™Contextä¾›åç»­ä½¿ç”¨
        if self.use_pool and self._context_wrapper:
            print("âœ“ ä»»åŠ¡å®Œæˆï¼ˆæµè§ˆå™¨æ± æ¨¡å¼ï¼ŒContextä¿ç•™åœ¨æ± ä¸­ï¼‰")

            # ä¸Šä¼ æœ€æ–°Cookieåˆ°é˜Ÿåˆ—
            if BROWSER_POOL_AVAILABLE and not self.login_invalid:
                try:
                    cookies = self._context_wrapper.get_cookies()
                    if cookies:
                        cookie_upload_queue.put(self.account_name, cookies)
                        print("   âœ“ Cookieå·²åŠ å…¥ä¸Šä¼ é˜Ÿåˆ—")
                except Exception as e:
                    print(f"   âš ï¸ Cookieä¸Šä¼ å¤±è´¥: {e}")
            return

        # ä¼ ç»Ÿæ¨¡å¼ï¼šå…³é—­æµè§ˆå™¨
        if self.context:
            self.context.close()
        if self.browser:
            self.browser.close()
        if self.playwright:
            self.playwright.stop()
        print("âœ“ æµè§ˆå™¨å·²å…³é—­")

    def navigate_to_page(self, page_key: str, max_retries: int = 2):
        """è·³è½¬åˆ°æŒ‡å®šé¡µé¢

        Args:
            page_key: é¡µé¢é”®å (report, flow_analysis, review)
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        page_url = PAGE_URLS.get(page_key)
        page_name = self.PAGE_NAME_MAP.get(page_key, page_key)

        if not page_url:
            logger.warning(f"æœªæ‰¾åˆ°é¡µé¢URL: {page_key}")
            return False

        print(f"\n{'=' * 60}")
        print(f"ğŸ”— æ­£åœ¨è·³è½¬åˆ° {page_name}...")
        print(f"   URL: {page_url[:80]}...")
        print(f"{'=' * 60}")

        for attempt in range(1, max_retries + 1):
            try:
                # ä½¿ç”¨ load è€Œä¸æ˜¯ networkidleï¼Œé¿å…å› æŒç»­ç½‘ç»œè¯·æ±‚å¯¼è‡´è¶…æ—¶
                self.page.goto(page_url, wait_until='load', timeout=BROWSER_PAGE_TIMEOUT)
                time.sleep(3)  # ç­‰å¾…é¡µé¢ç¨³å®š

                # æ£€æŸ¥æ˜¯å¦è¢«é‡å®šå‘åˆ°ç™»å½•é¡µé¢
                current_url = self.page.url.lower()
                if 'login' in current_url or 'passport' in current_url:
                    print(f"ğŸš¨ æ£€æµ‹åˆ°é¡µé¢è¢«é‡å®šå‘åˆ°ç™»å½•é¡µï¼ŒCookieå·²å¤±æ•ˆ")
                    self.login_invalid = True
                    self.login_invalid_error = "é¡µé¢è·³è½¬æ—¶æ£€æµ‹åˆ°Cookieå¤±æ•ˆï¼ˆé‡å®šå‘åˆ°ç™»å½•é¡µï¼‰"
                    return False

                # æ£€æŸ¥é¡µé¢å†…å®¹æ˜¯å¦åŒ…å«ç™»å½•å¤±æ•ˆæç¤º
                try:
                    page_content = self.page.content()
                    if 'è¯·é‡æ–°ç™»å½•' in page_content or 'ç™»å½•çŠ¶æ€å¤±æ•ˆ' in page_content or 'æœªç™»å½•' in page_content:
                        print(f"ğŸš¨ æ£€æµ‹åˆ°é¡µé¢åŒ…å«ç™»å½•å¤±æ•ˆæç¤ºï¼ŒCookieå·²å¤±æ•ˆ")
                        self.login_invalid = True
                        self.login_invalid_error = "é¡µé¢è·³è½¬æ—¶æ£€æµ‹åˆ°Cookieå¤±æ•ˆï¼ˆé¡µé¢æç¤ºæœªç™»å½•ï¼‰"
                        return False
                except:
                    pass  # è·å–é¡µé¢å†…å®¹å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œ

                # å¤„ç†é—¨åº—æƒé™é—®é¢˜ï¼ˆè‡ªåŠ¨åˆ‡æ¢åˆ°å…¨éƒ¨é—¨åº—ï¼‰
                handle_shop_permission_issue(self.page)

                print(f"âœ… å·²è·³è½¬åˆ° {page_name}")
                return True
            except Exception as e:
                error_str = str(e).lower()
                is_timeout = 'timeout' in error_str

                if is_timeout and attempt < max_retries:
                    delay = calculate_retry_delay(attempt)
                    logger.warning(f"é¡µé¢åŠ è½½è¶…æ—¶ï¼Œç¬¬ {attempt}/{max_retries} æ¬¡å°è¯•ï¼Œ"
                                   f"{delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    continue
                else:
                    logger.error(f"è·³è½¬å¤±è´¥: {e}")
                    return False

        return False

    def execute_page_tasks(self, page_key: str, start_date: str, end_date: str) -> List[Dict[str, Any]]:
        """æ‰§è¡ŒæŒ‡å®šé¡µé¢çš„æ‰€æœ‰ä»»åŠ¡

        Args:
            page_key: é¡µé¢é”®å
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            ä»»åŠ¡æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        tasks = PAGE_TASKS.get(page_key, [])
        page_name = self.PAGE_NAME_MAP.get(page_key, page_key)
        results = []

        # è¿‡æ»¤æ‰å·²ç¦ç”¨çš„ä»»åŠ¡
        enabled_tasks = [t for t in tasks if not TASK_DISABLED_FLAGS.get(t, False)]
        disabled_tasks = [t for t in tasks if TASK_DISABLED_FLAGS.get(t, False)]

        print(f"\nğŸ“‹ {page_name} éœ€è¦æ‰§è¡Œ {len(enabled_tasks)} ä¸ªä»»åŠ¡: {', '.join(enabled_tasks)}")
        if disabled_tasks:
            print(f"   â­ï¸ å·²ç¦ç”¨ä»»åŠ¡: {', '.join(disabled_tasks)}")

        # ä¸ºç¦ç”¨çš„ä»»åŠ¡æ·»åŠ æˆåŠŸçŠ¶æ€
        for task_name in disabled_tasks:
            logger.info(f"ä»»åŠ¡ {task_name} å·²ç¦ç”¨ï¼Œè·³è¿‡æ‰§è¡Œï¼ˆè¿”å›æˆåŠŸï¼‰")
            results.append({
                "task_name": task_name,
                "success": True,
                "record_count": 0,
                "error_message": "ä»»åŠ¡å·²ç¦ç”¨(é»˜è®¤æˆåŠŸ)"
            })

        for task_name in enabled_tasks:
            print(f"\n{'â”€' * 50}")
            print(f"â–¶ å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_name}")
            print(f"{'â”€' * 50}")

            # è·å–æœ€æ–°çš„å…±äº«æ•°æ®ï¼ˆå¯èƒ½è¢«å‰ä¸€ä¸ªä»»åŠ¡æ›´æ–°ï¼Œå¦‚ store_stats æ›´æ–°ç­¾åï¼‰
            current_cookies = SHARED_SIGNATURE.get('cookies') or self.cookies
            current_mtgsig = SHARED_SIGNATURE.get('mtgsig') or self.mtgsig
            current_shop_info = SHARED_SIGNATURE.get('shop_list') or self.shop_info
            current_compare_regions = SHARED_SIGNATURE.get('compare_regions') or self.compare_regions
            current_brands_json = SHARED_SIGNATURE.get('brands_json') or self.brands_json

            task_func = TASK_MAP.get(task_name)
            if task_func:
                # æ‰€æœ‰ä»»åŠ¡éƒ½ä¼ é€’å…±äº«çš„ cookies, mtgsig, shop_infoï¼ˆé¿å…é‡å¤è°ƒç”¨APIï¼‰
                if task_name == 'store_stats':
                    result = task_func(
                        self.account_name, start_date, end_date,
                        external_page=self.page,
                        cookies=current_cookies,
                        mtgsig=current_mtgsig,
                        shop_info=current_shop_info,
                        compare_regions=current_compare_regions,
                        brands_json=current_brands_json
                    )
                elif task_name == 'kewen_daily_report':
                    result = task_func(
                        self.account_name, start_date, end_date,
                        templates_id=self.templates_id,
                        cookies=current_cookies,
                        mtgsig=current_mtgsig
                    )
                elif task_name == 'promotion_daily_report':
                    result = task_func(
                        self.account_name, start_date, end_date,
                        cookies=current_cookies,
                        mtgsig=current_mtgsig
                    )
                elif task_name in ('review_detail_dianping', 'review_detail_meituan',
                                   'review_summary_dianping', 'review_summary_meituan'):
                    result = task_func(
                        self.account_name, start_date, end_date,
                        cookies=current_cookies,
                        mtgsig=current_mtgsig,
                        shop_info=current_shop_info
                    )
                else:
                    # å…¶ä»–ä»»åŠ¡ï¼ˆå…¼å®¹ï¼‰
                    result = task_func(self.account_name, start_date, end_date)
                results.append(result)

                if result.get('success'):
                    print(f"âœ… ä»»åŠ¡ {task_name} æ‰§è¡ŒæˆåŠŸ")
                else:
                    print(f"âŒ ä»»åŠ¡ {task_name} æ‰§è¡Œå¤±è´¥: {result.get('error_message')}")
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°ä»»åŠ¡å‡½æ•°: {task_name}")
                results.append({
                    "task_name": task_name,
                    "success": False,
                    "record_count": 0,
                    "error_message": f"æœªæ‰¾åˆ°ä»»åŠ¡å‡½æ•°"
                })

            # ä»»åŠ¡é—´éšæœºå»¶è¿Ÿ
            random_delay(2, 4)

        return results

    def run_all_tasks(self, start_date: str, end_date: str) -> List[Dict[str, Any]]:
        """æŒ‰é¡µé¢é¡ºåºæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡

        æ‰§è¡Œé¡ºåº:
        1. å®¢æµåˆ†æé¡µé¢: store_stats (å…ˆæ‰§è¡Œï¼Œæ›´æ–°ç­¾å)
        2. æŠ¥è¡¨é¡µé¢: kewen_daily_report, promotion_daily_report
        3. è¯„ä»·é¡µé¢(æœ€å): 4ä¸ªè¯„ä»·ç›¸å…³ä»»åŠ¡

        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            æ‰€æœ‰ä»»åŠ¡çš„æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        print("\n" + "=" * 80)
        print("ğŸš€ é¡µé¢é©±åŠ¨ä»»åŠ¡æ‰§è¡Œæ¨¡å¼")
        print("=" * 80)
        print(f"æ‰§è¡Œé¡ºåº:")
        for i, page_key in enumerate(PAGE_ORDER, 1):
            page_name = self.PAGE_NAME_MAP.get(page_key)
            tasks = PAGE_TASKS.get(page_key, [])
            print(f"   {i}. {page_name}: {', '.join(tasks)}")
        print("=" * 80)

        all_results = []

        try:
            self._disable_proxy()
            self._load_account_info()
            self.start_browser()

            # ========== æ£€æŸ¥å¹¶è‡ªåŠ¨è·å–/åˆ›å»º templates_id ==========
            if not self.templates_id or self.templates_id == 0 or str(self.templates_id) == '0':
                print("\n" + "=" * 60)
                print("âš ï¸ templates_id æœªè·å–åˆ°ï¼Œå¼€å§‹è‡ªåŠ¨è·å–/åˆ›å»º...")
                print("=" * 60)

                # å…ˆè·³è½¬åˆ°æŠ¥è¡¨ä¸­å¿ƒé¡µé¢
                print(f"\nğŸ“ è·³è½¬åˆ°æŠ¥è¡¨ä¸­å¿ƒé¡µé¢...")
                try:
                    self.page.goto(REPORT_CENTER_URL, wait_until='networkidle', timeout=BROWSER_PAGE_TIMEOUT)
                    random_delay(2, 3)
                    print("   âœ… é¡µé¢åŠ è½½å®Œæˆ")

                    # è°ƒç”¨ ensure_template_id è·å–æˆ–åˆ›å»ºæ¨¡æ¿ID
                    new_templates_id = ensure_template_id(self.account_name, self.cookies, self.mtgsig)

                    if new_templates_id:
                        self.templates_id = new_templates_id
                        print(f"\nâœ… å·²æˆåŠŸè·å– templates_id: {self.templates_id}")
                    else:
                        print("\nâŒ æ— æ³•è·å– templates_idï¼Œkewen_daily_report ä»»åŠ¡å¯èƒ½å¤±è´¥")
                except Exception as e:
                    print(f"âŒ è·å–/åˆ›å»ºæ¨¡æ¿IDå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()

            for page_key in PAGE_ORDER:
                # æ£€æŸ¥æ˜¯å¦å·²ç»æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆ
                if self.login_invalid:
                    print(f"\nğŸš¨ å·²æ£€æµ‹åˆ°Cookieå¤±æ•ˆï¼Œå°è¯•é‡æ–°ç™»å½•...")
                    # å°è¯•é‡æ–°ç™»å½•
                    if self._try_relogin():
                        print(f"âœ… é‡æ–°ç™»å½•æˆåŠŸï¼Œç»§ç»­æ‰§è¡Œä»»åŠ¡")
                        # é‡æ–°ç™»å½•æˆåŠŸï¼Œç»§ç»­æ‰§è¡Œå½“å‰é¡µé¢
                    else:
                        print(f"âŒ é‡æ–°ç™»å½•å¤±è´¥ï¼Œåœæ­¢åç»­æ‰€æœ‰ä»»åŠ¡")
                        # é‡æ–°ç™»å½•å¤±è´¥ï¼Œä¸ŠæŠ¥å¹¶é€€å‡º
                        report_auth_invalid(self.account_name)
                        # å°†å‰©ä½™ä»»åŠ¡æ ‡è®°ä¸ºå¤±è´¥
                        for remaining_page_key in PAGE_ORDER[PAGE_ORDER.index(page_key):]:
                            for task_name in PAGE_TASKS.get(remaining_page_key, []):
                                all_results.append({
                                    "task_name": task_name,
                                    "success": False,
                                    "record_count": 0,
                                    "error_message": f"Cookieå¤±æ•ˆä¸”é‡æ–°ç™»å½•å¤±è´¥: {self.login_invalid_error}"
                                })
                        break

                page_name = self.PAGE_NAME_MAP.get(page_key)

                # è·³è½¬åˆ°é¡µé¢
                if not self.navigate_to_page(page_key):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å› ä¸ºç™»å½•å¤±æ•ˆå¯¼è‡´çš„è·³è½¬å¤±è´¥
                    if self.login_invalid:
                        print(f"ğŸš¨ é¡µé¢è·³è½¬å¤±è´¥ï¼Œæ£€æµ‹åˆ°Cookieå·²å¤±æ•ˆï¼Œå°è¯•é‡æ–°ç™»å½•...")
                        # å°è¯•é‡æ–°ç™»å½•
                        if self._try_relogin():
                            print(f"âœ… é‡æ–°ç™»å½•æˆåŠŸï¼Œé‡æ–°è·³è½¬é¡µé¢")
                            # é‡æ–°ç™»å½•æˆåŠŸï¼Œé‡æ–°å°è¯•è·³è½¬
                            if not self.navigate_to_page(page_key):
                                # é‡æ–°è·³è½¬ä»ç„¶å¤±è´¥
                                print(f"âš ï¸ é‡æ–°ç™»å½•åé¡µé¢è·³è½¬ä»ç„¶å¤±è´¥ï¼Œè·³è¿‡ {page_name} çš„ä»»åŠ¡")
                                for task_name in PAGE_TASKS.get(page_key, []):
                                    all_results.append({
                                        "task_name": task_name,
                                        "success": False,
                                        "record_count": 0,
                                        "error_message": f"é‡æ–°ç™»å½•åé¡µé¢è·³è½¬å¤±è´¥"
                                    })
                                continue
                            # è·³è½¬æˆåŠŸï¼Œç»§ç»­æ‰§è¡Œä»»åŠ¡ï¼ˆä¸éœ€è¦breakæˆ–continueï¼‰
                        else:
                            print(f"âŒ é‡æ–°ç™»å½•å¤±è´¥ï¼Œåœæ­¢åç»­æ‰€æœ‰ä»»åŠ¡")
                            # é‡æ–°ç™»å½•å¤±è´¥ï¼Œä¸ŠæŠ¥å¹¶é€€å‡º
                            handle_auth_invalid(self.account_name, start_date, end_date,
                                              "page_navigate", self.login_invalid_error)
                            # å°†æ‰€æœ‰ä»»åŠ¡æ ‡è®°ä¸ºå¤±è´¥
                            for remaining_page_key in PAGE_ORDER[PAGE_ORDER.index(page_key):]:
                                for task_name in PAGE_TASKS.get(remaining_page_key, []):
                                    all_results.append({
                                        "task_name": task_name,
                                        "success": False,
                                        "record_count": 0,
                                        "error_message": f"Cookieå¤±æ•ˆä¸”é‡æ–°ç™»å½•å¤±è´¥: {self.login_invalid_error}"
                                    })
                            break
                    else:
                        # æ™®é€šè·³è½¬å¤±è´¥ï¼Œè·³è¿‡è¯¥é¡µé¢çš„ä»»åŠ¡
                        print(f"âš ï¸ è·³è¿‡ {page_name} çš„ä»»åŠ¡")
                        for task_name in PAGE_TASKS.get(page_key, []):
                            all_results.append({
                                "task_name": task_name,
                                "success": False,
                                "record_count": 0,
                                "error_message": f"é¡µé¢è·³è½¬å¤±è´¥"
                            })
                        continue

                # æ‰§è¡Œè¯¥é¡µé¢çš„ä»»åŠ¡
                results = self.execute_page_tasks(page_key, start_date, end_date)
                all_results.extend(results)

                # æ£€æŸ¥ä»»åŠ¡æ‰§è¡Œç»“æœä¸­æ˜¯å¦æœ‰ç™»å½•å¤±æ•ˆ
                for result in results:
                    error_msg = result.get('error_message', '')
                    if 'ç™»å½•å¤±æ•ˆ' in error_msg or 'Cookieå¤±æ•ˆ' in error_msg:
                        self.login_invalid = True
                        self.login_invalid_error = error_msg
                        break

                # å¦‚æœæ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆï¼Œå°è¯•é‡æ–°ç™»å½•
                if self.login_invalid:
                    print(f"\nğŸš¨ ä»»åŠ¡æ‰§è¡Œä¸­æ£€æµ‹åˆ°Cookieå¤±æ•ˆï¼Œå°è¯•é‡æ–°ç™»å½•...")
                    # å°è¯•é‡æ–°ç™»å½•
                    if self._try_relogin():
                        print(f"âœ… é‡æ–°ç™»å½•æˆåŠŸï¼Œç»§ç»­æ‰§è¡Œåç»­ä»»åŠ¡")
                        # é‡æ–°ç™»å½•æˆåŠŸï¼Œç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªé¡µé¢çš„ä»»åŠ¡
                    else:
                        print(f"âŒ é‡æ–°ç™»å½•å¤±è´¥ï¼Œåœæ­¢åç»­ä»»åŠ¡")
                        # é‡æ–°ç™»å½•å¤±è´¥ï¼Œå°†åœ¨ä¸‹ä¸€æ¬¡å¾ªç¯çš„é¡¶éƒ¨æ£€æŸ¥ä¸­å¤„ç†
                        continue

                # é¡µé¢é—´éšæœºå»¶è¿Ÿ
                random_delay(3, 5)

        except Exception as e:
            error_msg = str(e)
            print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {error_msg}")
            import traceback
            traceback.print_exc()

            # å¦‚æœæ˜¯ç™»å½•å¤±è´¥ï¼ŒåŒæ—¶ä¸ŠæŠ¥æ—¥å¿—åˆ°ä¸¤ä¸ªæ¥å£
            if "ç™»å½•å¤±è´¥" in error_msg or "Cookieç™»å½•å¤±è´¥" in error_msg or "ç™»å½•å¤±æ•ˆ" in error_msg:
                print(f"\nğŸ“¤ ä¸ŠæŠ¥ç™»å½•å¤±è´¥æ—¥å¿—...")
                handle_auth_invalid(self.account_name, start_date, end_date, "task_execution", error_msg)
        finally:
            self.stop_browser()

        return all_results


def run_page_driven_tasks(account_name: str, start_date: str, end_date: str, headless: bool = True, browser_pool: 'BrowserPoolManager' = None) -> List[Dict[str, Any]]:
    """æ‰§è¡Œé¡µé¢é©±åŠ¨çš„ä»»åŠ¡

    è¿™æ˜¯é¡µé¢é©±åŠ¨æ¨¡å¼çš„å…¥å£å‡½æ•°ï¼Œä¼šæŒ‰ç…§ä»¥ä¸‹é¡ºåºæ‰§è¡Œ:
    1. è·³è½¬å®¢æµåˆ†æé¡µé¢ â†’ æ‰§è¡Œ store_stats (å…ˆæ‰§è¡Œï¼Œæ›´æ–°ç­¾å)
    2. è·³è½¬æŠ¥è¡¨é¡µé¢ â†’ æ‰§è¡Œ kewen_daily_report, promotion_daily_report
    3. è·³è½¬è¯„ä»·é¡µé¢ â†’ æ‰§è¡Œ 4ä¸ªè¯„ä»·ä»»åŠ¡ (æœ€åæ‰§è¡Œ)

    Args:
        account_name: è´¦æˆ·åç§°
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        headless: æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼
        browser_pool: æµè§ˆå™¨æ± ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨æµè§ˆå™¨æ± æ¨¡å¼ï¼‰

    Returns:
        æ‰€æœ‰ä»»åŠ¡çš„æ‰§è¡Œç»“æœåˆ—è¡¨
    """
    if not PLAYWRIGHT_AVAILABLE:
        print("âŒ Playwrightæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨é¡µé¢é©±åŠ¨æ¨¡å¼")
        return []

    executor = PageDrivenTaskExecutor(account_name, headless=headless, browser_pool=browser_pool)
    return executor.run_all_tasks(start_date, end_date)


# ============================================================================
# ä»»åŠ¡æ˜ å°„å’Œä¸»å‡½æ•°
# ============================================================================
TASK_MAP = {
    'store_stats': run_store_stats,
    'kewen_daily_report': run_kewen_daily_report,
    'promotion_daily_report': run_promotion_daily_report,
    'review_detail_dianping': run_review_detail_dianping,
    'review_detail_meituan': run_review_detail_meituan,
    'review_summary_dianping': run_review_summary_dianping,
    'review_summary_meituan': run_review_summary_meituan,
}


# ============================================================================
# ä»»åŠ¡è°ƒåº¦APIå‡½æ•°
# ============================================================================
def create_task_schedule() -> bool:
    """ç”Ÿæˆä»»åŠ¡è°ƒåº¦

    è°ƒç”¨ post_task_schedule APIï¼Œè‡ªåŠ¨è®¡ç®—æ—¥æœŸï¼š
    - task_date: å½“æ—¥æ—¥æœŸ
    - data_start_date: å‰å¤©æ—¥æœŸ
    - data_end_date: æ˜¨å¤©æ—¥æœŸ

    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    today = datetime.now()
    task_date = today.strftime("%Y-%m-%d")
    data_start_date = (today - timedelta(days=2)).strftime("%Y-%m-%d")
    data_end_date = (today - timedelta(days=1)).strftime("%Y-%m-%d")

    headers = {'Content-Type': 'application/json'}
    json_param = {
        "task_date": task_date,
        "data_start_date": data_start_date,
        "data_end_date": data_end_date
    }
    proxies = {'http': None, 'https': None}

    print(f"\n{'=' * 80}")
    print("ğŸ“… ç”Ÿæˆä»»åŠ¡è°ƒåº¦")
    print(f"{'=' * 80}")
    print(f"   URL: {TASK_SCHEDULE_API_URL}")
    print(f"   task_date (å½“æ—¥): {task_date}")
    print(f"   data_start_date (å‰å¤©): {data_start_date}")
    print(f"   data_end_date (æ˜¨å¤©): {data_end_date}")

    try:
        response = requests.post(
            TASK_SCHEDULE_API_URL,
            headers=headers,
            data=json.dumps(json_param),
            proxies=proxies,
            timeout=30
        )
        print(f"   HTTPçŠ¶æ€ç : {response.status_code}")
        print(f"   å“åº”å†…å®¹: {response.text[:500] if response.text else '(ç©º)'}")

        if response.status_code == 200:
            print("   âœ… ä»»åŠ¡è°ƒåº¦ç”ŸæˆæˆåŠŸ")
            return True
        else:
            print(f"   âŒ ä»»åŠ¡è°ƒåº¦ç”Ÿæˆå¤±è´¥: HTTP {response.status_code}")
            return False
    except Exception as e:
        print(f"   âŒ ä»»åŠ¡è°ƒåº¦ç”Ÿæˆå¼‚å¸¸: {e}")
        return False


def fetch_task(server_ip: str = None) -> Optional[Dict[str, Any]]:
    """è·å–ä¸€æ¡å¾…æ‰§è¡Œä»»åŠ¡

    è°ƒç”¨ get_task API è·å–ä»»åŠ¡ä¿¡æ¯

    Args:
        server_ip: æœåŠ¡å™¨IPåœ°å€ï¼ˆç”¨äºä»»åŠ¡åˆ†é…ï¼‰

    Returns:
        dict: ä»»åŠ¡ä¿¡æ¯ï¼ŒåŒ…å« id, account_id, task_type, data_start_date, data_end_date ç­‰
        None: å¦‚æœæ²¡æœ‰ä»»åŠ¡æˆ–è·å–å¤±è´¥
    """
    headers = {'Content-Type': 'application/json'}
    proxies = {'http': None, 'https': None}

    print(f"\n{'=' * 80}")
    print("ğŸ“‹ è·å–å¾…æ‰§è¡Œä»»åŠ¡")
    print(f"{'=' * 80}")
    print(f"   URL: {GET_TASK_API_URL}")

    # æ„å»ºè¯·æ±‚å‚æ•°
    json_param = {}
    if server_ip:
        json_param["server"] = server_ip
        print(f"   Server IP: {server_ip}")

    try:
        response = requests.post(
            GET_TASK_API_URL,
            json=json_param,
            proxies=proxies,
            timeout=30
        )
        print(f"   HTTPçŠ¶æ€ç : {response.status_code}")
        print(f"   å“åº”å†…å®¹: {response.text[:500] if response.text else '(ç©º)'}")

        if response.status_code == 200:
            result = response.json()
            # APIè¿”å›æ ¼å¼: {"success":true,"data":{...}}
            task_data = result.get('data') if result.get('success') else None
            if task_data:
                print(f"   âœ… è·å–ä»»åŠ¡æˆåŠŸ")
                print(f"   ä»»åŠ¡ID: {task_data.get('id')}")
                print(f"   è´¦æˆ·: {task_data.get('account_id')}")
                print(f"   ä»»åŠ¡ç±»å‹: {task_data.get('task_type')}")
                print(f"   æ•°æ®æ—¥æœŸ: {task_data.get('data_start_date')} è‡³ {task_data.get('data_end_date')}")
                return task_data
            else:
                print("   âš ï¸ æ²¡æœ‰å¾…æ‰§è¡Œçš„ä»»åŠ¡")
                return None
        else:
            print(f"   âŒ è·å–ä»»åŠ¡å¤±è´¥: HTTP {response.status_code}")
            return None
    except Exception as e:
        print(f"   âŒ è·å–ä»»åŠ¡å¼‚å¸¸: {e}")
        return None


def report_task_callback(task_id: int, status: int, error_message: str, retry_add: int) -> bool:
    """ä¸ŠæŠ¥ä»»åŠ¡å®ŒæˆçŠ¶æ€

    Args:
        task_id: ä»»åŠ¡ID (ä»fetch_taskè·å–)
        status: çŠ¶æ€ (2=å…¨éƒ¨å®Œæˆ, 3=æœ‰ä»»åŠ¡å¤±è´¥)
        error_message: é”™è¯¯ä¿¡æ¯ (status=3æ—¶éœ€è¦å¡«å†™)
        retry_add: é‡è¯•æ¬¡æ•°å¢åŠ  (status=2æ—¶ä¸º0, status=3æ—¶ä¸º1)

    Returns:
        bool: æ˜¯å¦ä¸ŠæŠ¥æˆåŠŸ
    """
    headers = {'Content-Type': 'application/json'}
    json_param = {
        "id": task_id,
        "status": status,
        "error_message": error_message,
        "retry_add": retry_add
    }
    proxies = {'http': None, 'https': None}

    print(f"\n{'=' * 80}")
    print("ğŸ“¤ ä¸ŠæŠ¥ä»»åŠ¡å®ŒæˆçŠ¶æ€")
    print(f"{'=' * 80}")
    print(f"   URL: {TASK_CALLBACK_API_URL}")
    print(f"   ä»»åŠ¡ID: {task_id}")
    print(f"   çŠ¶æ€: {status} ({'å…¨éƒ¨å®Œæˆ' if status == 2 else 'æœ‰ä»»åŠ¡å¤±è´¥'})")
    if error_message:
        print(f"   é”™è¯¯ä¿¡æ¯: {error_message[:200]}...")
    print(f"   retry_add: {retry_add}")

    try:
        response = requests.post(
            TASK_CALLBACK_API_URL,
            headers=headers,
            data=json.dumps(json_param),
            proxies=proxies,
            timeout=30
        )
        print(f"   HTTPçŠ¶æ€ç : {response.status_code}")
        print(f"   å“åº”å†…å®¹: {response.text[:500] if response.text else '(ç©º)'}")

        if response.status_code == 200:
            print("   âœ… ä»»åŠ¡çŠ¶æ€ä¸ŠæŠ¥æˆåŠŸ")
            return True
        else:
            print(f"   âŒ ä»»åŠ¡çŠ¶æ€ä¸ŠæŠ¥å¤±è´¥: HTTP {response.status_code}")
            return False
    except Exception as e:
        print(f"   âŒ ä»»åŠ¡çŠ¶æ€ä¸ŠæŠ¥å¼‚å¸¸: {e}")
        return False


def reset_task_schedule(task_id: int) -> bool:
    """é‡ç½®ä»»åŠ¡çŠ¶æ€ï¼ˆèµ„æºä¸è¶³æ—¶å½’è¿˜ä»»åŠ¡ï¼‰

    å½“èµ„æºçŠ¶æ€ä¸ºcriticalæ— æ³•æ‰§è¡Œä»»åŠ¡æ—¶ï¼Œè°ƒç”¨æ­¤æ¥å£å°†ä»»åŠ¡çŠ¶æ€ä»1é‡ç½®ä¸º0ï¼Œ
    è®©ä»»åŠ¡é‡æ–°è¿›å…¥å¾…æ‰§è¡Œé˜Ÿåˆ—ï¼Œé¿å…ä»»åŠ¡ä¸¢å¤±ã€‚

    Args:
        task_id: ä»»åŠ¡ID

    Returns:
        bool: æ˜¯å¦é‡ç½®æˆåŠŸ
    """
    headers = {'Content-Type': 'application/json'}
    json_param = {"id": task_id}
    proxies = {'http': None, 'https': None}

    print(f"   ğŸ”„ é‡ç½®ä»»åŠ¡ {task_id}ï¼ˆèµ„æºä¸è¶³ï¼Œå½’è¿˜ä»»åŠ¡ï¼‰...")

    try:
        response = requests.post(
            TASK_RESET_API_URL,
            headers=headers,
            data=json.dumps(json_param),
            proxies=proxies,
            timeout=30
        )

        if response.status_code == 200:
            print(f"   âœ… ä»»åŠ¡ {task_id} å·²é‡ç½®ï¼Œå°†åœ¨èµ„æºæ¢å¤åé‡æ–°æ‰§è¡Œ")
            return True
        else:
            print(f"   âŒ ä»»åŠ¡é‡ç½®å¤±è´¥: HTTP {response.status_code}")
            return False
    except Exception as e:
        print(f"   âŒ ä»»åŠ¡é‡ç½®å¼‚å¸¸: {e}")
        return False


def reschedule_failed_tasks() -> bool:
    """é‡æ–°è°ƒåº¦å¤±è´¥çš„ä»»åŠ¡

    è°ƒç”¨ reschedule-failed APIï¼Œè®©å¤±è´¥çš„ä»»åŠ¡é‡æ–°è¿›å…¥è°ƒåº¦é˜Ÿåˆ—

    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    headers = {'Content-Type': 'application/json'}
    proxies = {'http': None, 'https': None}

    print(f"\n{'=' * 80}")
    print("ğŸ”„ é‡æ–°è°ƒåº¦å¤±è´¥ä»»åŠ¡")
    print(f"{'=' * 80}")
    print(f"   URL: {RESCHEDULE_FAILED_API_URL}")

    try:
        response = requests.post(
            RESCHEDULE_FAILED_API_URL,
            json={},
            proxies=proxies,
            timeout=30
        )
        print(f"   HTTPçŠ¶æ€ç : {response.status_code}")
        print(f"   å“åº”å†…å®¹: {response.text[:500] if response.text else '(ç©º)'}")

        if response.status_code == 200:
            print("   âœ… å¤±è´¥ä»»åŠ¡é‡æ–°è°ƒåº¦æˆåŠŸ")
            return True
        else:
            print(f"   âŒ å¤±è´¥ä»»åŠ¡é‡æ–°è°ƒåº¦å¤±è´¥: HTTP {response.status_code}")
            return False
    except Exception as e:
        print(f"   âŒ å¤±è´¥ä»»åŠ¡é‡æ–°è°ƒåº¦å¼‚å¸¸: {e}")
        return False


def validate_date(date_str: str) -> bool:
    """éªŒè¯æ—¥æœŸæ ¼å¼"""
    try:
        datetime.strptime(date_str, '%Y-%m-%d')
        return True
    except ValueError:
        return False


def print_summary(results: List[Dict[str, Any]]):
    """æ‰“å°æ‰§è¡Œæ‘˜è¦"""
    print("\n" + "=" * 80)
    print("æ‰§è¡Œæ‘˜è¦")
    print("=" * 80)

    success_count = sum(1 for r in results if r.get('success'))
    print(f"æ€»ä»»åŠ¡æ•°: {len(results)}, æˆåŠŸ: {success_count}, å¤±è´¥: {len(results) - success_count}")
    print("-" * 40)

    for result in results:
        status = "âœ…" if result.get('success') else "âŒ"
        print(f"{status} {result.get('task_name')}: è®°å½•æ•°={result.get('record_count', 0)}, é”™è¯¯={result.get('error_message', 'æ— ')}")

    print("=" * 80)


def execute_single_task(task_info: Dict[str, Any], browser_pool: 'BrowserPoolManager' = None) -> bool:
    """æ‰§è¡Œå•ä¸ªä»»åŠ¡

    Args:
        task_info: ä»APIè·å–çš„ä»»åŠ¡ä¿¡æ¯
        browser_pool: æµè§ˆå™¨æ± ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨æµè§ˆå™¨æ± æ¨¡å¼ï¼‰

    Returns:
        bool: ä»»åŠ¡æ˜¯å¦æ‰§è¡ŒæˆåŠŸ
    """
    global ACCOUNT_NAME, START_DATE, END_DATE, TASK, TARGET_DATE

    task_id = task_info.get("id")

    # å¡«å……é…ç½®å˜é‡
    ACCOUNT_NAME = task_info.get("account_id", "")
    START_DATE = task_info.get("data_start_date", "")
    END_DATE = task_info.get("data_end_date", "")
    TASK = task_info.get("task_type", "all")
    TARGET_DATE = ""

    account_name = ACCOUNT_NAME
    start_date = START_DATE
    end_date = END_DATE
    task = TASK

    # è¯„ä»·è¯¦ç»†ä»»åŠ¡ä½¿ç”¨è¿‘7å¤©æ—¥æœŸï¼ˆæ˜¨å¤©å¾€å‰æ¨6å¤©ï¼‰
    if task in ['review_detail_dianping', 'review_detail_meituan']:
        today = datetime.now()
        end_date = (today - timedelta(days=1)).strftime("%Y-%m-%d")  # æ˜¨å¤©
        start_date = (today - timedelta(days=7)).strftime("%Y-%m-%d")  # æ˜¨å¤©å¾€å‰6å¤©
        START_DATE = start_date
        END_DATE = end_date

    print(f"\n{'=' * 80}")
    print("ğŸ“Œ ä»»åŠ¡é…ç½®")
    print(f"{'=' * 80}")
    print(f"   ä»»åŠ¡ID: {task_id}")
    print(f"   è´¦æˆ·åç§°: {account_name}")
    print(f"   æ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}")
    print(f"   ä»»åŠ¡ç±»å‹: {task}")

    # éªŒè¯å‚æ•°
    if not account_name:
        error_msg = "è´¦æˆ·åç§°ä¸ºç©º"
        print(f"âŒ {error_msg}")
        report_task_callback(task_id, status=3, error_message=error_msg, retry_add=1)
        return False

    if not validate_date(start_date) or not validate_date(end_date):
        error_msg = "æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œåº”ä¸º YYYY-MM-DD"
        print(f"âŒ {error_msg}")
        report_task_callback(task_id, status=3, error_message=error_msg, retry_add=1)
        return False

    start = datetime.strptime(start_date, '%Y-%m-%d')
    end = datetime.strptime(end_date, '%Y-%m-%d')
    if start > end:
        error_msg = "å¼€å§‹æ—¥æœŸä¸èƒ½å¤§äºç»“æŸæ—¥æœŸ"
        print(f"âŒ {error_msg}")
        report_task_callback(task_id, status=3, error_message=error_msg, retry_add=1)
        return False

    valid_tasks = ['all'] + list(TASK_MAP.keys())
    if task not in valid_tasks:
        error_msg = f"æ— æ•ˆçš„ä»»åŠ¡åç§°: {task}ï¼Œå¯é€‰å€¼: {', '.join(valid_tasks)}"
        print(f"âŒ {error_msg}")
        report_task_callback(task_id, status=3, error_message=error_msg, retry_add=1)
        return False

    # ========== è·å–å¹³å°è´¦æˆ·ä¿¡æ¯å¹¶æ£€æŸ¥ templates_id ==========
    print(f"\n{'=' * 80}")
    print("ğŸ” æ£€æŸ¥å¹³å°è´¦æˆ·é…ç½®")
    print(f"{'=' * 80}")

    platform_account = get_platform_account(account_name)

    if not platform_account.get('success'):
        error_msg = f"è·å–å¹³å°è´¦æˆ·ä¿¡æ¯å¤±è´¥: {platform_account.get('error_message', 'æœªçŸ¥é”™è¯¯')}"
        print(f"âŒ {error_msg}")
        # åŒæ—¶ä¸ŠæŠ¥åˆ°ä¸¤ä¸ªæ—¥å¿—æ¥å£
        log_failure(account_name, 0, "platform_account_check", start_date, end_date, error_msg)
        upload_task_status_batch(account_name, start_date, end_date, [{
            'task_name': 'platform_account_check',
            'success': False,
            'record_count': 0,
            'error_message': error_msg
        }])
        report_task_callback(task_id, status=3, error_message=error_msg, retry_add=1)
        return False

    # æ£€æŸ¥ auth_status æ˜¯å¦ä¸ºæ— æ•ˆçŠ¶æ€
    auth_status = platform_account.get('auth_status')
    if auth_status == 'invalid':
        error_msg = f"è´¦æˆ·Cookieå·²å¤±æ•ˆ(auth_status=invalid)ï¼Œè¯·é‡æ–°ç™»å½•"
        print(f"âŒ {error_msg}")
        # åŒæ—¶ä¸ŠæŠ¥åˆ°ä¸¤ä¸ªæ—¥å¿—æ¥å£
        log_failure(account_name, 0, "auth_status_check", start_date, end_date, error_msg)
        upload_task_status_batch(account_name, start_date, end_date, [{
            'task_name': 'auth_status_check',
            'success': False,
            'record_count': 0,
            'error_message': error_msg
        }])
        # retry_add=0 é¿å…æ— æ•ˆé‡è¯•ï¼ˆCookieæœªæ›´æ–°æ—¶é‡è¯•æ²¡æœ‰æ„ä¹‰ï¼‰
        report_task_callback(task_id, status=3, error_message=error_msg, retry_add=0)
        return False

    templates_id = platform_account.get('templates_id')
    if templates_id == 0 or templates_id is None:
        print("\n" + "=" * 60)
        print("âš ï¸ templates_id æœªè·å–åˆ°ï¼Œå¼€å§‹è‡ªåŠ¨è·å–/åˆ›å»º...")
        print("=" * 60)

        # è·å– cookies ç”¨äºè°ƒç”¨æ¨¡æ¿API
        cookies = platform_account.get('cookie', {})
        mtgsig = platform_account.get('mtgsig')

        # ä½¿ç”¨æµè§ˆå™¨è·³è½¬é¡µé¢åè·å–/åˆ›å»ºæ¨¡æ¿ID
        templates_id = ensure_template_id_with_browser(account_name, cookies, mtgsig, headless=HEADLESS, browser_pool=browser_pool)

        if templates_id:
            print(f"âœ… å·²æˆåŠŸè·å– templates_id: {templates_id}")
        else:
            error_msg = "æ— æ³•è·å–æˆ–åˆ›å»ºæŠ¥è¡¨æ¨¡æ¿ID"
            print(f"âŒ {error_msg}")
            # åŒæ—¶ä¸ŠæŠ¥åˆ°ä¸¤ä¸ªæ—¥å¿—æ¥å£
            log_failure(account_name, 0, "templates_id_check", start_date, end_date, error_msg)
            upload_task_status_batch(account_name, start_date, end_date, [{
                'task_name': 'templates_id_check',
                'success': False,
                'record_count': 0,
                'error_message': error_msg
            }])
            report_task_callback(task_id, status=3, error_message=error_msg, retry_add=1)
            return False

    print(f"   âœ… templates_id æ£€æŸ¥é€šè¿‡: {templates_id}")

    print("\n" + "=" * 80)
    print("ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡")
    print("=" * 80)
    if task == 'all':
        print(f"æ‰§è¡Œæ¨¡å¼: é¡µé¢é©±åŠ¨æ¨¡å¼ - å…ˆè·³è½¬é¡µé¢å†æ‰§è¡Œä»»åŠ¡")
        print(f"æ‰§è¡Œé¡ºåº:")
        print(f"   1. å®¢æµåˆ†æé¡µé¢: store_stats (å…ˆæ‰§è¡Œï¼Œæ›´æ–°ç­¾å)")
        print(f"   2. æŠ¥è¡¨é¡µé¢: kewen_daily_report, promotion_daily_report")
        print(f"   3. è¯„ä»·é¡µé¢: review_detail_dianping, review_detail_meituan,")
        print(f"                review_summary_dianping, review_summary_meituan")
    print("=" * 80)

    # æ‰§è¡Œä»»åŠ¡
    results = []
    try:
        if task == 'all':
            results = run_page_driven_tasks(
                account_name=account_name,
                start_date=start_date,
                end_date=end_date,
                headless=HEADLESS,
                browser_pool=browser_pool
            )
        else:
            result = TASK_MAP[task](account_name, start_date, end_date)
            results.append(result)
    except Exception as e:
        error_msg = f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}"
        print(f"âŒ {error_msg}")
        report_task_callback(task_id, status=3, error_message=error_msg, retry_add=1)
        return False

    print_summary(results)

    # ä¸ŠæŠ¥ä»»åŠ¡çŠ¶æ€
    if task == 'all':
        upload_task_status_batch(account_name, start_date, end_date, results)
    else:
        if results:
            upload_task_status_single(account_name, start_date, end_date, results[0])

    # æ”¶é›†é”™è¯¯å¹¶ä¸ŠæŠ¥ä»»åŠ¡å›è°ƒ
    task_errors = []
    for result in results:
        if not result.get('success'):
            task_name = result.get('task_name', 'æœªçŸ¥ä»»åŠ¡')
            error_msg = result.get('error_message', 'æœªçŸ¥é”™è¯¯')
            task_errors.append(f"[{task_name}] {error_msg}")

    if len(task_errors) == 0:
        report_task_callback(task_id, status=2, error_message="", retry_add=0)
        return True
    else:
        all_errors = "\n".join(task_errors)
        report_task_callback(task_id, status=3, error_message=all_errors, retry_add=1)
        return False


def main():
    """ä¸»å‡½æ•° - å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼

    æŒç»­å¾ªç¯è¿è¡Œï¼Œè‡ªåŠ¨è·å–å¹¶æ‰§è¡Œä»»åŠ¡:
    1. æ£€æŸ¥æ—¶é—´çª—å£ (DEV_MODE=Trueæ—¶24å°æ—¶è¿è¡Œ)
    2. ç”Ÿæˆä»»åŠ¡è°ƒåº¦
    3. è·å–ä»»åŠ¡å¹¶æ‰§è¡Œ
    4. æ— ä»»åŠ¡æ—¶ç­‰å¾…5åˆ†é’Ÿåé‡è¯•
    5. æ”¯æŒ Ctrl+C ä¼˜é›…é€€å‡º

    æµè§ˆå™¨æ± æ¨¡å¼ (USE_BROWSER_POOL=True):
    - å¯åŠ¨æ—¶åˆå§‹åŒ–æµè§ˆå™¨æ± 
    - å¯åŠ¨ä¿æ´»æœåŠ¡ï¼ˆ24å°æ—¶ä¿æŒCookieæ´»è·ƒï¼‰
    - ä½¿ç”¨æœåŠ¡å™¨IPè·å–ä»»åŠ¡
    - é€€å‡ºæ—¶ä¿å­˜çŠ¶æ€
    """
    global _daemon_running

    # ========== åˆå§‹åŒ– ==========
    print("\n" + "=" * 80)
    print("ç¾å›¢ç‚¹è¯„æ•°æ®é‡‡é›†ç³»ç»Ÿ (å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼)")
    print("=" * 80)
    print(f"   è¿è¡Œæ¨¡å¼: {'å¼€å‘æ¨¡å¼ (24å°æ—¶è¿è¡Œ)' if DEV_MODE else f'ç”Ÿäº§æ¨¡å¼ ({WORK_START_HOUR}:00-{WORK_END_HOUR}:00)'}")
    print(f"   æµè§ˆå™¨æ± : {'å¯ç”¨' if USE_BROWSER_POOL and BROWSER_POOL_AVAILABLE else 'ç¦ç”¨'}")
    print(f"   æ— ä»»åŠ¡ç­‰å¾…: {NO_TASK_WAIT_SECONDS // 60} åˆ†é’Ÿ")
    print(f"   æ•°æ®ç›®å½•: {DATA_DIR}")
    print(f"   çŠ¶æ€ç›®å½•: {STATE_DIR}")
    print(f"   ä¸‹è½½ç›®å½•: {DOWNLOAD_DIR}")
    print("=" * 80)

    # è®¾ç½®ä¿¡å·å¤„ç†å™¨
    _setup_signal_handlers()

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    ensure_directories()

    # æµè§ˆå™¨æ± å’Œä¿æ´»æœåŠ¡
    browser_pool_instance = None
    keepalive_service = None
    server_ip = None

    # ========== æµè§ˆå™¨æ± æ¨¡å¼åˆå§‹åŒ– ==========
    if USE_BROWSER_POOL and BROWSER_POOL_AVAILABLE:
        try:
            print("\nğŸš€ åˆå§‹åŒ–æµè§ˆå™¨æ± æ¨¡å¼...")

            # è·å–æœåŠ¡å™¨å…¬ç½‘IP
            server_ip = get_public_ip()
            if not server_ip:
                print("âš ï¸ æ— æ³•è·å–æœåŠ¡å™¨IPï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼")
            else:
                print(f"   æœåŠ¡å™¨IP: {server_ip}")

                # åˆå§‹åŒ–æµè§ˆå™¨æ± 
                browser_pool_instance = initialize_browser_pool(headless=HEADLESS)

                # å¯åŠ¨ä¿æ´»æœåŠ¡
                keepalive_service = start_keepalive_service(browser_pool_instance)

                print("âœ… æµè§ˆå™¨æ± æ¨¡å¼åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            print(f"âŒ æµè§ˆå™¨æ± åˆå§‹åŒ–å¤±è´¥: {e}")
            print("   å°†ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼è¿è¡Œ")
            browser_pool_instance = None
            keepalive_service = None

    # ç»Ÿè®¡ä¿¡æ¯
    total_tasks = 0
    success_tasks = 0
    failed_tasks = 0

    print("\nğŸš€ å¼€å§‹å®ˆæŠ¤è¿›ç¨‹å¾ªç¯...")
    print("   æŒ‰ Ctrl+C å¯ä¼˜é›…é€€å‡º\n")

    # ========== ä¸»å¾ªç¯ ==========
    try:
        while _daemon_running:
            try:
                # ========== Step 1: æ—¶é—´çª—å£æ£€æŸ¥ ==========
                if not is_in_work_window():
                    wait_seconds = seconds_until_work_start()
                    hours = wait_seconds // 3600
                    minutes = (wait_seconds % 3600) // 60
                    print(f"\n{'=' * 60}")
                    print(f"ğŸ’¤ å½“å‰éå·¥ä½œæ—¶é—´ ({WORK_START_HOUR}:00-{WORK_END_HOUR}:00)")
                    print(f"   å°†åœ¨ {hours}å°æ—¶{minutes}åˆ†é’Ÿ åå¼€å§‹å·¥ä½œ...")
                    print(f"{'=' * 60}")

                    if not interruptible_sleep(wait_seconds):
                        break  # æ”¶åˆ°é€€å‡ºä¿¡å·
                    continue

                # ========== Step 2: ç”Ÿæˆä»»åŠ¡è°ƒåº¦ ==========
                create_task_schedule()
                time.sleep(5)

                # ========== Step 3: è·å–ä»»åŠ¡ ==========
                # æµè§ˆå™¨æ± æ¨¡å¼ä¸‹ä¼ å…¥æœåŠ¡å™¨IP
                if browser_pool_instance and server_ip:
                    task_info = fetch_task(server_ip=server_ip)
                else:
                    task_info = fetch_task()

                if not task_info:
                    print(f"\nâ³ æš‚æ— å¾…æ‰§è¡Œä»»åŠ¡ï¼Œ{NO_TASK_WAIT_SECONDS // 60}åˆ†é’Ÿåé‡è¯•...")
                    reschedule_failed_tasks()

                    # åœ¨ç­‰å¾…æœŸé—´æ‰§è¡Œä¿æ´»ï¼ˆåŒæ­¥æ¨¡å¼ + èµ„æºä¿æŠ¤ï¼‰
                    if keepalive_service and browser_pool_instance:
                        # åˆ†æ®µç­‰å¾…ï¼Œæ¯60ç§’æ£€æŸ¥ä¸€æ¬¡
                        remaining_wait = NO_TASK_WAIT_SECONDS
                        keepalive_check_interval = 60  # æ¯60ç§’æ£€æŸ¥ä¸€æ¬¡

                        while remaining_wait > 0 and _daemon_running:
                            # ç­‰å¾…ä¸€å°æ®µæ—¶é—´
                            sleep_chunk = min(keepalive_check_interval, remaining_wait)
                            if not interruptible_sleep(sleep_chunk):
                                break  # æ”¶åˆ°é€€å‡ºä¿¡å·
                            remaining_wait -= sleep_chunk

                            if not _daemon_running or remaining_wait <= 0:
                                break

                            # ===== èµ„æºæ£€æŸ¥ä¸è‡ªåŠ¨è°ƒèŠ‚ =====
                            try:
                                status = resource_monitor.check_status(force=True)

                                if status == resource_monitor.STATUS_CRITICAL:
                                    # å±é™©ï¼šç´§æ€¥é‡Šæ”¾èµ„æº
                                    print("\nğŸš¨ èµ„æºå±é™©ï¼æ‰§è¡Œç´§æ€¥é‡Šæ”¾...")
                                    resource_monitor.print_status()
                                    browser_pool_instance.emergency_release()
                                    # è·³è¿‡ä¿æ´»
                                    continue

                                elif status == resource_monitor.STATUS_WARNING:
                                    # è­¦å‘Šï¼šé‡Šæ”¾ç©ºé—²Contextï¼Œè·³è¿‡ä¿æ´»
                                    resource_monitor.print_status()
                                    browser_pool_instance.release_idle_contexts()
                                    # è·³è¿‡ä¿æ´»
                                    continue

                                # æ­£å¸¸ï¼šæ‰§è¡Œä¿æ´»
                                keepalive_service.perform_keepalive_batch()

                                # æ‰§è¡ŒContextæ•°é‡é™åˆ¶
                                browser_pool_instance.enforce_context_limit()

                            except Exception as e:
                                print(f"   âš ï¸ ç©ºé—²å¤„ç†å¼‚å¸¸: {e}")

                        if not _daemon_running:
                            break  # æ”¶åˆ°é€€å‡ºä¿¡å·
                    else:
                        # éæµè§ˆå™¨æ± æ¨¡å¼ï¼Œç›´æ¥ç­‰å¾…
                        if not interruptible_sleep(NO_TASK_WAIT_SECONDS):
                            break  # æ”¶åˆ°é€€å‡ºä¿¡å·

                    continue

                # ========== Step 4: æ‰§è¡Œä»»åŠ¡ ==========

                # èµ„æºæ£€æŸ¥ï¼ˆä»»åŠ¡æ‰§è¡Œå‰ï¼‰
                if browser_pool_instance and BROWSER_POOL_AVAILABLE:
                    status = resource_monitor.check_status(force=True)
                    if status == resource_monitor.STATUS_CRITICAL:
                        print("\nğŸš¨ èµ„æºå±é™©ï¼æš‚åœä»»åŠ¡æ‰§è¡Œï¼Œç­‰å¾…èµ„æºæ¢å¤...")
                        resource_monitor.print_status()
                        # é‡ç½®ä»»åŠ¡çŠ¶æ€ï¼Œé¿å…ä»»åŠ¡ä¸¢å¤±
                        task_id = task_info.get('id')
                        if task_id:
                            reset_task_schedule(task_id)
                        browser_pool_instance.emergency_release()
                        # ç­‰å¾…30ç§’åé‡è¯•
                        if not interruptible_sleep(30):
                            break
                        continue

                total_tasks += 1

                # æµè§ˆå™¨æ± æ¨¡å¼ä¸‹ä½¿ç”¨è´¦å·é”
                if browser_pool_instance:
                    account_id = task_info.get('account_id')
                    # è·å–è´¦å·é”ï¼ˆé˜»å¡ç­‰å¾…ï¼Œæœ€å¤šç­‰60ç§’ï¼‰
                    if account_lock_manager.acquire(account_id, blocking=True, timeout=60):
                        try:
                            success = execute_single_task(task_info, browser_pool=browser_pool_instance)
                        finally:
                            account_lock_manager.release(account_id)
                    else:
                        print(f"âš ï¸ è´¦å· {account_id} é”è·å–è¶…æ—¶ï¼Œè·³è¿‡æ­¤ä»»åŠ¡")
                        success = False
                else:
                    success = execute_single_task(task_info)

                if success:
                    success_tasks += 1
                else:
                    failed_tasks += 1

                # ========== Step 5: é‡æ–°è°ƒåº¦å¤±è´¥ä»»åŠ¡ ==========
                reschedule_failed_tasks()

                # æ‰“å°å½“å‰ç»Ÿè®¡
                print(f"\nğŸ“Š ç´¯è®¡ç»Ÿè®¡: æ€»ä»»åŠ¡={total_tasks}, æˆåŠŸ={success_tasks}, å¤±è´¥={failed_tasks}")

                # çŸ­æš‚ç­‰å¾…åç»§ç»­ä¸‹ä¸€è½®
                time.sleep(2)

            except KeyboardInterrupt:
                # äºŒæ¬¡ Ctrl+C å¼ºåˆ¶é€€å‡º
                print("\nâš ï¸ å†æ¬¡æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œå¼ºåˆ¶é€€å‡º...")
                break
            except Exception as e:
                print(f"\nâŒ ä¸»å¾ªç¯å‘ç”Ÿå¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
                # ç­‰å¾…ä¸€æ®µæ—¶é—´åç»§ç»­
                print(f"   å°†åœ¨60ç§’åç»§ç»­è¿è¡Œ...")
                if not interruptible_sleep(60):
                    break

    finally:
        # ========== æ¸…ç†æµè§ˆå™¨æ±  ==========
        if browser_pool_instance:
            print("\nğŸ›‘ æ­£åœ¨å…³é—­æµè§ˆå™¨æ± ...")
            try:
                if keepalive_service:
                    keepalive_service.stop()
                shutdown_browser_pool()
                print("âœ… æµè§ˆå™¨æ± å·²å…³é—­")
            except Exception as e:
                print(f"âš ï¸ å…³é—­æµè§ˆå™¨æ± æ—¶å‡ºé”™: {e}")

    # ========== é€€å‡º ==========
    print("\n" + "=" * 80)
    print("âœ… å®ˆæŠ¤è¿›ç¨‹æ­£å¸¸é€€å‡º")
    print(f"   æ€»ä»»åŠ¡: {total_tasks}, æˆåŠŸ: {success_tasks}, å¤±è´¥: {failed_tasks}")
    print("=" * 80)


if __name__ == "__main__":
    main()

